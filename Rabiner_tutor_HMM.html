<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Notes on: Rabiner, L. R. (1990): A tutorial on hidden markov models and selected applications in speech recognition &mdash; Reading Notes  文档</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/theme_overrides.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script src="_static/proof.js"></script>
        <script src="_static/translations.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="搜索" href="search.html" />
    <link rel="next" title="Notes on: 张书岩, et al. (1997): 简化字溯源" href="张书岩_简化字溯源_1997.html" />
    <link rel="prev" title="Notes on: Christie, A. (2009): 清洁女工之死" href="Christie_清洁女工之死_2009.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> Reading Notes
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p><span class="caption-text">目录</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Plokhy_Chernobyl_2020.html">Notes on: Plokhy, S. (2020): 切尔诺贝利：一部悲剧史</a></li>
<li class="toctree-l1"><a class="reference internal" href="杨奎松_毛泽东与莫斯科的恩恩怨怨_2005.html">Notes on: 杨奎松,  (2005): 毛泽东与莫斯科的恩恩怨怨</a></li>
<li class="toctree-l1"><a class="reference internal" href="郑执_仙症_2020.html">Notes on: 郑执,  (2020): 仙症</a></li>
<li class="toctree-l1"><a class="reference internal" href="许纪霖_新天下主义_2015.html">Notes on:  许纪霖, &amp;  刘擎 (2015): 新天下主义</a></li>
<li class="toctree-l1"><a class="reference internal" href="建国以来毛泽东文稿_vol12.html">Notes on: 毛泽东,  (1998): 建国以来毛泽东文稿–第十二册</a></li>
<li class="toctree-l1"><a class="reference internal" href="魏舒歌_战场之外_2020.html">Notes on: 魏舒歌,  (2020): 战场之外：租界英文报刊与中国的国际宣传</a></li>
<li class="toctree-l1"><a class="reference internal" href="叶永烈_四人帮_2014.html">Notes on: 叶永烈,  (2014): 四人帮”兴亡（增订版）</a></li>
<li class="toctree-l1"><a class="reference internal" href="Holt_柏林病人_2021.html">Notes on: Holt, N. (2021): 柏林病人：艾滋病医疗史的转折</a></li>
<li class="toctree-l1"><a class="reference internal" href="邹金灿_唐宋诗会意_2016.html">Notes on: 邹金灿,  (2016): 唐宋诗会意：七百年的风流儒雅</a></li>
<li class="toctree-l1"><a class="reference internal" href="Stern_我的五个德国_2020.html">Notes on: Stern, F. (2020): 我的五个德国</a></li>
<li class="toctree-l1"><a class="reference internal" href="秦晖_乌克兰评论.html">秦晖《乌克兰评论系列》</a></li>
<li class="toctree-l1"><a class="reference internal" href="Eckermann_歌德谈话录_1978.html">Notes on: Eckermann,  (1978): 歌德谈话录</a></li>
<li class="toctree-l1"><a class="reference internal" href="秦晖_走出帝制_2015.html">Notes on: 秦晖,  (2015): 走出帝制：从晚清到民国的历史回望</a></li>
<li class="toctree-l1"><a class="reference internal" href="Turvey_犯罪心理画像_2005.html">Notes on: Turvey, B. E. (2005): 犯罪心理画像：行为证据分析入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="程连升_筚路蓝缕_2016.html">Notes on: 程连升,  (2016): 筚路蓝缕：计划经济在中国</a></li>
<li class="toctree-l1"><a class="reference internal" href="Obama_應許之地_2020.html">Notes on: Obama, B. (2020): 應許之地：歐巴馬回憶錄</a></li>
<li class="toctree-l1"><a class="reference internal" href="薛林荣_鲁迅的饭局_2021.html">Notes on: 薛林荣,  (2021): 鲁迅的饭局</a></li>
<li class="toctree-l1"><a class="reference internal" href="Luo_homo_21.html">Notes on: Luo, S., Zhao, Y., Xiao, Y., Lin, R., &amp; Yan, Y. (2021): A temporal-spatial spectrum prediction using the concept of homotopy theory for uav communications</a></li>
<li class="toctree-l1"><a class="reference internal" href="Nowicki_factor_15.html">Notes on: Nowicki, M., &amp; Skrzypczyński, P. (2015): Indoor navigation with a smartphone fusing inertial and wifi data via factor graph optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="张爱玲_倾城之恋_2012.html">Notes on: 张爱玲,  (2012): 倾城之恋</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lane_生命之源_2016.html">Notes on: Lane, N. (2016): 生命之源：能量、演化与复杂生命的起源</a></li>
<li class="toctree-l1"><a class="reference internal" href="岛田庄司_异位_2011.html">Notes on: 岛田庄司,  (2011): 异位</a></li>
<li class="toctree-l1"><a class="reference internal" href="梅汝璈_远东国际军事法庭_1988.html">Notes on: 梅汝璈,  (1988): 远东国际军事法庭</a></li>
<li class="toctree-l1"><a class="reference internal" href="Mato_lp_07.html">Notes on: Matousek, J., &amp; Gaertner, B. (2007): Understanding and using linear programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="冈田英弘_紫禁城的荣光_2017.html">Notes on: 冈田英弘, , 神田信夫, , &amp; 松村润,  (2017): 紫禁城的荣光：明清全史</a></li>
<li class="toctree-l1"><a class="reference internal" href="陶孟和_北平生活费之分析_2011.html">Notes on: 陶孟和,  (2011): 北平生活费之分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="笑忘书_2013.html">Notes on:  王朔 (2013): 笑忘书――梁左作品集</a></li>
<li class="toctree-l1"><a class="reference internal" href="范福潮_书海泛舟记_2013.html">Notes on: 范福潮,  (2013): 书海泛舟记</a></li>
<li class="toctree-l1"><a class="reference internal" href="杨学军_留存记忆_2016.html">Notes on: 杨学军,  (2016): 留存记忆：老北京地名文化寻踪</a></li>
<li class="toctree-l1"><a class="reference internal" href="鲁迅_且介亭杂文_1973.html">Notes on: 鲁迅,  (1973): 且介亭杂文</a></li>
<li class="toctree-l1"><a class="reference internal" href="Christie_清洁女工之死_2009.html">Notes on: Christie, A. (2009): 清洁女工之死</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Notes on: Rabiner, L. R. (1990): A tutorial on hidden markov models and selected applications in speech recognition</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduction">INTRODUCTION</a></li>
<li class="toctree-l2"><a class="reference internal" href="#discrete-markov-processes">DISCRETE MARKOV PROCESSES </a><ul>
<li class="toctree-l3"><a class="reference internal" href="#extension-to-hidden-markov-models">Extension to Hidden Markov Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="#elements-of-an-hmm">Elements of an HMM</a></li>
<li class="toctree-l3"><a class="reference internal" href="#the-three-basic-problems-for-hmms">The Three Basic Problems for HMMs </a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#solutions-to-the-three-basic-problems-of-hmms">SOLUTIONS TO THE THREE BASIC PROBLEMS OF HMMs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#solution-to-problem-1">Solution to Problem 1</a></li>
<li class="toctree-l3"><a class="reference internal" href="#solution-to-problem-2">Solution to Problem 2</a></li>
<li class="toctree-l3"><a class="reference internal" href="#solution-to-problem-3-ref1-ref5">Solution to Problem 3 <span>[Ref1]</span> - <span>[Ref5]</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#types-of-hmms">TYPES OF HMMs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#continuous-observation-densities-in-hmms-ref24-ref25-ref26">Continuous Observation Densities in HMMs <span>[Ref24]</span>, <span>[Ref25]</span>, <span>[Ref26]</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="#autoregressive-hmms-ref27-ref28">Autoregressive HMMs <span>[Ref27]</span>, <span>[Ref28]</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="#variants-on-hmm-structures-null-transitions-and-tied-states">Variants on HMM Structures - Null Transitions and Tied States</a></li>
<li class="toctree-l3"><a class="reference internal" href="#inclusion-of-explicit-state-duration-density-in-hmms-ref29-ref30">Inclusion of Explicit State Duration Density in HMMs , <span>[Ref29]</span>, <span>[Ref30]</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="#optimization-criterion-ml-mmi-and-mdi-ref32-ref33">Optimization Criterion - ML, MMI, and MDI <span>[Ref32]</span>, <span>[Ref33]</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="#comparison-of-hmms-ref34">Comparison of HMMs <span>[Ref34]</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#implementation-issues-for-hmms">IMPLEMENTATION ISSUES FOR HMMs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#scaling-ref14">Scaling <span>[Ref14]</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="#multiple-observation-sequences-ref14">Multiple Observation Sequences <span>[Ref14]</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="#initial-estimates-of-hmm-parameters">Initial Estimates of HMM Parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="#effects-of-insufficient-training-data-ref36">Effects of Insufficient Training Data <span>[Ref36]</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="#choice-of-model">Choice of Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#implementation-of-speech-recognizers-using-hmms">IMPLEMENTATION OF SPEECH RECOGNIZERS USING HMMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#connected-word-recognition-using-hmms-ref59-ref63">CONNECTED WORD RECOGNITION USING HMMs <span>[Ref59]</span> - <span>[Ref63]</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#hmms-for-large-vocabulary-speech-recognition-ref6-ref13-ref31-ref37-ref38-ref51-ref64-ref66">HMMs FOR LARGE VOCABULARY SPEECH RECOGNITION <span>[Ref6]</span> - <span>[Ref13]</span>, <span>[Ref31]</span>, <span>[Ref37]</span>, <span>[Ref38]</span>, <span>[Ref51]</span>, <span>[Ref64]</span> - <span>[Ref66]</span></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="张书岩_简化字溯源_1997.html">Notes on: 张书岩,  et al. (1997): 简化字溯源</a></li>
<li class="toctree-l1"><a class="reference internal" href="袁珂_中国神话史_2015.html">Notes on: 袁珂,  (2015): 中国神话史</a></li>
<li class="toctree-l1"><a class="reference internal" href="Christie_hollow_2002.html">Notes on: Christie, A. (2002): The hollow</a></li>
<li class="toctree-l1"><a class="reference internal" href="京极夏彦_络新妇之理.html">Notes on: 京极夏彦,  (2009): 络新妇之理</a></li>
<li class="toctree-l1"><a class="reference internal" href="老舍_牛天赐传_2009.html">Notes on: 老舍,  (2009): 牛天赐传</a></li>
<li class="toctree-l1"><a class="reference internal" href="Nesterov_convex_2nd.html">Notes on: Nesterov, Y. (2018): Lectures on convex optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="定宜庄_城墙之外_2017.html">Notes on: 定宜庄,  (2017): 城墙之外</a></li>
<li class="toctree-l1"><a class="reference internal" href="Durkheim_宗教生活的基本形式_1999.html">Notes on: Durkheim, E. (1999): 宗教生活的基本形式</a></li>
<li class="toctree-l1"><a class="reference internal" href="宠物先生_虚拟街头_2009.html">Notes on: 宠物先生,  (2009): 虚拟街头漂流记</a></li>
<li class="toctree-l1"><a class="reference internal" href="熊家军_养鸡必读_2006.html">Notes on: 熊家军,  (2006): 养鸡必读</a></li>
<li class="toctree-l1"><a class="reference internal" href="陈晓维_书贩笑忘录_2018.html">Notes on: 陈晓维,  (2018): 书贩笑忘录</a></li>
<li class="toctree-l1"><a class="reference internal" href="渊田美津雄_中途岛海战_1979.html">Notes on: 渊田美津雄,  &amp; 奥宫正武,  (1979): 中途岛海战</a></li>
<li class="toctree-l1"><a class="reference internal" href="Greenspan_繁荣与衰退_2019.html">Notes on: Greenspan, A. &amp; Wooldridge, A. (2019): 繁荣与衰退：一部美国经济发展史</a></li>
<li class="toctree-l1"><a class="reference internal" href="黄奇帆_分析与思考_2020.html">Notes on: 黄奇帆,  (2020): 分析与思考</a></li>
<li class="toctree-l1"><a class="reference internal" href="常青_协和医事_2017.html">Notes on: 常青,  (2017): 协和医事：协和百年纪念版</a></li>
<li class="toctree-l1"><a class="reference internal" href="黄永玉_比我老的老头_增订珍藏版_2005.html">Notes on: 黄永玉,  (2005): 比我老的老头（增订珍藏版）</a></li>
<li class="toctree-l1"><a class="reference internal" href="周克希_译边草_2012.html">Notes on: 周克希,  (2012): 译边草</a></li>
<li class="toctree-l1"><a class="reference internal" href="Wortley_犯罪心理学_2019.html">Notes on: Wortley, R. (2019): 犯罪心理学：犯罪为何会发生</a></li>
<li class="toctree-l1"><a class="reference internal" href="Christie_dumb_witness_2011.html">Notes on: Christie, A. (2011): Dumb Witness</a></li>
<li class="toctree-l1"><a class="reference internal" href="Berman_法律与宗教_1991.html">Notes on: Berman, H. J. (1991): 法律与宗教</a></li>
<li class="toctree-l1"><a class="reference internal" href="Vil_indoor_2019.html">Notes on: Carrera Villacres, J. L. et al. (2019): A particle filter-based reinforcement learning approach for reliable wireless indoor positioning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Fletcher_hybrid_1987.html">Notes on: Fletcher, R. &amp; Xu, C. (1987): Hybrid methods for nonlinear least squares</a></li>
<li class="toctree-l1"><a class="reference internal" href="爱因斯坦文集第一卷.html">Notes on: Einstein, A. (1976): 爱因斯坦文集第一卷</a></li>
<li class="toctree-l1"><a class="reference internal" href="何兆武_上学记_2006.html">Notes on: 何兆武,  (2006): 上学记</a></li>
<li class="toctree-l1"><a class="reference internal" href="陈冠中_我这一代香港人_2005.html">Notes on: 陈冠中,  (2005): 我这一代香港人</a></li>
<li class="toctree-l1"><a class="reference internal" href="邓小平文选第二卷_1994.html">Notes on: 邓小平,  (1994): 邓小平文选第二卷</a></li>
<li class="toctree-l1"><a class="reference internal" href="邓小平文选第三卷_1993.html">Notes on: 邓小平,  (1993): 邓小平文选第三卷</a></li>
<li class="toctree-l1"><a class="reference internal" href="郭沫若_十批判书_1996.html">Notes on: 郭沫若,  (1996): 十批判书</a></li>
<li class="toctree-l1"><a class="reference internal" href="李泽厚_论语今读_2008.html">Notes on: 李泽厚,  (2008): 论语今读</a></li>
<li class="toctree-l1"><a class="reference internal" href="李泽厚_美的历程_2009.html">Notes on: 李泽厚,  (2009): 美的历程</a></li>
<li class="toctree-l1"><a class="reference internal" href="李泽厚_中国古代思想史论_2008.html">Notes on: 李泽厚,  (2008): 中国古代思想史论</a></li>
<li class="toctree-l1"><a class="reference internal" href="李泽厚_中国近代思想史论_2008.html">Notes on: 李泽厚,  (2008): 中国近代思想史论</a></li>
<li class="toctree-l1"><a class="reference internal" href="李泽厚_中国现代思想史论_2008.html">Notes on: 李泽厚,  (2008): 中国现代思想史论</a></li>
<li class="toctree-l1"><a class="reference internal" href="李泽厚_华夏美学_美学四讲_2008.html">Notes on: 李泽厚,  (2008): 华夏美学・美学四讲</a></li>
<li class="toctree-l1"><a class="reference internal" href="李泽厚_历史本体论_己卯五说_2008.html">Notes on: 李泽厚,  (2008): 历史本体论・己卯五说</a></li>
<li class="toctree-l1"><a class="reference internal" href="李泽厚_实用理性与乐感文化_2008.html">Notes on: 李泽厚,  (2008): 实用理性与乐感文化</a></li>
<li class="toctree-l1"><a class="reference internal" href="李泽厚_告别革命_1997.html">Notes on: 李泽厚,  &amp; 刘再复,  (1997): 告别革命――回望二十世纪中国</a></li>
<li class="toctree-l1"><a class="reference internal" href="李泽厚_杂著集_2008.html">Notes on: 李泽厚,  (2008): 杂著集</a></li>
<li class="toctree-l1"><a class="reference internal" href="Wittgenstein_逻辑哲学论_贺绍甲译_1996.html">Notes on: Wittgenstein, L. (1996): 逻辑哲学论</a></li>
<li class="toctree-l1"><a class="reference internal" href="Russell_为什么我不是基督教徒_2010.html">Notes on: Russell, B. (2010): 为什么我不是基督教徒</a></li>
<li class="toctree-l1"><a class="reference internal" href="托克维尔_旧制度与大革命_1992.html">Notes on: 托克维尔,  (1992): 旧制度与大革命</a></li>
<li class="toctree-l1"><a class="reference internal" href="Satrapi_我在伊朗长大_2006.html">Notes on: Satrapi, M. (2006): 我在伊朗长大</a></li>
<li class="toctree-l1"><a class="reference internal" href="Snow_西行漫记_1979.html">Notes on: Snow, E. (1979): 西行漫记（红星照耀中国）</a></li>
<li class="toctree-l1"><a class="reference internal" href="恩格斯_德国古典哲学的终结_97.html">Notes on: 恩格斯,  (1997): 路德维希・费尔巴哈和德国古典哲学的终结</a></li>
<li class="toctree-l1"><a class="reference internal" href="钱理群_毛泽东时代和后毛泽东时代.html">Notes on: 钱理群,  (2012): 毛泽东时代和后毛泽东时代（1949-2009）――另一种历史书写</a></li>
<li class="toctree-l1"><a class="reference internal" href="Russell_西方哲学史_上.html">Notes on: Russell, B. (1963): 西方哲学史（上卷）</a></li>
<li class="toctree-l1"><a class="reference internal" href="Russell_西方哲学史_下.html">Notes on: Russell, B. (1982): 西方哲学史（下卷）</a></li>
<li class="toctree-l1"><a class="reference internal" href="zzref.html">参考文献</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Reading Notes</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Notes on: Rabiner, L. R. (1990): A tutorial on hidden markov models and selected applications in speech recognition</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/Rabiner_tutor_HMM.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="notes-on-rabiner-l-r-1990-a-tutorial-on-hidden-markov-models-and-selected-applications-in-speech-recognition">
<h1>Notes on: Rabiner, L. R. (1990): A tutorial on hidden markov models and selected applications in speech recognition<a class="headerlink" href="#notes-on-rabiner-l-r-1990-a-tutorial-on-hidden-markov-models-and-selected-applications-in-speech-recognition" title="永久链接至标题">¶</a></h1>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@article</span><span class="p">{</span><span class="nl">Rabiner_tutor_HMM</span><span class="p">,</span><span class="w"></span>
<span class="w">  </span><span class="na">author</span><span class="w">    </span><span class="p">=</span><span class="w"> </span><span class="s">{Rabiner, Lawrence R.}</span><span class="p">,</span><span class="w"></span>
<span class="w">  </span><span class="na">title</span><span class="w">     </span><span class="p">=</span><span class="w"> </span><span class="s">{A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition}</span><span class="p">,</span><span class="w"></span>
<span class="w">  </span><span class="na">journal</span><span class="w">   </span><span class="p">=</span><span class="w"> </span><span class="s">{Readings in Speech Recognition}</span><span class="p">,</span><span class="w"></span>
<span class="w">  </span><span class="na">pages</span><span class="w">     </span><span class="p">=</span><span class="w"> </span><span class="s">{267–296}</span><span class="p">,</span><span class="w"></span>
<span class="w">  </span><span class="na">year</span><span class="w">      </span><span class="p">=</span><span class="w"> </span><span class="s">{1990}</span><span class="p">,</span><span class="w"></span>
<span class="w">  </span><span class="na">doi</span><span class="w">       </span><span class="p">=</span><span class="w"> </span><span class="s">{10.1016/b978-0-08-051584-7.50027-9}</span><span class="p">,</span><span class="w"></span>
<span class="w">  </span><span class="na">url</span><span class="w">       </span><span class="p">=</span><span class="w"> </span><span class="s">{http://dx.doi.org/10.1016/b978-0-08-051584-7.50027-9}</span><span class="p">,</span><span class="w"></span>
<span class="w">  </span><span class="na">isbn</span><span class="w">      </span><span class="p">=</span><span class="w"> </span><span class="s">{http://id.crossref.org/isbn/9781558601246}</span><span class="p">,</span><span class="w"></span>
<span class="w">  </span><span class="na">publisher</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Elsevier BV}</span><span class="p">,</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>Although initially introduced and studied in the late 1960s and early 1970s,
statistical methods of Markov source or hidden Markov modeling have become
increasingly popular in the last several years. There are two strong reasons why
this has occurred. First the models are very rich in mathematical structure and
hence can form the theoretical basis for use in a wide range of applications.
Second the models, when applied properly, work very well in practice for several
important applications. In this paper we attempt to carefully and methodically
review the theoretical aspects of this type of statistical modeling and show how
they have been applied to selected problems in machine recognition of speech.</p>
<section id="introduction">
<h2>INTRODUCTION<a class="headerlink" href="#introduction" title="永久链接至标题">¶</a></h2>
<p>Real-world processes generally produce observable outputs which can be
characterized as signals. The signals can be discrete in nature (e.g.,
characters from a finite alphabet, quantized vectors from a codebook, etc.), or
continuous in nature (e.g., speech samples, temperature measurements, music,
etc.). The signal source can be stationary (i.e., its statistical properties do
not vary with time), or nonstationary (i.e., the signal properties vary over
time). The signals can be pure (i.e., coming strictly from a single source), or
can be corrupted from other signal sources (e.g., noise) or by transmission
distortions, reverberation, etc.</p>
<p>A problem of fundamental interest is characterizing such real-world signals in
terms of signal models. There are several reasons why one is interested in
applying signal models. First of all, a signal model can provide the basis for a
theoretical description of a signal processing system which can be used to
process the signal so as to provide a desired output. For example if we are
interested in enhancing a speech signal corrupted by noise and transmission
distortion, we can use the signal model to design a system which will optimally
remove the noise and undo the transmission distortion. A second reason why
signal models are important is that they are potentially capable of letting us
learn a great deal about the signal source (i.e., the real-world process which
produced the signal) without having to have the source available. This property
is especially important when the cost of getting signals from the actual source
is high. In this case, with a good signal model, we can simulate the source and
learn as much as possible via simulations. Finally, the most important reason
why signal models are important is that they often work extremely well in
practice, and enable us to realize important practical systems-e.g., prediction
systems, recognition systems, identification systems, etc., in a very efficient
manner.</p>
<p>These are several possible choices for what type of signal model is used for
characterizing the properties of a given signal. Broadly one can dichotomize the
types of signal models into the class of deterministic models, and the class of
statistical models. Deterministic models generally exploit some known specific
properties of the signal, e.g., that the signal is a sine wave, or a sum of
exponentials, etc. In these cases, specification of the signal model is
generally straightforward; all that is required is to determine (estimate)
values of the parameters of the signal model (e.g., amplitude, frequency, phase
of a sine wave, amplitudes and rates of exponentials, etc.). The second broad
class of signal models is the set of statistical models in which one tries to
characterize only the statistical properties of the signal. Examples of such
statistical models include Gaussian processes, Poisson processes, Markov
processes, and hidden Markov processes, among others. The underlying assumption
of the statistical model is that the signal can be well characterized as a
parametric random process, and that the parameters of the stochastic process can
be determined (estimated) in a precise, well-defined manner.</p>
<p>For the applications of interest, namely speech processing, both deterministic
and stochastic signal models have had good success. In this paper we will
concern ourselves strictly with one type of stochastic signal model, namely the
hidden Markov model (HMM). (These models are referred to as Markov sources or
probabilistic functions of Markov chains in the communications literature.) We
will first review the theory of Markov chains and then extend the ideas to the
class of hidden Markov models using several simple examples. We will then focus
our attention on the three fundamental problems <a class="footnote-reference brackets" href="#hmm1" id="id1">1</a> for HMM design, namely:
the evaluation of the probability (or likelihood) of a sequence of observations
given a specific HMM; the determination of a best sequence of model states; and
the adjustment of model parameters so as to best account for the observed
signal. We will show that once these three fundamental problems are solved, we
can apply HMMs to selected problems in speech recognition.</p>
<p>Neither the theory of hidden Markov models nor its applications to speech
recognition is new. The basic theory was published in a series of classic papers
by Baum and his colleagues <a class="reference internal" href="#ref1" id="id2"><span>[Ref1]</span></a>, <a class="reference internal" href="#ref2" id="id3"><span>[Ref2]</span></a>, <a class="reference internal" href="#ref3" id="id4"><span>[Ref3]</span></a>, <a class="reference internal" href="#ref4" id="id5"><span>[Ref4]</span></a>, <a class="reference internal" href="#ref5" id="id6"><span>[Ref5]</span></a> in the
late 1960s and early 1970s and was implemented for speech processing
applications by Baker <a class="reference internal" href="#ref6" id="id7"><span>[Ref6]</span></a> at CMU, and by Jelinek and his colleagues at IBM
<a class="reference internal" href="#ref7" id="id8"><span>[Ref7]</span></a>, <a class="reference internal" href="#ref8" id="id9"><span>[Ref8]</span></a>, <a class="reference internal" href="#ref9" id="id10"><span>[Ref9]</span></a>, <a class="reference internal" href="#ref10" id="id11"><span>[Ref10]</span></a>, <a class="reference internal" href="#ref11" id="id12"><span>[Ref11]</span></a>, <a class="reference internal" href="#ref12" id="id13"><span>[Ref12]</span></a>, <a class="reference internal" href="#ref13" id="id14"><span>[Ref13]</span></a> in the 1970s.
However, widespread understanding and application of the theory of HMMs to
speech processing has occurred only within the past several years. There are
several reasons why this has been the case. First, the basic theory of hidden
Markov models was published in mathematical journals which were not generally
read by engineers working on problems in speech processing. The second reason
was that the original applications of the theory to speech processing did not
provide sufficient tutorial material for most readers to understand the theory
and to be able to apply it to their own research. As a result, several tutorial
papers were written which provided a sufficient level of detail for a number of
research labs to begin work using HMMs in individual speech processing
applications <a class="reference internal" href="#ref14" id="id15"><span>[Ref14]</span></a>, <a class="reference internal" href="#ref15" id="id16"><span>[Ref15]</span></a>, <a class="reference internal" href="#ref16" id="id17"><span>[Ref16]</span></a>, <a class="reference internal" href="#ref17" id="id18"><span>[Ref17]</span></a>, <a class="reference internal" href="#ref18" id="id19"><span>[Ref18]</span></a>, <a class="reference internal" href="#ref19" id="id20"><span>[Ref19]</span></a>. This
tutorial is intended to provide an overview of the basic theory of HMMs (as
originated by Baum and his colleagues), provide practical details on methods of
implementation of the theory, and describe a couple of selected applications of
the theory to distinct problems in speech recognition. The paper combines
results from a number of original sources and hopefully provides a single source
for acquiring the background required to pursue further this fascinating area of
research.</p>
<p>The organization of this paper is as follows. In Section II we review the theory
of discrete Markov chains and show how the concept of hidden states, where the
observation is a probabilistic function of the state, can be used effectively.
We illustrate the theory with two simple examples, namely coin-tossing, and the
classic balls-in-urns system. In Section III we discuss the three fundamental
problems of HMMs, and give several practical techniques for solving these
problems. In Section IV we discuss the various types of HMMs that have been
studied including ergodic as well as left-right models. In this section we also
discuss the various model features including the form of the observation density
function, the state duration density, and the optimization criterion for
choosing optimal HMM parameter values. In Section V we discuss the issues that
arise in implementing HMMs including the topics of scaling, initial parameter
estimates, model size, model form, missing data, and multiple observation
sequences. In Section VI we describe an isolated word speech recognizer,
implemented with HMM ideas, and show how it performs as compared to alternative
implementations. In Section VII we extend the ideas presented in Section VI to
the problem of recognizing a string of spoken words based on concatenating
individual HMMs of each word in the vocabulary. In Section VIII we briefly
outline how the ideas of HMM have been applied to a large vocabulary speech
recognizer, and in Section IX we summarize the ideas discussed throughout the
paper.</p>
</section>
<section id="discrete-markov-processes">
<h2>DISCRETE MARKOV PROCESSES <a class="footnote-reference brackets" href="#hmm2" id="id21">2</a><a class="headerlink" href="#discrete-markov-processes" title="永久链接至标题">¶</a></h2>
<figure class="align-center" id="id102">
<span id="hmmfig1"></span><img alt="_images/hmmfig1.png" src="_images/hmmfig1.png" />
<figcaption>
<p><span class="caption-number">图 1 </span><span class="caption-text">A Markov chain with 5 states (labeled <span class="math notranslate nohighlight">\(S_1\)</span> to <span class="math notranslate nohighlight">\(S_5\)</span>) with selected state transitions.</span><a class="headerlink" href="#id102" title="永久链接至图片">¶</a></p>
</figcaption>
</figure>
<p>Consider a system which may be described at any time as being in one of a set of
<span class="math notranslate nohighlight">\(N\)</span> distinct states, <span class="math notranslate nohighlight">\(S_1, S_2, \ldots, S_N\)</span>, as illustrated in
<a class="reference internal" href="#hmmfig1"><span class="std std-numref">图 1</span></a> (where <span class="math notranslate nohighlight">\(N = 5\)</span> for simplicity). At regularly spaced
discrete times, the system undergoes a change of state (possibly back to the
same state) according to a set of probabilities associated with the state. We
denote the time instants associated with state changes as <span class="math notranslate nohighlight">\(t = 1, 2,
\ldots\)</span> , and we denote the actual state at time <span class="math notranslate nohighlight">\(t\)</span> as <span class="math notranslate nohighlight">\(q_t\)</span>. A
full probabilistic description of the above system would, in general, require
specification of the current state (at time <span class="math notranslate nohighlight">\(t\)</span>), as well as all the
predecessor states. For the special case of a discrete, first order, Markov
chain, this probabilistic description is truncated to just the current and the
predecessor state, i.e.,</p>
<div class="math notranslate nohighlight" id="equation-hmmeq1">
<span class="eqno">(1)<a class="headerlink" href="#equation-hmmeq1" title="公式的永久链接">¶</a></span>\[P[q_t = S_j \mid q_{t-1} = S_i, q_{t-2} = S_k, \ldots] = P[q_t = S_j \mid q_{t-1} = S_i].\]</div>
<p>Further more we only consider those processes in which the right-hand side of
<a class="reference internal" href="#equation-hmmeq1">(1)</a> is independent of time, thereby leading to the set of state
transition probabilities <span class="math notranslate nohighlight">\(a_{ij}\)</span> of the form</p>
<div class="math notranslate nohighlight" id="equation-hmmeq2">
<span class="eqno">(2)<a class="headerlink" href="#equation-hmmeq2" title="公式的永久链接">¶</a></span>\[a_{ij} = P[q_t = S_j \mid q_{t-1} = S_i], \quad 1 \leq i, j \leq N\]</div>
<p>with the state transition coefficients having the properties</p>
<div class="math notranslate nohighlight" id="equation-hmmeq3">
<span class="eqno">(3)<a class="headerlink" href="#equation-hmmeq3" title="公式的永久链接">¶</a></span>\[\begin{split}a_{ij} &amp; \geq 0 \\
\sum_{j = 1}^{N} a_{ij} &amp; = 1\end{split}\]</div>
<p>since they obey standard stochastic constraints.</p>
<p>The above stochastic process could be called an observable Markov model since
the output of the process is the set of states at each instant of time, where
each state corresponds to a physical (observable) event. To set ideas, consider
a simple 3-state Markov model of the weather. We assume that once a day (e.g.,
at noon), the weather is observed as being one of the following:</p>
<blockquote>
<div><p>State 1: rain or (snow)</p>
<p>State 2: cloudy</p>
<p>State 3: sunny</p>
</div></blockquote>
<p>We postulate that the weather on day <span class="math notranslate nohighlight">\(t\)</span> is characterized by a single one
of the three states above, and that the matrix <span class="math notranslate nohighlight">\(A\)</span> of state transition
probabilities is</p>
<div class="math notranslate nohighlight">
\[\begin{split}A = \{a_{ij}\} =
\begin{bmatrix}
0.4 &amp; 0.3 &amp; 0.3 \\
0.2 &amp; 0.6 &amp; 0.2 \\
0.1 &amp; 0.1 &amp; 0.8
\end{bmatrix}
.\end{split}\]</div>
<p>Given that the weather on day 1 (<span class="math notranslate nohighlight">\(t = 1\)</span>) is sunny (state 3), we can ask
the question: What is the probability (according to the model) that the weather
for the next 7 days will be “sun-sun-rain-rain-sun-cloudy-sun”? Stated more
formally, we define the observation sequence <span class="math notranslate nohighlight">\(O\)</span> as
<span class="math notranslate nohighlight">\(O = \{S_3, S_3, S_3, S_1, S_1, S_3, S_2, S_3\}\)</span>
corresponding to <span class="math notranslate nohighlight">\(t = 1, 2, \ldots, 8,\)</span> and we
wish to determine the probability of <span class="math notranslate nohighlight">\(O\)</span> , given the model. This
probability can be expressed (and evaluated) as</p>
<div class="math notranslate nohighlight">
\[\begin{split}P(O \mid \text{Model}) &amp; = P[S_3, S_3, S_3, S_1, S_1, S_3, S_2, S_3 \mid \text{Model}] \\
&amp; = P[S_3] \cdot P[S_3 \mid S_3] \cdot P[S_3 \mid S_3] \cdot P[S_1 \mid S_3] \\
&amp; \quad \cdot P[S_1 \mid S_1] \cdot P[S_3 \mid S_1] \mid P[S_2 \mid S_3] \mid P[S_3 \mid S_2] \\
&amp; = \pi_3 \cdot a_{33} a_{33} a_{31} a_{11} a_{13} a_{32} a_{23} \\
&amp; = 1 \times 0.8 \times 0.8 \times 0.1 \times 0.4 \times 0.3 \times 0.1 \times 0.2 \\
&amp; = 1.536 \times 10^{-4}\end{split}\]</div>
<p>where we use the notation</p>
<div class="math notranslate nohighlight" id="equation-hmmeq4">
<span class="eqno">(4)<a class="headerlink" href="#equation-hmmeq4" title="公式的永久链接">¶</a></span>\[\pi_i = P[q_1 = S_i], \quad 1 \leq i \leq N\]</div>
<p>to denote the initial state probabilities.</p>
<p>Another interesting question we can ask (and answer using the model) is: Given
that the model is in a known state, what is the probability it stays in that
state for exactly <span class="math notranslate nohighlight">\(d\)</span> days? This probability can be evaluated as the
probability of the observation sequence</p>
<div class="math notranslate nohighlight">
\[O = \{S_i, S_i, S_i, \ldots, S_i, S_j \neq S_i\},\]</div>
<p>given the model, which is</p>
<div class="math notranslate nohighlight" id="equation-hmmeq5">
<span class="eqno">(5)<a class="headerlink" href="#equation-hmmeq5" title="公式的永久链接">¶</a></span>\[P(O \mid \text{Model}, q_1 = S_i) = (a_{ii})^{d-1} (1 - a_{ii}) = p_i(d).\]</div>
<p>The quantity <span class="math notranslate nohighlight">\(p_i(d)\)</span> is the (discrete) probability density function of
duration <span class="math notranslate nohighlight">\(d\)</span> in state <span class="math notranslate nohighlight">\(i\)</span> . This exponential duration density is
characteristic of the state duration in a Markov chain. Based on <span class="math notranslate nohighlight">\(p_i(d)\)</span>
, we can readily calculate the expected number of observations (duration) in a
state, conditioned on starting in that state as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq6">
<span class="eqno">(6)<a class="headerlink" href="#equation-hmmeq6" title="公式的永久链接">¶</a></span>\[\begin{split}\bar{d}_i &amp; = \sum_{d=1}^{\infty} d p_i(d) \\
&amp; = \sum_{d=1}^{\infty} d (a_{ii})^{d-1} (1 - a_{ii}) = \dfrac{1}{1 - a_{ii}}.\end{split}\]</div>
<p>Thus the expected number of consecutive days of sunny weather, according to the
model, is <span class="math notranslate nohighlight">\(1/0.2 = 5\)</span> ; for cloudy it is <span class="math notranslate nohighlight">\(2.5\)</span> ; for rain it is
<span class="math notranslate nohighlight">\(1.67\)</span> .</p>
<section id="extension-to-hidden-markov-models">
<h3>Extension to Hidden Markov Models<a class="headerlink" href="#extension-to-hidden-markov-models" title="永久链接至标题">¶</a></h3>
<p>So far we have considered Markov models in which each state corresponded to an
observable (physical) event. This model is too restrictive to be applicable to
many problems of interest. In this section we extend the concept of Markov
models to include the case where the observation is a probabilistic function of
the state-i.e., the resulting model (which is called a hidden Markov model) is a
doubly embedded stochastic process with an underlying stochastic process that is
not observable (it is hidden), but can only be observed through another set of
stochastic processes that produce the sequence of observations. To fix ideas,
consider the following model of some simple coin tossing experiments.</p>
<p><strong>Coin Toss Models</strong>: Assume the following scenario. You are in a room with a
barrier (e.g., a curtain) through which you cannot see what is happening. On the
other side of the barrier is another person who is performing a coin (or
multiple coin) tossing experiment. The other person will not tell you anything
about what he is doing exactly; he will only tell you the result of each coin
flip. Thus a sequence of hidden coin tossing experiments is performed, with the
observation sequence consisting of a series of heads and tails; e.g., a typical
observation sequence would be</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathcal{O} &amp; = O_1 O_2 O_3 \cdots O_T \\
&amp; = \mathscr{H} \mathscr{H} \mathscr{T} \cdots \mathscr{H}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathscr{H}\)</span> stands for heads and <span class="math notranslate nohighlight">\(\mathscr{T}\)</span> stands for
tails.</p>
<p>Given the above scenario, the problem of interest is how do we build an HMM to
explain (model) the observed sequence of heads and tails. The first problem one
faces is deciding what the states in the model correspond to, and then deciding
how many states should be in the model. One possible choice would be to assume
that only a single biased coin was being tossed. In this case we could model the
situation with a 2-state model where each state corresponds to a side of the
coin (i.e., heads or tails). This model is depicted in <a class="reference internal" href="#hmmfig2"><span class="std std-numref">图 2</span></a> (a)
<a class="footnote-reference brackets" href="#hmm3" id="id22">3</a>. In this case the Markov model is observable, and the only issue for
complete specification of the model would be to decide on the best value for the
bias (i.e., the probability of, say, heads). Interestingly, an equivalent HMM to
that of <a class="reference internal" href="#hmmfig2"><span class="std std-numref">图 2</span></a> (a) would be a degenerate 1-state model, where the
state corresponds to the single biased coin, and the unknown parameter is the
bias of the coin.</p>
<figure class="align-center" id="id103">
<span id="hmmfig2"></span><img alt="_images/hmmfig2.png" src="_images/hmmfig2.png" />
<figcaption>
<p><span class="caption-number">图 2 </span><span class="caption-text">Three possible Markov models which can account for the results of hidden coin tossing experiments. (a) 1-coin model. (b) 2-coins model. (c) 3-coins model.</span><a class="headerlink" href="#id103" title="永久链接至图片">¶</a></p>
</figcaption>
</figure>
<p>A second form of HMM for explaining the observed sequence of coin toss outcome
is given in <a class="reference internal" href="#hmmfig2"><span class="std std-numref">图 2</span></a> (b). In this case there are 2 states in the model
and each state corresponds to a different, biased, coin being tossed. Each state
is characterized by a probability distribution of heads and tails, and
transitions between states are characterized by a state transition matrix. The
physical mechanism which accounts for how state transitions are selected could
itself be a set of independent coin tosses, or some other probabilistic event.</p>
<p>A third form of HMM for explaining the observed sequence of coin toss outcomes
is given in <a class="reference internal" href="#hmmfig2"><span class="std std-numref">图 2</span></a> (c). This model corresponds to using 3 biased
coins, and choosing from among the three, based on some probabilistic event.</p>
<p>Given the choice among the three models shown in <a class="reference internal" href="#hmmfig2"><span class="std std-numref">图 2</span></a> for
explaining the observed sequence of heads and tails, a natural question would be
which model best matches the actual observations. It should be clear that the
simple 1-coin model of <a class="reference internal" href="#hmmfig2"><span class="std std-numref">图 2</span></a> (a) has only 1 unknown parameter; the
2-coin model of <a class="reference internal" href="#hmmfig2"><span class="std std-numref">图 2</span></a> (b) has 4 unknown parameters; and the 3-coin
model of <a class="reference internal" href="#hmmfig2"><span class="std std-numref">图 2</span></a> (c) has 9 unknown parameters. Thus, with the greater
degrees of freedom, the larger HMMs would seem to inherently be more capable of
modeling a series of coin tossing experiments than would equivalently smaller
models. Although this is theoretically true, we will see later in this paper
that practical considerations impose some strong limitations on the size of
models that we can consider. Furthermore, it might just be the case that only a
single coin is being tossed. Then using the 3-coin model of
<a class="reference internal" href="#hmmfig2"><span class="std std-numref">图 2</span></a> (c) would be inappropriate, since the actual physical event
would not correspond to the model being used-i.e., we would be using an
underspecified system.</p>
<p><strong>The Urn and Ball Mode</strong> <a class="footnote-reference brackets" href="#hmm4" id="id23">4</a>: To extend the ideas of the HMM to a somewhat
more complicated situation, consider the urn and ball system of
<a class="reference internal" href="#hmmfig3"><span class="std std-numref">图 3</span></a> . We assume that there are <span class="math notranslate nohighlight">\(N\)</span> (large) glass urns in a
room. Within each urn there are a large number of colored balls. We assume there
are <span class="math notranslate nohighlight">\(M\)</span> distinct colors of the balls. The physical process for obtaining
observations is as follows. A genie is in the room, and according to some random
process, he (or she) chooses an initial urn. From this urn, a ball is chosen at
random, and its color is recorded as the observation. The ball is then replaced
in the urn from which it was selected. A new urn is then selected according to
the random selection process associated with the current urn, and the ball
selection process is repeated. This entire process generates a finite
observation sequence of colors, which we would like to model as the observable
output of an HMM.</p>
<figure class="align-center" id="id104">
<span id="hmmfig3"></span><img alt="_images/hmmfig3.png" src="_images/hmmfig3.png" />
<figcaption>
<p><span class="caption-number">图 3 </span><span class="caption-text">An <span class="math notranslate nohighlight">\(N\text{-state}\)</span> urn and ball model which illustrates the general
case of a discrete symbol HMM.</span><a class="headerlink" href="#id104" title="永久链接至图片">¶</a></p>
</figcaption>
</figure>
<p>It should be obvious that the simplest HMM that corresponds to the urn and ball
process is one in which each state corresponds to a specific urn, and for which
a (ball) color probability is defined for each state. The choice of urns is
dictated by the state transition matrix of the HMM.</p>
</section>
<section id="elements-of-an-hmm">
<h3>Elements of an HMM<a class="headerlink" href="#elements-of-an-hmm" title="永久链接至标题">¶</a></h3>
<p>The above examples give us a pretty good idea of what an HMM is and how it can
be applied to some simple scenarios. We now formally define the elements of an
HMM, and explain how the model generates observation sequences.</p>
<p>An HMM is characterized by the following:</p>
<ol class="arabic">
<li><p><span class="math notranslate nohighlight">\(N\)</span>, the number of states in the model. Although the states are hidden,
for many practical applications there is often some physical significance
attached to the states or to sets of states of the model. Hence, in the coin
tossing experiments, each state corresponded to a distinct biased coin. In
the urn and ball model, the states corresponded to the urns. Generally the
states are interconnected in such a way that any state can be reached from
any other state (e.g., an ergodic model); however, we will see later in this
paper that other possible interconnections of states are often of interest.
We denote the individual states as <span class="math notranslate nohighlight">\(S = \{S_1, S_2, \ldots, S_N\}\)</span>, and
the state at time <span class="math notranslate nohighlight">\(t\)</span> as <span class="math notranslate nohighlight">\(q_t\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(M\)</span>, the number of distinct observation symbols per state, i.e., the
discrete alphabet size. The observation symbols correspond to the physical
output of the system being modeled. For the coin toss experiments the
observation symbols were simply heads or tails; for the ball and urn model
they were the colors of the balls selected from the urns. We denote the
individual symbols as <span class="math notranslate nohighlight">\(V = \{v_1, v_2, \ldots, v_M\}\)</span>.</p></li>
<li><p>The state transition probability distribution <span class="math notranslate nohighlight">\(A = \{a_{ij}\}\)</span> where</p>
<div class="math notranslate nohighlight" id="equation-hmmeq7">
<span class="eqno">(7)<a class="headerlink" href="#equation-hmmeq7" title="公式的永久链接">¶</a></span>\[a_{ij} = P[q_{t+1} = S_j \mid q_t = S_i], \quad 1 \leq i, j \leq N.\]</div>
<p>For the special case where any state can reach any other state in a single
step, we have <span class="math notranslate nohighlight">\(a_{ij} &gt; 0\)</span> for all <span class="math notranslate nohighlight">\(i, j\)</span> . For other types of
HMMs, we would have <span class="math notranslate nohighlight">\(a_{ij} = 0\)</span> for one or more <span class="math notranslate nohighlight">\((i,j)\)</span> pairs.</p>
</li>
<li><p>The observation symbol probability distribution in state <span class="math notranslate nohighlight">\(j\)</span>,
<span class="math notranslate nohighlight">\(B = \{b_j(k)\}\)</span>, where</p>
<div class="math notranslate nohighlight" id="equation-hmmeq8">
<span class="eqno">(8)<a class="headerlink" href="#equation-hmmeq8" title="公式的永久链接">¶</a></span>\[b_j(k) = P[v_k \text{ at } t \mid q_t = S_j], \quad 1 \leq j \leq N, \quad 1 \leq k \leq M.\]</div>
</li>
<li><p>The initial state distribution <span class="math notranslate nohighlight">\(\pi = \{\pi_i\}\)</span> where</p>
<div class="math notranslate nohighlight" id="equation-hmmeq9">
<span class="eqno">(9)<a class="headerlink" href="#equation-hmmeq9" title="公式的永久链接">¶</a></span>\[\pi_i = P[q_1 = S_i], \quad 1 \leq i \leq N.\]</div>
</li>
</ol>
<p>Given appropriate values of <span class="math notranslate nohighlight">\(N, M, A, B\)</span>, and <span class="math notranslate nohighlight">\(\pi\)</span>, the HMM can be
used as a generator to give an observation sequence</p>
<div class="math notranslate nohighlight" id="equation-hmmeq10">
<span class="eqno">(10)<a class="headerlink" href="#equation-hmmeq10" title="公式的永久链接">¶</a></span>\[\mathcal{O} = O_1 O_2 \cdots O_T\]</div>
<p>(where each observation <span class="math notranslate nohighlight">\(O_t\)</span> is one of the symbols from <span class="math notranslate nohighlight">\(V\)</span>, and
<span class="math notranslate nohighlight">\(T\)</span> is the number of observations in the sequence) as follows:</p>
<ol class="arabic simple">
<li><p>Choose an initial state <span class="math notranslate nohighlight">\(q_1 = S_i\)</span> according to the initial state
distribution <span class="math notranslate nohighlight">\(\pi\)</span>.</p></li>
<li><p>Set <span class="math notranslate nohighlight">\(t = 1\)</span>.</p></li>
<li><p>Choose <span class="math notranslate nohighlight">\(O_t = v_k\)</span> according to the symbol probability distribution in
state <span class="math notranslate nohighlight">\(S_i\)</span>, i.e., <span class="math notranslate nohighlight">\(b_i(k)\)</span>.</p></li>
<li><p>Transit to a new state <span class="math notranslate nohighlight">\(q_{t+1} = S_j\)</span> according to the state
transition probability distribution for state <span class="math notranslate nohighlight">\(S_i\)</span>, i.e.,
<span class="math notranslate nohighlight">\(a_{ij}\)</span>.</p></li>
<li><p>Set <span class="math notranslate nohighlight">\(t = t + 1\)</span>; return to step 3 if <span class="math notranslate nohighlight">\(t &lt; T\)</span>; otherwise terminate
the procedure.</p></li>
</ol>
<p>The above procedure can be used as both a generator of observations, and as a
model for how a given observation sequence was generated by an appropriate HMM.</p>
<p>It can be seen from the above discussion that a complete specification of an HMM
requires specification of two model parameters (<span class="math notranslate nohighlight">\(N\)</span> and <span class="math notranslate nohighlight">\(M\)</span>),
specification of observation symbols, and the specification of the three
probability measures <span class="math notranslate nohighlight">\(A, B\)</span>, and <span class="math notranslate nohighlight">\(\pi\)</span> . For convenience, we use the
compact notation</p>
<div class="math notranslate nohighlight" id="equation-hmmeq11">
<span class="eqno">(11)<a class="headerlink" href="#equation-hmmeq11" title="公式的永久链接">¶</a></span>\[\lambda = (A, B, \pi)\]</div>
<p>to indicate the complete parameter set of the model.</p>
</section>
<section id="the-three-basic-problems-for-hmms">
<h3>The Three Basic Problems for HMMs <a class="footnote-reference brackets" href="#hmm5" id="id24">5</a><a class="headerlink" href="#the-three-basic-problems-for-hmms" title="永久链接至标题">¶</a></h3>
<p>Given the form of HMM of the previous section, there are three basic problems of
interest that must be solved for the model to be useful in real-world
applications. These problems are the following:</p>
<p><strong>Problem 1</strong>: Given the observation sequence <span class="math notranslate nohighlight">\(\mathcal{O} = O_1 O_2
\cdots O_T\)</span>, and a model <span class="math notranslate nohighlight">\(\lambda = (A, B, \pi)\)</span>, how do we efficiently
compute <span class="math notranslate nohighlight">\(P(\mathcal{O} \mid \lambda)\)</span>, the probability of the observation
sequence, given the model?</p>
<p><strong>Problem 2</strong>: Given the observation sequence <span class="math notranslate nohighlight">\(\mathcal{O} = O_1 O_2
\cdots O_T\)</span>, and the model <span class="math notranslate nohighlight">\(\lambda\)</span>, how do we choose a corresponding
state sequence <span class="math notranslate nohighlight">\(Q = q_1 q_2 \cdots q_T\)</span> which is optimal in some
meaningful sense (i.e., best “explains” the observations?)</p>
<p><strong>Problem 3</strong>: How do we adjust the model parameters <span class="math notranslate nohighlight">\(\lambda = (A, B,
\pi)\)</span> to maximize <span class="math notranslate nohighlight">\(P(\mathcal{O} \mid \lambda)\)</span>?</p>
<p>Problem 1 is the evaluation problem, namely given a model and a sequence of
observations, how do we compute the probability that the observed sequence was
produced by the model. We can also view the problem as one of scoring how well a
given model matches a given observation sequence. The latter viewpoint is
extremely useful. For example, if we consider the case in which we are trying to
choose among several competing models, the solution to Problem 1 allows us to
choose the model which best matches the observations.</p>
<p>Problem 2 is the one in which we attempt to uncover the hidden part of the
model, i.e., to find the “correct” state sequence. It should be clear that for
all but the case of degenerate models, there is no “correct” state sequence to
be found. Hence for practical situations, we usually use an optimality criterion
to solve this problem as best as possible. Unfortunately, as we will see, there
are several reasonable optimality criteria that can be imposed, and hence the
choice of criterion is a strong function of the intended use for the uncovered
state sequence. Typical uses might be to learn about the structure of the model,
to find optimal state sequences for continuous speech recognition, or to get
average statistics of individual states, etc.</p>
<p>Problem 3 is the one in which we attempt to optimize the model parameters so as
to best describe how a given observation sequence comes about. The observation
sequence used to adjust the model parameters is called a training sequence since
it is used to “train” the HMM. The training problem is the crucial one for most
applications of HMMs, since it allows us to optimally adapt model parameters to
observed training data-i.e., to create best models for real phenomena.</p>
<p>To fix ideas, consider the following simple isolated word speech recognizer. For
each word of a <span class="math notranslate nohighlight">\(W\)</span> word vocabulary, we want to design a separate
<span class="math notranslate nohighlight">\(N\)</span>-state HMM. We represent the speech signal of a given word as a time
sequence of coded spectral vectors. We assume that the coding is done using a
spectral codebook with <span class="math notranslate nohighlight">\(M\)</span> unique spectral vectors; hence each observation
is the index of the spectral vector closest (in some spectral sense) to the
original speech signal. Thus, for each vocabulary word, we have a training
sequence consisting of a number of repetitions of sequences of codebook indices
of the word (by one or more talkers). The first task is to build individual word
models. This task is done by using the solution to Problem 3 to optimally
estimate model parameters for each word model. To develop an understanding of
the physical meaning of the model states, we use the solution to Problem 2 to
segment each of the word training sequences into states, and then study the
properties of the spectral vectors that lead to the observations occurring in
each state. The goal here would be to make refinements on the model (e.g., more
states, different codebook size, etc.) so as to improve its capability of
modeling the spoken word sequences. Finally, once the set of <span class="math notranslate nohighlight">\(W\)</span> HMMs has
been designed and optimized and thoroughly studied, recognition of an unknown
word is performed using the solution to Problem 1 to score each word model based
upon the given test observation sequence, and select the word whose model score
is highest (i.e., the highest likelihood).</p>
<p>In the next section we present formal mathematical solutions to each of the
three fundamental problems for HMMs. We shall see that the three problems are
linked together tightly under our probabilistic framework.</p>
</section>
</section>
<section id="solutions-to-the-three-basic-problems-of-hmms">
<h2>SOLUTIONS TO THE THREE BASIC PROBLEMS OF HMMs<a class="headerlink" href="#solutions-to-the-three-basic-problems-of-hmms" title="永久链接至标题">¶</a></h2>
<section id="solution-to-problem-1">
<h3>Solution to Problem 1<a class="headerlink" href="#solution-to-problem-1" title="永久链接至标题">¶</a></h3>
<p>We wish to calculate the probability of the observation sequence,
<span class="math notranslate nohighlight">\(\mathcal{O} = O_1 O_2 \cdots O_T\)</span>, given the model <span class="math notranslate nohighlight">\(\lambda\)</span>, i.e.,
<span class="math notranslate nohighlight">\(P(\mathcal{O} \mid \lambda)\)</span>. The most straightforward way of doing this
is through enumerating every possible state sequence of length <span class="math notranslate nohighlight">\(T\)</span> (the
number of observations). Consider one such fixed state sequence</p>
<div class="math notranslate nohighlight" id="equation-hmmeq12">
<span class="eqno">(12)<a class="headerlink" href="#equation-hmmeq12" title="公式的永久链接">¶</a></span>\[Q = q_1 q_2 \cdots q_T\]</div>
<p>where <span class="math notranslate nohighlight">\(q_1\)</span> is the initial state. The probability of the observation
sequence <span class="math notranslate nohighlight">\(\mathcal{O}\)</span> for the state sequence of <a class="reference internal" href="#equation-hmmeq12">(12)</a> is</p>
<div class="math notranslate nohighlight" id="equation-hmmeq13a">
<span class="eqno">(13)<a class="headerlink" href="#equation-hmmeq13a" title="公式的永久链接">¶</a></span>\[P(\mathcal{O} \mid Q, \lambda) = \prod_{t = 1}^T P(O_t \mid q_t, \lambda)\]</div>
<p>where we have assumed statistical indepencence of observations. Thus we get</p>
<div class="math notranslate nohighlight" id="equation-hmmeq13b">
<span class="eqno">(14)<a class="headerlink" href="#equation-hmmeq13b" title="公式的永久链接">¶</a></span>\[P(\mathcal{O} \mid Q, \lambda) = b_{q_1}(O_1) \cdot b_{q_2}(O_2) \cdots b_{q_T}(O_T).\]</div>
<p>The probability of such a state sequence <span class="math notranslate nohighlight">\(Q\)</span> can be written as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq14">
<span class="eqno">(15)<a class="headerlink" href="#equation-hmmeq14" title="公式的永久链接">¶</a></span>\[P(Q \mid \lambda) = \pi_{q_1} a_{q_1 q_2} a_{q_2 q_3} \cdots a_{q_{T-1} q_T}.\]</div>
<p>The joint probability of <span class="math notranslate nohighlight">\(\mathcal{O}\)</span> and <span class="math notranslate nohighlight">\(Q\)</span>, i.e., the
probability that <span class="math notranslate nohighlight">\(\mathcal{O}\)</span> and <span class="math notranslate nohighlight">\(Q\)</span> occur simultaneously, is
simply the product of the above two terms, i.e.,</p>
<div class="math notranslate nohighlight" id="equation-hmmeq15">
<span class="eqno">(16)<a class="headerlink" href="#equation-hmmeq15" title="公式的永久链接">¶</a></span>\[P(\mathcal{O}, Q \mid \lambda) = P(\mathcal{O} \mid Q, \lambda) P(Q \mid \lambda).\]</div>
<p>The probability of <span class="math notranslate nohighlight">\(\mathcal{O}\)</span> (given the model) is obtained by summing
this joint probability over all possible state sequences <span class="math notranslate nohighlight">\(Q\)</span> giving</p>
<div class="math notranslate nohighlight" id="equation-hmmeq17">
<span class="eqno">(17)<a class="headerlink" href="#equation-hmmeq17" title="公式的永久链接">¶</a></span>\[\begin{split}P(\mathcal{O} \mid \lambda) &amp; = \sum_{\text{all } Q} P(\mathcal{O} \mid Q, \lambda) P(Q \mid \lambda) \\
&amp; = \sum_{q_1, q_2, \ldots, q_T} \pi_{q_1} b_{q_1}(O_1) a_{q_1 q_2} b_{q_2}(O_2) \cdots a_{q_{T-1} q_T} b_{q_T}(O_T).\end{split}\]</div>
<p>The interpretation of the computation in the above equation is the following.
Initially (at time <span class="math notranslate nohighlight">\(t = 1\)</span>) we are in state <span class="math notranslate nohighlight">\(q_1\)</span> with probability
<span class="math notranslate nohighlight">\(\pi_{q_1}\)</span>, and generate the symbol <span class="math notranslate nohighlight">\(O_1\)</span> (in this state) with
probability <span class="math notranslate nohighlight">\(b_{q_1}(O_1)\)</span>. The clock changes from time <span class="math notranslate nohighlight">\(t\)</span> to
<span class="math notranslate nohighlight">\(t+1\)</span> (<span class="math notranslate nohighlight">\(t = 2\)</span>) and we make a transition to state <span class="math notranslate nohighlight">\(q_2\)</span> from
state <span class="math notranslate nohighlight">\(q_1\)</span> with probability <span class="math notranslate nohighlight">\(a_{q_1 q_2}\)</span>, and generate symbol
<span class="math notranslate nohighlight">\(O_2\)</span> with probability <span class="math notranslate nohighlight">\(b_{q_2}(O_2)\)</span>. This process continues in
this manner until we make the list transition (at time <span class="math notranslate nohighlight">\(T\)</span>) from state
<span class="math notranslate nohighlight">\(q_{T-1}\)</span> to state <span class="math notranslate nohighlight">\(q_T\)</span> with probability <span class="math notranslate nohighlight">\(a_{q_{T-1} q_T}\)</span>
and generate symbol <span class="math notranslate nohighlight">\(O_T\)</span> with probability <span class="math notranslate nohighlight">\(b_{q_T}(O_T)\)</span>.</p>
<p>A little thought should convince the reader that the calculation of
<span class="math notranslate nohighlight">\(P(\mathcal{O} \mid \lambda)\)</span>, according to its direct definition
<a class="reference internal" href="#equation-hmmeq17">(17)</a> involves on the order of <span class="math notranslate nohighlight">\(2 T \cdot N^T\)</span> calculations, since
at every <span class="math notranslate nohighlight">\(t = 1, 2, \ldots, T\)</span>, there are <span class="math notranslate nohighlight">\(N\)</span> possible states which
can be reached (i.e., there are <span class="math notranslate nohighlight">\(N^T\)</span> possible state sequences), and for
each such state sequence about <span class="math notranslate nohighlight">\(2T\)</span> calculations are required for each
term in the sum of <a class="reference internal" href="#equation-hmmeq17">(17)</a>. (To be precise, we need <span class="math notranslate nohighlight">\((2T-1)N^T\)</span>
multiplications, and <span class="math notranslate nohighlight">\(N^T-1\)</span> additions.) This calculation is
computationally unfeasible, even for small values of <span class="math notranslate nohighlight">\(N\)</span> and <span class="math notranslate nohighlight">\(T\)</span>;
e.g., for <span class="math notranslate nohighlight">\(N = 5\)</span> (states), <span class="math notranslate nohighlight">\(T = 100\)</span> (observations), there are on
the order of <span class="math notranslate nohighlight">\(2 \cdot 100 \cdot 5^{100} \approx 10^{72}\)</span> computations!
Clearly a more efficient procedure is required to solve Problem 1. Fortunately
such a procedure exists and is called the forward-backward procedure.</p>
<p><strong>The Forward-Backward Procedure</strong> <a class="footnote-reference brackets" href="#hmm6" id="id25">6</a> <a class="reference internal" href="#ref2" id="id26"><span>[Ref2]</span></a>, <a class="reference internal" href="#ref3" id="id27"><span>[Ref3]</span></a>: Consider the
forward variable <span class="math notranslate nohighlight">\(\alpha_t(i)\)</span> defined as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq18">
<span class="eqno">(18)<a class="headerlink" href="#equation-hmmeq18" title="公式的永久链接">¶</a></span>\[\alpha_t(i) = P(O_1 O_2 \cdots O_t, q_t = S_i \mid \lambda)\]</div>
<p>i.e., the probability of the partial observation sequence, <span class="math notranslate nohighlight">\(O_1 O_2 \cdots
O_t\)</span>, (until time <span class="math notranslate nohighlight">\(t\)</span>) and state <span class="math notranslate nohighlight">\(S_i\)</span> at time <span class="math notranslate nohighlight">\(t\)</span>, given the
model <span class="math notranslate nohighlight">\(\lambda\)</span>. We can solve for <span class="math notranslate nohighlight">\(\alpha_t(i)\)</span> inductively, as
follows:</p>
<ol class="arabic">
<li><p>Initialization:</p>
<div class="math notranslate nohighlight" id="equation-hmmeq19">
<span class="eqno">(19)<a class="headerlink" href="#equation-hmmeq19" title="公式的永久链接">¶</a></span>\[\alpha_1(i) = \pi_i b_i(O_1), \quad 1 \leq i \leq N.\]</div>
</li>
<li><p>Induction:</p>
<div class="math notranslate nohighlight" id="equation-hmmeq20">
<span class="eqno">(20)<a class="headerlink" href="#equation-hmmeq20" title="公式的永久链接">¶</a></span>\[\alpha_{t+1}(j) = \left[ \sum_{i = 1}^N \alpha_t(i) a_{ij} \right] b_j(O_{t+1}), \quad 1 \leq t \leq T - 1, \quad 1 \leq j \leq N.\]</div>
</li>
<li><p>Termination:</p>
<div class="math notranslate nohighlight" id="equation-hmmeq21">
<span class="eqno">(21)<a class="headerlink" href="#equation-hmmeq21" title="公式的永久链接">¶</a></span>\[P(\mathcal{O} \mid \lambda) = \sum_{i = 1}^N \alpha_{T}(i).\]</div>
</li>
</ol>
<p>Step 1) initializes the forward probabilities as the joint probability of state
<span class="math notranslate nohighlight">\(S_i\)</span> and initial observation <span class="math notranslate nohighlight">\(O_1\)</span>. The induction step, which is
the heart of the forward calculation, is illustrated in <a class="reference internal" href="#hmmfig4"><span class="std std-numref">图 4</span></a>. This
figure shows how state <span class="math notranslate nohighlight">\(S_j\)</span> can be reached at time <span class="math notranslate nohighlight">\(t + 1\)</span> from the
<span class="math notranslate nohighlight">\(N\)</span> possible states, <span class="math notranslate nohighlight">\(S_i, 1 \leq i \leq N\)</span>, at time <span class="math notranslate nohighlight">\(t\)</span>.
Since <span class="math notranslate nohighlight">\(\alpha_t(i)\)</span> is the probability of the joint event that <span class="math notranslate nohighlight">\(O_1
O_2 \cdots O_t\)</span> are observed, and the state at time <span class="math notranslate nohighlight">\(t\)</span> is <span class="math notranslate nohighlight">\(S_i\)</span>,
the product <span class="math notranslate nohighlight">\(\alpha_t(i) a_{ij}\)</span> is then the probability of the joint
event that <span class="math notranslate nohighlight">\(O_1 O_2 \cdots O_t\)</span> are observed, and state <span class="math notranslate nohighlight">\(S_j\)</span> is
reached at time <span class="math notranslate nohighlight">\(t + 1\)</span> via state <span class="math notranslate nohighlight">\(S_i\)</span> at time <span class="math notranslate nohighlight">\(t\)</span>. Summing
this product over all the <span class="math notranslate nohighlight">\(N\)</span> possible states <span class="math notranslate nohighlight">\(S_i, 1 \leq i \leq N\)</span>
at time <span class="math notranslate nohighlight">\(t\)</span> results in the probability of <span class="math notranslate nohighlight">\(S_j\)</span> at time <span class="math notranslate nohighlight">\(t +
1\)</span> with all the accompanying previous partial observations. Once this is done
and <span class="math notranslate nohighlight">\(S_j\)</span> is known, it is easy to see that <span class="math notranslate nohighlight">\(\alpha_{t+1}(j)\)</span> is
obtained by accounting for quantity by the probability <span class="math notranslate nohighlight">\(b_j(O_{t+1})\)</span>. The
computation of <a class="reference internal" href="#equation-hmmeq20">(20)</a> is performed for all states <span class="math notranslate nohighlight">\(j, 1 \leq j \leq
N\)</span>, for a given <span class="math notranslate nohighlight">\(t\)</span>; the computation is then iterated for <span class="math notranslate nohighlight">\(t = 1, 2,
\ldots, T - 1\)</span>. Finally, step 3) gives the desired calculation of
<span class="math notranslate nohighlight">\(P(\mathcal{O} \mid \lambda)\)</span> as the sum of the terminal forward variables
<span class="math notranslate nohighlight">\(\alpha_T(i)\)</span>. This is the case since, by definition,</p>
<div class="math notranslate nohighlight" id="equation-hmmeq22">
<span class="eqno">(22)<a class="headerlink" href="#equation-hmmeq22" title="公式的永久链接">¶</a></span>\[\alpha_T(i) = P(O_1 O_2 \cdots O_T, q_T = S_i \mid \lambda)\]</div>
<p>and hence <span class="math notranslate nohighlight">\(P(\mathcal{O} \mid \lambda)\)</span> is just the sum of the
<span class="math notranslate nohighlight">\(\alpha_T(i)\)</span>’s.</p>
<figure class="align-center" id="id105">
<span id="hmmfig4"></span><img alt="_images/hmmfig4.png" src="_images/hmmfig4.png" />
<figcaption>
<p><span class="caption-number">图 4 </span><span class="caption-text">(a) Illustration of the sequence of operations required for the computation
of the forward variable <span class="math notranslate nohighlight">\(\alpha_{t+1}(j)\)</span>. (b) Implementation of the
computation of <span class="math notranslate nohighlight">\(\alpha_{t}(j)\)</span> in terms of a lattice of observations
<span class="math notranslate nohighlight">\(t\)</span>, and states <span class="math notranslate nohighlight">\(i\)</span>.</span><a class="headerlink" href="#id105" title="永久链接至图片">¶</a></p>
</figcaption>
</figure>
<p>If we examine the computation involved in the calculation of
<span class="math notranslate nohighlight">\(\alpha_t(j)\)</span>, <span class="math notranslate nohighlight">\(1 \leq t \leq T\)</span>, <span class="math notranslate nohighlight">\(1 \leq j \leq N\)</span>, we see
that it requires on the order of <span class="math notranslate nohighlight">\(N^2 T\)</span> calculations, rather than
<span class="math notranslate nohighlight">\(2 T N^T\)</span> as required by the direct calculation. (Again, to be precise, we
need <span class="math notranslate nohighlight">\(N(N+1)(T-1) + N\)</span> multiplications and <span class="math notranslate nohighlight">\(N(N-1)(T-1)\)</span> additions.)
For <span class="math notranslate nohighlight">\(N = 5\)</span>, <span class="math notranslate nohighlight">\(T = 100\)</span>, we need about <span class="math notranslate nohighlight">\(3000\)</span> computations for
the forward method, versus <span class="math notranslate nohighlight">\(10^{72}\)</span> computations for the direct
calculation, a savings of about <span class="math notranslate nohighlight">\(69\)</span> orders of magnitude.</p>
<p>The forward probability calculation is, in effect, based upon the lattice (or
trellis) structure shown in <a class="reference internal" href="#hmmfig4"><span class="std std-numref">图 4</span></a> (b). The key is that since there
are only <span class="math notranslate nohighlight">\(N\)</span> states (nodes at each time slot in the lattice), all the
possible state sequences will re-merge into these <span class="math notranslate nohighlight">\(N\)</span> nodes, no matter how
long the observation sequence. At time <span class="math notranslate nohighlight">\(t = 1\)</span> (the first time slot in the
lattice), we need to calculate values of <span class="math notranslate nohighlight">\(\alpha_1(i)\)</span>, <span class="math notranslate nohighlight">\(1 \leq i
\leq N\)</span>. At times <span class="math notranslate nohighlight">\(t = 2, 3, \ldots, T\)</span>, we only need to calculate values
of <span class="math notranslate nohighlight">\(\alpha_t(j)\)</span>, <span class="math notranslate nohighlight">\(1 \leq j \leq N\)</span>, where each calculation involves
only <span class="math notranslate nohighlight">\(N\)</span> previous values of <span class="math notranslate nohighlight">\(\alpha_{t-1}(i)\)</span> because each of the
<span class="math notranslate nohighlight">\(N\)</span> grid points is reached from the same <span class="math notranslate nohighlight">\(N\)</span> grid points at the
previous time slot.</p>
<p>In a similar manner <a class="footnote-reference brackets" href="#hmm7" id="id28">7</a>, we can consider a backward variable
<span class="math notranslate nohighlight">\(\beta_t(i)\)</span> defined as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq23">
<span class="eqno">(23)<a class="headerlink" href="#equation-hmmeq23" title="公式的永久链接">¶</a></span>\[\beta_t(i) = P(O_{t+1} O_{t+2} \cdots O_T \mid q_t = S_i, \lambda)\]</div>
<p>i.e., the probability of the partial observation sequence from <span class="math notranslate nohighlight">\(t + 1\)</span> to
the end, given state <span class="math notranslate nohighlight">\(S_i\)</span> at time <span class="math notranslate nohighlight">\(t\)</span> and the model
<span class="math notranslate nohighlight">\(\lambda\)</span>. Again we can solve for <span class="math notranslate nohighlight">\(\beta_t(i)\)</span> inductively, as
follows:</p>
<ol class="arabic">
<li><p>Initialization:</p>
<div class="math notranslate nohighlight" id="equation-hmmeq24">
<span class="eqno">(24)<a class="headerlink" href="#equation-hmmeq24" title="公式的永久链接">¶</a></span>\[\beta_T(i) = 1, \quad 1 \leq i \leq N.\]</div>
</li>
<li><p>Induction:</p>
<div class="math notranslate nohighlight" id="equation-hmmeq25">
<span class="eqno">(25)<a class="headerlink" href="#equation-hmmeq25" title="公式的永久链接">¶</a></span>\[\beta_t(i) = \sum_{j = 1}^N a_{ij} b_j(O_{t+1}) \beta_{t+1}(j), \quad t = T-1, T-2, \cdots, 1, \quad 1 \leq i \leq N.\]</div>
</li>
</ol>
<p>The initialization step 1) arbitrarily defines <span class="math notranslate nohighlight">\(\beta_T(i)\)</span> to be
<span class="math notranslate nohighlight">\(1\)</span> for all <span class="math notranslate nohighlight">\(i\)</span>. Step 2), which is illustrated in <a class="reference internal" href="#hmmfig5"><span class="std std-numref">图 5</span></a>,
shows that in order to have been in state <span class="math notranslate nohighlight">\(S_i\)</span> at time <span class="math notranslate nohighlight">\(t\)</span>, and to
account for the observation sequence from time <span class="math notranslate nohighlight">\(t + 1\)</span> on, you have to
consider all possible states <span class="math notranslate nohighlight">\(S_j\)</span> at time <span class="math notranslate nohighlight">\(t + 1\)</span>, accounting for
the transition from <span class="math notranslate nohighlight">\(S_i\)</span> to <span class="math notranslate nohighlight">\(S_j\)</span> (the <span class="math notranslate nohighlight">\(a_{ij}\)</span> term), and
then account for the remaining partial observation sequence from state <span class="math notranslate nohighlight">\(j\)</span>
(the <span class="math notranslate nohighlight">\(\beta_{t+1}(j)\)</span> term). We will see later how the backward, as well
as the forward calculations are used extensively to help solve fundamental
Problems 2 and 3 of HMMs.</p>
<figure class="align-center" id="id106">
<span id="hmmfig5"></span><img alt="_images/hmmfig5.png" src="_images/hmmfig5.png" />
<figcaption>
<p><span class="caption-number">图 5 </span><span class="caption-text">Illustration of the sequence of operations required for the computation of
the backward variable <span class="math notranslate nohighlight">\(\beta_t(i)\)</span>.</span><a class="headerlink" href="#id106" title="永久链接至图片">¶</a></p>
</figcaption>
</figure>
<p>Again, the computation of <span class="math notranslate nohighlight">\(\beta_t(i)\)</span>, <span class="math notranslate nohighlight">\(1 \leq t \leq T\)</span>, <span class="math notranslate nohighlight">\(1
\leq i \leq N\)</span>, requires on the order of <span class="math notranslate nohighlight">\(N^2 T\)</span> calculations, and can be
computed in a lattice structure similar to that of <a class="reference internal" href="#hmmfig4"><span class="std std-numref">图 4</span></a> (b).</p>
</section>
<section id="solution-to-problem-2">
<h3>Solution to Problem 2<a class="headerlink" href="#solution-to-problem-2" title="永久链接至标题">¶</a></h3>
<p>Unlike Problem 1 for which an exact solution can be given, there are several
possible ways of solving Problem 2, namely finding the “optimal” state sequence
associated with the given observation sequence. The difficulty lies with the
definition of the optimal state sequence; i.e., there are several possible
optimality criteria. For example, one possible optimality criterion is to choose
the states <span class="math notranslate nohighlight">\(q_t\)</span>, which are individually most likely. This optimality
criterion maximizes the expected number of correct individual states. To
implement this solution to Problem 2, we define the variable</p>
<div class="math notranslate nohighlight" id="equation-hmmeq26">
<span class="eqno">(26)<a class="headerlink" href="#equation-hmmeq26" title="公式的永久链接">¶</a></span>\[\gamma_t(i) = P(q_t = S_i \mid \mathcal{O}, \lambda)\]</div>
<p>i.e., the probability of being in state <span class="math notranslate nohighlight">\(S_i\)</span> at time <span class="math notranslate nohighlight">\(t\)</span>, given the
observation sequence <span class="math notranslate nohighlight">\(\mathcal{O}\)</span>, and the model <span class="math notranslate nohighlight">\(\lambda\)</span>.
Equation <a class="reference internal" href="#equation-hmmeq26">(26)</a> can be expressed simply in terms of the forward-backward
variables, i.e.,</p>
<div class="math notranslate nohighlight" id="equation-hmmeq27">
<span class="eqno">(27)<a class="headerlink" href="#equation-hmmeq27" title="公式的永久链接">¶</a></span>\[\gamma_t(i) = \dfrac{\alpha_t(i) \beta_t(i)}{P(\mathcal{O} \mid \lambda)}
= \dfrac{\alpha_t(i) \beta_t(i)}{\sum_{i=1}^N \alpha_t(i) \beta_t(i)}\]</div>
<p>since <span class="math notranslate nohighlight">\(\alpha_t(i)\)</span> accounts for the partial observation sequence
<span class="math notranslate nohighlight">\(O_1 O_2 \cdots O_t\)</span> and state <span class="math notranslate nohighlight">\(S_i\)</span> at <span class="math notranslate nohighlight">\(t\)</span>, while
<span class="math notranslate nohighlight">\(\beta_t(i)\)</span> accounts for the remainder of the observation sequence
<span class="math notranslate nohighlight">\(O_{t+1} O_{t+2} \cdots O_T\)</span>, given state <span class="math notranslate nohighlight">\(S_i\)</span> at <span class="math notranslate nohighlight">\(t\)</span>. The
normalization factor <span class="math notranslate nohighlight">\(P(\mathcal{O} \mid \lambda) = \sum_{i=1}^N
\alpha_t(i)\)</span>, <span class="math notranslate nohighlight">\(\beta_t(i)\)</span> makes <span class="math notranslate nohighlight">\(\gamma_t(i)\)</span> a probability measure
so that</p>
<div class="math notranslate nohighlight" id="equation-hmmeq28">
<span class="eqno">(28)<a class="headerlink" href="#equation-hmmeq28" title="公式的永久链接">¶</a></span>\[\sum_{i = 1}^N \gamma_t(i) = 1.\]</div>
<p>Using <span class="math notranslate nohighlight">\(\gamma_t(i)\)</span>, we can solve for the individually most likey state
<span class="math notranslate nohighlight">\(q_t\)</span> at time <span class="math notranslate nohighlight">\(t\)</span>, as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq29">
<span class="eqno">(29)<a class="headerlink" href="#equation-hmmeq29" title="公式的永久链接">¶</a></span>\[q_t = \mathrm{argmax}_{1 \leq i \leq N} [\gamma_t(i)], \quad 1 \leq t \leq T.\]</div>
<p>Although <a class="reference internal" href="#equation-hmmeq29">(29)</a> maximizes the expected number of correct states (by
choosing the most likely state for each <span class="math notranslate nohighlight">\(t\)</span>), there could be some problems
with the resulting state sequence. For example, when the HMM has state
transitions which have zero probability (<span class="math notranslate nohighlight">\(a_{ij} = 0\)</span> for some <span class="math notranslate nohighlight">\(i\)</span>
and <span class="math notranslate nohighlight">\(j\)</span>), the “optimal” state sequence may, in fact, not even be a valid
state sequence. This is due to the fact that the solution of <a class="reference internal" href="#equation-hmmeq29">(29)</a>
simply determines the most likely state at every instant, without regard to the
probability of occurrence of sequences of states.</p>
<p>One possible solution to the above problem is to modify the optimality
criterion. For example, one could solve for the state sequence that maximizes
the expected number of correct pairs of states <span class="math notranslate nohighlight">\((q_t, q_{t + 1})\)</span>, or
triples of states <span class="math notranslate nohighlight">\((q_t, q_{t + 1}, q_{t+2})\)</span>, etc. Although these
criteria might be reasonable for some applications, the most widely used
criterion is to find the single best state sequence (path), i.e., to maximize
<span class="math notranslate nohighlight">\(P(Q \mid \mathcal{O}, \lambda)\)</span> which is equivalent to maximizing
<span class="math notranslate nohighlight">\(P(Q, \mathcal{O} \mid \lambda)\)</span>. A formal technique for finding this
single best state sequence exists, based on dynamic programming methods, and is
called the Viterbi algorithm.</p>
<p><strong>Viterbi Algorithm</strong> <a class="reference internal" href="#ref21" id="id29"><span>[Ref21]</span></a>, <a class="reference internal" href="#ref22" id="id30"><span>[Ref22]</span></a>: To find the single best state
sequence, <span class="math notranslate nohighlight">\(Q = \{q_1 q_2 \cdots q_T\}\)</span>, for the given observation sequence
<span class="math notranslate nohighlight">\(O = \{O_1 O_2 \cdots O_T\}\)</span>, we need to define the quantity</p>
<div class="math notranslate nohighlight" id="equation-hmmeq30">
<span class="eqno">(30)<a class="headerlink" href="#equation-hmmeq30" title="公式的永久链接">¶</a></span>\[\delta_t(i) = \mathrm{max}_{q_1, q_2, \ldots, q_{t-1}} P[q_1 q_2 \cdots q_t = i, O_1 O_2 \cdots O_t \mid \lambda]\]</div>
<p>i.e., <span class="math notranslate nohighlight">\(\delta_t(i)\)</span> is the best score (highest probability) along a single
path, at time <span class="math notranslate nohighlight">\(t\)</span>, which accounts for the first <span class="math notranslate nohighlight">\(t\)</span> observations and
ends in state <span class="math notranslate nohighlight">\(S_i\)</span>. By induction we have</p>
<div class="math notranslate nohighlight" id="equation-hmmeq31">
<span class="eqno">(31)<a class="headerlink" href="#equation-hmmeq31" title="公式的永久链接">¶</a></span>\[\delta_{t+1}(j) = [\mathrm{max}_i \delta_t(i) a_{ij} \cdot b_j(O_{t+1})].\]</div>
<p>To actually retrieve the state sequence, we need to keep track of the argument
which maximized <a class="reference internal" href="#equation-hmmeq31">(31)</a>, for each <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(j\)</span>. We do this via
the array <span class="math notranslate nohighlight">\(\psi_t(j)\)</span>. The complete procedure for finding the best state
sequence can now be stated as follows:</p>
<ol class="arabic">
<li><p>Initialization:</p>
<div class="math notranslate nohighlight" id="equation-hmmeq32">
<span class="eqno">(32)<a class="headerlink" href="#equation-hmmeq32" title="公式的永久链接">¶</a></span>\[\begin{split}\delta_1(i) &amp; = \pi b_i(O_1), \quad 1 \leq i \leq N \\
\psi_1(i) &amp; = 0\end{split}\]</div>
</li>
<li><p>Recursion:</p>
<div class="math notranslate nohighlight" id="equation-hmmeq33">
<span class="eqno">(33)<a class="headerlink" href="#equation-hmmeq33" title="公式的永久链接">¶</a></span>\[\begin{split}\delta_t(j) &amp; = \mathrm{max}_{1 \leq i \leq N} [\delta_{t-1}(i) a_{ij}] b_j(O_t), \quad 2 \leq t \leq T, \quad 1 \leq j \leq N \\
\psi_t(j) &amp; = \mathrm{argmax}_{1 \leq i \leq N} [\delta_{t-1}(i) a_{ij}], \quad 2 \leq t \leq T, \quad 1 \leq j \leq N.\end{split}\]</div>
</li>
<li><p>Termination:</p>
<div class="math notranslate nohighlight" id="equation-hmmeq34">
<span class="eqno">(34)<a class="headerlink" href="#equation-hmmeq34" title="公式的永久链接">¶</a></span>\[\begin{split}P^* &amp; = \mathrm{max}_{1 \leq i \leq N} [\delta_T(i)] \\
q_T^* &amp; = \mathrm{argmax}_{1 \leq i \leq N} [\delta_T(i)].\end{split}\]</div>
</li>
<li><p>Path (state sequence) backtracking:</p></li>
</ol>
<div class="math notranslate nohighlight" id="equation-hmmeq35">
<span class="eqno">(35)<a class="headerlink" href="#equation-hmmeq35" title="公式的永久链接">¶</a></span>\[q_t^* = \psi_{t + 1}(q_{t+1}^*), \quad t = T-1, T-2, \ldots, 1.\]</div>
<p>It should be noted that the Viterbi algorithm is similar (except for the
backtracking step) in implementation to the forward calculation of <a class="reference internal" href="#equation-hmmeq19">(19)</a>
<a class="reference internal" href="#equation-hmmeq20">(20)</a> <a class="reference internal" href="#equation-hmmeq21">(21)</a>. The major difference is the maximization in
<a class="reference internal" href="#equation-hmmeq33">(33)</a> (a) over previous states which is used in place of the summing
procedure in <a class="reference internal" href="#equation-hmmeq20">(20)</a>. It also should be clear that a lattice (or trellis)
structure efficiently implements the computation of the Viterbi procedure.</p>
</section>
<section id="solution-to-problem-3-ref1-ref5">
<h3>Solution to Problem 3 <a class="reference internal" href="#ref1" id="id31"><span>[Ref1]</span></a> - <a class="reference internal" href="#ref5" id="id32"><span>[Ref5]</span></a><a class="headerlink" href="#solution-to-problem-3-ref1-ref5" title="永久链接至标题">¶</a></h3>
<p>The third, and by far the most difficult, problem of HMMs is to determine a
method to adjust the model parameters <span class="math notranslate nohighlight">\((A, B, \pi)\)</span> to maximize the
probability of the observation sequence given the model. There is no known way
to analytically solve for the model which maximizes the probability of the
observation sequence. In fact, given any finite observation sequence as training
data, there is no optimal way of estimating the model parameters. We can,
however, choose <span class="math notranslate nohighlight">\(\lambda = (A, B, \pi)\)</span> such that <span class="math notranslate nohighlight">\(P(\mathcal{O}
\mid \lambda)\)</span> is locally maximized using an iterative procedure such as the
Baum-Welch method (or equivalently the EM (expectation-modification) method
<a class="reference internal" href="#ref23" id="id33"><span>[Ref23]</span></a>), or using gradient techniques <a class="reference internal" href="#ref14" id="id34"><span>[Ref14]</span></a>. In this section we discuss one
iterative procedure, based primarily on the classic work of Baum and his
colleagues, for choosing model parameters.</p>
<figure class="align-center" id="id107">
<span id="hmmfig6"></span><img alt="_images/hmmfig6.png" src="_images/hmmfig6.png" />
<figcaption>
<p><span class="caption-number">图 6 </span><span class="caption-text">Illustration of the sequence of operations required for the computation of
the joint event that the system is in state <span class="math notranslate nohighlight">\(S_i\)</span>, at time <span class="math notranslate nohighlight">\(t\)</span>
and state <span class="math notranslate nohighlight">\(S_j\)</span>, at time <span class="math notranslate nohighlight">\(t + 1\)</span>.</span><a class="headerlink" href="#id107" title="永久链接至图片">¶</a></p>
</figcaption>
</figure>
<p>In order to describe the procedure for reestimation (iterative update and
improvement) of HMM parameters, we first define <span class="math notranslate nohighlight">\(\xi_t(i, j)\)</span>, the
probability of being in state <span class="math notranslate nohighlight">\(S_i\)</span> at time <span class="math notranslate nohighlight">\(t\)</span>, and state
<span class="math notranslate nohighlight">\(S_j\)</span>, at time <span class="math notranslate nohighlight">\(t+1\)</span>, given the model and the observation sequence,
i.e.</p>
<div class="math notranslate nohighlight" id="equation-hmmeq36">
<span class="eqno">(36)<a class="headerlink" href="#equation-hmmeq36" title="公式的永久链接">¶</a></span>\[\xi_t(i, j) = P(q_t = S_i, q_{t+1} = S_j \mid \mathcal{O}, \lambda).\]</div>
<p>The sequence of events leading to the conditions required by <a class="reference internal" href="#equation-hmmeq36">(36)</a> is
illustrated in <a class="reference internal" href="#hmmfig6"><span class="std std-numref">图 6</span></a>. It should be clear, from the definitions of
the forward and backward variables, that we can write <span class="math notranslate nohighlight">\(\xi_t(i, j)\)</span> in the
form</p>
<div class="math notranslate nohighlight" id="equation-hmmeq37">
<span class="eqno">(37)<a class="headerlink" href="#equation-hmmeq37" title="公式的永久链接">¶</a></span>\[\begin{split}\xi_t(i, j) &amp;= \dfrac{\alpha_t(i) a_{ij} b_j(O_{t+1}) \beta_{t+1}(j)}{P(\mathcal{O} \mid \lambda)} \\
&amp;= \dfrac{\alpha_t(i) a_{ij} b_j(O_{t+1}) \beta_{t+1}(j)}{\sum_{i = 1}^N \sum_{j = 1}^N \alpha_t(i) a_{ij} b_j(O_{t+1}) \beta_{t+1}(j)}\end{split}\]</div>
<p>where the numerator term is just <span class="math notranslate nohighlight">\(P(q_t = S_i, q_{t+1} = S_j, \mathcal{O}
\mid \lambda)\)</span> and division by <span class="math notranslate nohighlight">\(P(\mathcal{O} \mid \lambda)\)</span> gives the
desired probability measure.</p>
<p>We have previously defined <span class="math notranslate nohighlight">\(\gamma_t(i)\)</span> as the probability of being in
state <span class="math notranslate nohighlight">\(S_i\)</span> at time <span class="math notranslate nohighlight">\(t\)</span>, given the observation sequence and the
model; hence we can relate <span class="math notranslate nohighlight">\(\gamma_t(i)\)</span> to <span class="math notranslate nohighlight">\(\xi_t(i, j)\)</span> by summing
over <span class="math notranslate nohighlight">\(j\)</span>, giving</p>
<div class="math notranslate nohighlight" id="equation-hmmeq38">
<span class="eqno">(38)<a class="headerlink" href="#equation-hmmeq38" title="公式的永久链接">¶</a></span>\[\gamma_t(i) = \sum_{j = 1}^N \xi_t(i, j).\]</div>
<p>If we sum <span class="math notranslate nohighlight">\(\gamma_t(i)\)</span> over the time index <span class="math notranslate nohighlight">\(t\)</span>, we get a quantity which
can be interpreted as the expected (over time) number of
times that state <span class="math notranslate nohighlight">\(S_i\)</span> is visited, or equivalently, the expected
number of transitions made from state <span class="math notranslate nohighlight">\(S_i\)</span> (if we exclude the
time slot <span class="math notranslate nohighlight">\(t = T\)</span> from the summation). Similarly, summation
of <span class="math notranslate nohighlight">\(\xi_t(i, j)\)</span> over <span class="math notranslate nohighlight">\(t\)</span> (from <span class="math notranslate nohighlight">\(t = 1\)</span> to <span class="math notranslate nohighlight">\(t = T - 1\)</span>) can be interpreted
as the expected number of transitions from state <span class="math notranslate nohighlight">\(S_i\)</span> to state
<span class="math notranslate nohighlight">\(S_j\)</span>. That is</p>
<div class="math notranslate nohighlight" id="equation-hmmeq39">
<span class="eqno">(39)<a class="headerlink" href="#equation-hmmeq39" title="公式的永久链接">¶</a></span>\[\begin{split}\sum_{t = 1}^{T-1} \gamma_t(i) &amp;= \text{expected number of transitions from } S_i \\
\sum_{t = 1}^{T-1} \xi_t(i, j) &amp;= \text{expected number of transitions from } S_i \text{ to } S_j\end{split}\]</div>
<p>Using the above formulas (and the concept of counting event occurrences) we can
give a method for reestimation of the parameters of an HMM. A set of reasonable
reestimation formulas for <span class="math notranslate nohighlight">\(\pi\)</span>, <span class="math notranslate nohighlight">\(A\)</span>, and <span class="math notranslate nohighlight">\(B\)</span> are</p>
<div class="math notranslate nohighlight" id="equation-hmmeq40">
<span class="eqno">(40)<a class="headerlink" href="#equation-hmmeq40" title="公式的永久链接">¶</a></span>\[\begin{split}\bar{\pi}_i &amp;= \text{expected frequency (number of times) in state } S_i \text{ at time } (t = 1) = \gamma_1(i) \\
\bar{a}_{ij} &amp;= \dfrac{\text{expected number of transitions from state } S_i \text{ to state } S_j}{\text{expected number of transitions from state } S_i} \\
&amp;= \dfrac{\sum_{t=1}^{T-1} \xi_t(i, j)}{\sum_{t = 1}^{T-1} \gamma_t(i)} \\
\bar{b}_j(k) &amp;= \dfrac{\text{expected number of times in state } j \text{ and observing symbol } v_k}{\text{expected number of times in state } j} \\
&amp; = \dfrac{\sum_{t = 1, \text{ s.t. } O_t = v_k}^T \gamma_t(j)}{\sum_{t=1}^T \gamma_t(j)}.\end{split}\]</div>
<p>If we define the current model as <span class="math notranslate nohighlight">\(\lambda = (A, B, \pi)\)</span>, and use that to
compute the right-hand sides of <a class="reference internal" href="#equation-hmmeq40">(40)</a>, and we define the reestimated
model as <span class="math notranslate nohighlight">\(\bar{\lambda} = (\bar{A}, \bar{B}, \bar{\pi})\)</span>, as determined
from the left-hand sides of <a class="reference internal" href="#equation-hmmeq40">(40)</a>, then it has been proven by Baum and
his colleagues <a class="reference internal" href="#ref6" id="id35"><span>[Ref6]</span></a>, <a class="reference internal" href="#ref3" id="id36"><span>[Ref3]</span></a> that either 1) the initial model <span class="math notranslate nohighlight">\(\lambda\)</span>
defines a critical point of the likelihood function, in which case
<span class="math notranslate nohighlight">\(\bar{\lambda} = \lambda\)</span>; or 2) model <span class="math notranslate nohighlight">\(\bar{\lambda}\)</span> is more
likely than model <span class="math notranslate nohighlight">\(\lambda\)</span> in the sense that <span class="math notranslate nohighlight">\(P(\mathcal{O} \mid
\bar{\lambda}) &gt; P(\mathcal{O} \mid \lambda)\)</span>, i.e., we have found a new model
<span class="math notranslate nohighlight">\(\bar{\lambda}\)</span> from which the observation sequence is more likely to have
been produced.</p>
<p>Based on the above procedure, if we iteratively use <span class="math notranslate nohighlight">\(\bar{\lambda}\)</span> in
place of <span class="math notranslate nohighlight">\(\lambda\)</span> and repeat the reestimation calculation, we then can
improve the probability of <span class="math notranslate nohighlight">\(\mathcal{O}\)</span> being observed from the model
until some limiting point is reached. The final result of this reestimation
procedure is called a maximum likelihood estimate of the HMM. It should be
pointed out that the forward-backward algorithm leads to local maxima only, and
that in most problems of interest, the optimization surface is very complex and
has many local maxima.</p>
<p>The reestimation formulas of <a class="reference internal" href="#equation-hmmeq40">(40)</a> can be derived directly by maximizing
(using standard constrained optimization techniques) Baum’s auxiliary function</p>
<div class="math notranslate nohighlight" id="equation-hmmeq41">
<span class="eqno">(41)<a class="headerlink" href="#equation-hmmeq41" title="公式的永久链接">¶</a></span>\[Q(\lambda, \bar{\lambda}) = \sum_Q P(Q \mid \mathcal{O}, \lambda) \log [P(\mathcal{O}, Q \mid \bar{\lambda})]\]</div>
<p>over <span class="math notranslate nohighlight">\(\bar{\lambda}\)</span>. It has been proven by Baum and his colleagues
<a class="reference internal" href="#ref6" id="id37"><span>[Ref6]</span></a>, <a class="reference internal" href="#ref3" id="id38"><span>[Ref3]</span></a> that maximization of <span class="math notranslate nohighlight">\(Q(\lambda, \bar{\lambda})\)</span> leads to
increased likelihood, i.e.</p>
<div class="math notranslate nohighlight" id="equation-hmmeq42">
<span class="eqno">(42)<a class="headerlink" href="#equation-hmmeq42" title="公式的永久链接">¶</a></span>\[\mathrm{max}_{\bar{\lambda}} [Q(\lambda, \bar{\lambda})] \Rightarrow P(\mathcal{O} \mid \bar{\lambda}) \geq P(\mathcal{O} \mid \lambda).\]</div>
<p>Eventually the likelihood function converges to a critical point.</p>
<p><strong>Notes on the Reestimation Procedure</strong>: The reestimation formulas can readily
be interpreted as an implementation of the EM algorithm of statistics <a class="reference internal" href="#ref23" id="id39"><span>[Ref23]</span></a>
in which the E (expectation) step is the calculation of the auxiliary function
<span class="math notranslate nohighlight">\(Q(\lambda, \bar{\lambda})\)</span>, and the M (modification) step is the
maximization over <span class="math notranslate nohighlight">\(\bar{\lambda}\)</span>. Thus the Baum-Welch reestimation
equations are essentially identical to the EM steps for this particular problem.</p>
<p>An important aspect of the reestimation procedure is that
the stochastic constraints of the HMM parameters, namely</p>
<div class="math notranslate nohighlight" id="equation-hmmeq43">
<span class="eqno">(43)<a class="headerlink" href="#equation-hmmeq43" title="公式的永久链接">¶</a></span>\[\begin{split}\sum_{i = 1}^N \bar{\pi}_i &amp;= 1 \\
\sum_{j = 1}^N \bar{a}_{ij} &amp;= 1, \quad 1 \leq i \leq N \\
\sum_{k = 1}^M \bar{b}_j(k) &amp;= 1, \quad 1 \leq j \leq N\end{split}\]</div>
<p>are automatically satisfied at each iteration. By looking at the parameter
estimation problem as a constrained optimization of <span class="math notranslate nohighlight">\(P(\mathcal{O} \mid
\lambda)\)</span> (subject to the constraints of <a class="reference internal" href="#equation-hmmeq43">(43)</a>), the techniques of
Lagrange multipliers can be used to find the values of <span class="math notranslate nohighlight">\(\pi, a_{ij}\)</span> and
<span class="math notranslate nohighlight">\(b_j(k)\)</span> which maximize <span class="math notranslate nohighlight">\(P\)</span> (we use the notation <span class="math notranslate nohighlight">\(P =
P(\mathcal{O} \mid \lambda)\)</span> as short-hand in this section). Based on setting up
a standard Lagrange optimization using Lagrange multipliers, it can readily be
shown that <span class="math notranslate nohighlight">\(P\)</span> is maximized when the following conditions are met:</p>
<div class="math notranslate nohighlight" id="equation-hmmeq44">
<span class="eqno">(44)<a class="headerlink" href="#equation-hmmeq44" title="公式的永久链接">¶</a></span>\[\begin{split}\pi_i &amp;= \dfrac{\pi_i \dfrac{\partial P}{\partial \pi_i}}{\sum_{k = 1}^N \pi_k \dfrac{\partial P}{\partial \pi_k}} \\
a_{ij} &amp;= \dfrac{a_{ij} \dfrac{\partial P}{\partial a_{ij}}}{\sum_{k = 1}^N a_{ik} \dfrac{\partial P}{\partial a_{ik}}} \\
b_j(k) &amp;= \dfrac{b_j(k) \dfrac{\partial P}{\partial b_j(k)}}{\sum_{\ell = 1}^M b_j(\ell) \dfrac{\partial P}{\partial b_j(\ell)}}\end{split}\]</div>
<p>By appropriate manipulation of <a class="reference internal" href="#equation-hmmeq44">(44)</a>, the right-hand sides of each
equation can be readily converted to be identical to the right-hand sides of
each part of <a class="reference internal" href="#equation-hmmeq40">(40)</a>, thereby showing that the reestimation formulas are
indeed exactly correct at critical points of <span class="math notranslate nohighlight">\(P\)</span>. In fact the form of
<a class="reference internal" href="#equation-hmmeq44">(44)</a> is essentially that of a reestimation formula in which the
left-hand side is the reestimate and the right-hand side is computed using the
current values of the variables.</p>
<p>Finally, we note that since the entire problem can be set up as an optimization
problem, standard gradient techniques can be used to solve for “optimal” values
of the model parameters <a class="reference internal" href="#ref14" id="id40"><span>[Ref14]</span></a>. Such procedures have been tried and have been
shown to yield solutions comparable to those of the standard reestimation
procedures.</p>
</section>
</section>
<section id="types-of-hmms">
<h2>TYPES OF HMMs<a class="headerlink" href="#types-of-hmms" title="永久链接至标题">¶</a></h2>
<p>Until now, we have only considered the special case of ergodic or fully
connected HMMs in which every state of the model could be reached (in a single
step) from every other state of the model. (Strictly speaking, an ergodic model
has the property that every state can be reached from every other state in a
finite number of steps.) As shown in <a class="reference internal" href="#hmmfig7"><span class="std std-numref">图 7</span></a> (a), for an <span class="math notranslate nohighlight">\(N = 4\)</span>
state model, this type of model has the property that every <span class="math notranslate nohighlight">\(a_{ij}\)</span>
coefficient is positive. Hence for the example of <a class="reference internal" href="#hmmfig7"><span class="std std-numref">图 7</span></a> (a) we have</p>
<div class="math notranslate nohighlight">
\[\begin{split}A =
\begin{bmatrix}
a_{11} &amp; a_{12} &amp; a_{13} &amp; a_{14} \\
a_{21} &amp; a_{22} &amp; a_{23} &amp; a_{24} \\
a_{31} &amp; a_{32} &amp; a_{33} &amp; a_{34} \\
a_{41} &amp; a_{42} &amp; a_{43} &amp; a_{44}
\end{bmatrix}\end{split}\]</div>
<figure class="align-center" id="id108">
<span id="hmmfig7"></span><img alt="_images/hmmfig7.png" src="_images/hmmfig7.png" />
<figcaption>
<p><span class="caption-number">图 7 </span><span class="caption-text">Illustration of 3 distinct types of HMMs. (a) A 4-state ergodic model. (b) A
4-state left-right model. (c) A 6-state parallel path left-right model.</span><a class="headerlink" href="#id108" title="永久链接至图片">¶</a></p>
</figcaption>
</figure>
<p>For some applications, in particular those to be discussed later in this paper,
other types of HMMs have been found to account for observed properties of the
signal being modeled better than the standard ergodic model. One such model is
shown in <a class="reference internal" href="#hmmfig7"><span class="std std-numref">图 7</span></a> (b). This model is called a left-right model or a
Bakis model <a class="reference internal" href="#ref11" id="id41"><span>[Ref11]</span></a>, <a class="reference internal" href="#ref10" id="id42"><span>[Ref10]</span></a> because the underlying state sequence associated
with the model has the property that as time increases the state index increases
(or stays the same), i.e., the states proceed from left to right. Clearly the
left-right type of HMM has the desirable property that it can readily model
signals whose properties change overtime- e.g., speech. The fundamental property
of all left-right HMMs is that the state transition coefficients have the
property</p>
<div class="math notranslate nohighlight" id="equation-hmmeq45">
<span class="eqno">(45)<a class="headerlink" href="#equation-hmmeq45" title="公式的永久链接">¶</a></span>\[a_{ij} = 0, \quad j &lt; i\]</div>
<p>i.e., no transitions are allowed to states whose indices are lower than the
current state. Furthermore, the initial state probabilities have the property</p>
<div class="math notranslate nohighlight" id="equation-hmmeq46">
<span class="eqno">(46)<a class="headerlink" href="#equation-hmmeq46" title="公式的永久链接">¶</a></span>\[\begin{split}\pi_i =
\left\{
\begin{split}
0 &amp;, \quad i \neq 1\\
1 &amp;, \quad i = 1\\
\end{split}
\right.\end{split}\]</div>
<p>since the state sequence must begin in state <span class="math notranslate nohighlight">\(1\)</span> (and end in state
<span class="math notranslate nohighlight">\(N\)</span>) . Often, with left-right models, additional constraints are placed on
the state transition coefficients to make sure that large changes in state
indices do not occur; hence a constraint of the form</p>
<div class="math notranslate nohighlight" id="equation-hmmeq47">
<span class="eqno">(47)<a class="headerlink" href="#equation-hmmeq47" title="公式的永久链接">¶</a></span>\[a_{ij} = 0, \quad j &gt; i + \Delta\]</div>
<p>is often used. In particular, for the example of <a class="reference internal" href="#hmmfig7"><span class="std std-numref">图 7</span></a> (b), the
value of <span class="math notranslate nohighlight">\(\Delta\)</span> is <span class="math notranslate nohighlight">\(2\)</span>, i.e., no jumps of more than <span class="math notranslate nohighlight">\(2\)</span>
states are allowed. The form of the state transition matrix for the example of
<a class="reference internal" href="#hmmfig7"><span class="std std-numref">图 7</span></a> (b) is thus</p>
<div class="math notranslate nohighlight">
\[\begin{split}A =
\begin{bmatrix}
a_{11} &amp; a_{12} &amp; a_{13} &amp; 0 \\
0 &amp; a_{22} &amp; a_{23} &amp; a_{24} \\
0 &amp; 0 &amp; a_{33} &amp; a_{34} \\
0 &amp; 0 &amp; 0 &amp; a_{44}
\end{bmatrix}\end{split}\]</div>
<p>It should be clear that, for the last state in a left-right model, that the
state transition coefficients are specified as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq48">
<span class="eqno">(48)<a class="headerlink" href="#equation-hmmeq48" title="公式的永久链接">¶</a></span>\[\begin{split}a_{NN} &amp;= 1 \\
a_{Ni} &amp;= 0, \quad i &lt; N\end{split}\]</div>
<p>Although we have dichotomized HMMs into ergodic and left-right models, there are
many possible variations and combinations possible. By way of example,
<a class="reference internal" href="#hmmfig7"><span class="std std-numref">图 7</span></a> (c) shows a cross-coupled connection of two parallel
left-right HMMs. Strictly speaking, this model is a left-right model (it obeys
all the <span class="math notranslate nohighlight">\(a_{ij}\)</span> constraints); however, it can be seen that it has certain
flexibility not present in a strict left-right model (i.e., one without parallel
paths).</p>
<p>It should be clear that the imposition of the constraints of the left-right
model, or those of the constrained jump model, essentially have no effect on the
reestimation procedure. This is the case because any HMM parameter set to zero
initially, will remain at zero throughout the reestimation procedure (see
<a class="reference internal" href="#equation-hmmeq44">(44)</a>).</p>
<section id="continuous-observation-densities-in-hmms-ref24-ref25-ref26">
<h3>Continuous Observation Densities in HMMs <a class="reference internal" href="#ref24" id="id43"><span>[Ref24]</span></a>, <a class="reference internal" href="#ref25" id="id44"><span>[Ref25]</span></a>, <a class="reference internal" href="#ref26" id="id45"><span>[Ref26]</span></a><a class="headerlink" href="#continuous-observation-densities-in-hmms-ref24-ref25-ref26" title="永久链接至标题">¶</a></h3>
<p>All of our discussion, to this point, has considered only the case when the
observations were characterized as discrete symbols chosen from a finite
alphabet, and therefore we could use a discrete probability density within each
state of this model. The problem with this approach, at least for some
applications, is that the observations are continuous signals (or vectors).
Although it is possible to quantize such continuous signals via codebooks, etc.,
there might be serious degradation associated with such quantization. Hence it
would be advantageous to be able to use HMMs with continuous observation
densities.</p>
<p>In order to use a continuous observation density, some restrictions have to be
placed on the form of the model probability density function (pdf) to insure
that the parameters of the pdf can be reestimated in a consistent way. The most
general representation of the pdf, for which a reestimation procedure has been
formulated <a class="reference internal" href="#ref24" id="id46"><span>[Ref24]</span></a>, <a class="reference internal" href="#ref25" id="id47"><span>[Ref25]</span></a>, <a class="reference internal" href="#ref26" id="id48"><span>[Ref26]</span></a>, is a finite mixture of the form</p>
<div class="math notranslate nohighlight" id="equation-hmmeq49">
<span class="eqno">(49)<a class="headerlink" href="#equation-hmmeq49" title="公式的永久链接">¶</a></span>\[b_j(\mathbf{O}) = \sum_{m = 1}^M c_{jm} \mathcal{N} [\mathbf{O}, {\mu}_{jm}, \mathbf{U}_{jm}], \quad 1 \leq j \leq N\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{O}\)</span> is the vector being modeled, <span class="math notranslate nohighlight">\(c_{jm}\)</span> is the
mixture coefficient for the <span class="math notranslate nohighlight">\(m\)</span> -th mixture in state <span class="math notranslate nohighlight">\(j\)</span> and
<span class="math notranslate nohighlight">\(\mathcal{N}\)</span> is any log-concave or elliptically symmetric density
<a class="reference internal" href="#ref24" id="id49"><span>[Ref24]</span></a> (e.g., Gaussian), with mean vector <span class="math notranslate nohighlight">\(\mu_{jm}\)</span> and covariance
matrix <span class="math notranslate nohighlight">\(\mathbf{U}_{jm}\)</span> for the <span class="math notranslate nohighlight">\(m\)</span> -th in state <span class="math notranslate nohighlight">\(j\)</span>. Usually
a Gaussian density is used for <span class="math notranslate nohighlight">\(\mathcal{N}\)</span>. The mixture gains
<span class="math notranslate nohighlight">\(c_{jm}\)</span> satisfy the stochastic constraint</p>
<div class="math notranslate nohighlight" id="equation-hmmeq50">
<span class="eqno">(50)<a class="headerlink" href="#equation-hmmeq50" title="公式的永久链接">¶</a></span>\[\begin{split}\sum_{m = 1}^M c_{jm} &amp;= 1, \quad 1 \leq j \leq N \\
c_{jm} \geq 0, \quad 1 \leq j \leq N, 1 \leq m \leq M\end{split}\]</div>
<p>so that the pdf is properly normalized, i.e.,</p>
<div class="math notranslate nohighlight" id="equation-hmmeq51">
<span class="eqno">(51)<a class="headerlink" href="#equation-hmmeq51" title="公式的永久链接">¶</a></span>\[\int_{-\infty}^{\infty} b_j(x) dx = 1, \quad 1 \leq j \leq N.\]</div>
<p>The pdf of <a class="reference internal" href="#equation-hmmeq49">(49)</a> can be used to approximate, arbitrarily closely, any
finite, continuous density function. Hence it can be applied to a wide range of
problems.</p>
<p>It can be shown <a class="reference internal" href="#ref24" id="id50"><span>[Ref24]</span></a>, <a class="reference internal" href="#ref25" id="id51"><span>[Ref25]</span></a>, <a class="reference internal" href="#ref26" id="id52"><span>[Ref26]</span></a> that the reestimation formulas for
the coefficients of the mixture density, i.e., <span class="math notranslate nohighlight">\(c_{jm}, \mu_{jk}\)</span>, and
<span class="math notranslate nohighlight">\(\mathbf{U}_{jk}\)</span>, are of the form</p>
<div class="math notranslate nohighlight" id="equation-hmmeq52">
<span class="eqno">(52)<a class="headerlink" href="#equation-hmmeq52" title="公式的永久链接">¶</a></span>\[\bar{c}_{jk} = \dfrac{\sum_{t = 1}^T \gamma_t(j, k)}{\sum_{t = 1}^T \sum_{k = 1}^M \gamma_t(j, k)}\]</div>
<div class="math notranslate nohighlight" id="equation-hmmeq53">
<span class="eqno">(53)<a class="headerlink" href="#equation-hmmeq53" title="公式的永久链接">¶</a></span>\[\bar{\mu}_{jk} = \dfrac{\sum_{t = 1}^T \gamma_t(j, k) \cdot \mathbf{O}_t}{\sum_{t = 1}^T \gamma_t(j, k)}\]</div>
<div class="math notranslate nohighlight" id="equation-hmmeq54">
<span class="eqno">(54)<a class="headerlink" href="#equation-hmmeq54" title="公式的永久链接">¶</a></span>\[\bar{\mathbf{U}}_{jk} = \dfrac{\sum_{t = 1}^T \gamma_t(j, k) \cdot (\mathbf{O}_t - \mathbf{\mu}_{jk})(\mathbf{O}_t - \mathbf{\mu}_{jk})^{\prime}}{\sum_{t = 1}^T \gamma_t(j, k)}\]</div>
<p>where prime denotes vector transpose and where <span class="math notranslate nohighlight">\(\gamma_t(j, k)\)</span> is the
probability of being in state <span class="math notranslate nohighlight">\(j\)</span> at time <span class="math notranslate nohighlight">\(t\)</span> with the <span class="math notranslate nohighlight">\(k\)</span> -th
mixture component accounting for <span class="math notranslate nohighlight">\(\mathbf{O}_t\)</span>, i.e.,</p>
<div class="math notranslate nohighlight">
\[\gamma_t(j, k) =
\left[
\dfrac{\alpha_t(j) \beta_t(j)}{\sum_{j = 1}^N \alpha_t(j) \beta_t(j)}
\right]
\left[
\dfrac{c_{jk} \mathcal{N}(\mathbf{O}_t, \mu_{jk}, \mathbf{U}_{jk})}{\sum_{m = 1}^M c_{jm} \mathcal{N}(\mathbf{O}_t, \mu_{jm}, \mathbf{U}_{jm})}
\right].\]</div>
<p>(The term <span class="math notranslate nohighlight">\(\gamma_t(j, k)\)</span> generalizes to <span class="math notranslate nohighlight">\(\gamma_t(j)\)</span> of
<a class="reference internal" href="#equation-hmmeq26">(26)</a> in the case of a simple mixture, or a discrete density.) The
reestimation formula for <span class="math notranslate nohighlight">\(a_{ij}\)</span> is identical to the one used for
discrete observation densities (i.e., <a class="reference internal" href="#equation-hmmeq40">(40)</a>). The interpretation of
<a class="reference internal" href="#equation-hmmeq52">(52)</a>, <a class="reference internal" href="#equation-hmmeq53">(53)</a>, <a class="reference internal" href="#equation-hmmeq54">(54)</a> is fairly straightforward. The
reestimation formula for <span class="math notranslate nohighlight">\(c_{jk}\)</span> is the ratio between the expected number
of times the system is in state <span class="math notranslate nohighlight">\(j\)</span> using the <span class="math notranslate nohighlight">\(k\)</span> -th mixture
component, and the expected number of times the system is in state <span class="math notranslate nohighlight">\(j\)</span>.
Similarly, the reestimation formula for the mean vector <span class="math notranslate nohighlight">\(\mu_{jk}\)</span> weights
each numerator term of <a class="reference internal" href="#equation-hmmeq52">(52)</a> by the observation, thereby giving the
expected value of the portion of the observation vector accounted for by the
<span class="math notranslate nohighlight">\(k\)</span> -th mixture component. A similar interpretation can be given for the
reestimation term for the covariance matrix <span class="math notranslate nohighlight">\(\mathbf{U}_{jk}\)</span>.</p>
</section>
<section id="autoregressive-hmms-ref27-ref28">
<h3>Autoregressive HMMs <a class="reference internal" href="#ref27" id="id53"><span>[Ref27]</span></a>, <a class="reference internal" href="#ref28" id="id54"><span>[Ref28]</span></a><a class="headerlink" href="#autoregressive-hmms-ref27-ref28" title="永久链接至标题">¶</a></h3>
<p>Although the general formulation of continuous density HMMs is applicable to a
wide range of problems, there is one other very interesting class of HMMs that
is particularly applicable to speech processing. This is the class of
autoregressive HMMs <a class="reference internal" href="#ref27" id="id55"><span>[Ref27]</span></a>, <a class="reference internal" href="#ref28" id="id56"><span>[Ref28]</span></a>. For this class, the observation vectors
are drawn from an autoregression process.</p>
<p>To be more specific, consider the observation vector <span class="math notranslate nohighlight">\(\mathbf{O}\)</span> with
components <span class="math notranslate nohighlight">\((x_0, x_1, x_2, \ldots, x_{K-1})\)</span>. Since the basis probability
density function for the observation vector is Gaussian autoregressive (or order
<span class="math notranslate nohighlight">\(p\)</span>), then the components of <span class="math notranslate nohighlight">\(\mathbf{O}\)</span> are related by</p>
<div class="math notranslate nohighlight" id="equation-hmmeq55">
<span class="eqno">(55)<a class="headerlink" href="#equation-hmmeq55" title="公式的永久链接">¶</a></span>\[\mathbf{O}_k = - \sum_{i = 1}^p a_i \mathbf{O}_{k - i} + e_k\]</div>
<p>where <span class="math notranslate nohighlight">\(e_k, k = 0, 1, 2, \ldots, K - 1\)</span> are Gaussian, independent,
identically distributed random variables with zero mean and variance
<span class="math notranslate nohighlight">\(\sigma^2\)</span>, and <span class="math notranslate nohighlight">\(a_i, i = 1, 2, \ldots, p\)</span>, are the autoregression
or predictor coefficients. It can be shown that for large <span class="math notranslate nohighlight">\(K\)</span>, the density
function for <span class="math notranslate nohighlight">\(\mathbf{O}\)</span> is approximately</p>
<div class="math notranslate nohighlight" id="equation-hmmeq56">
<span class="eqno">(56)<a class="headerlink" href="#equation-hmmeq56" title="公式的永久链接">¶</a></span>\[f(\mathbf{O}) = (2 \pi \sigma^2)^{-K/2} \exp{-\dfrac{1}{2 \sigma^2} \delta(\mathbf{O}, \mathbf{a})}\]</div>
<p>where</p>
<div class="math notranslate nohighlight" id="equation-hmmeq57">
<span class="eqno">(57)<a class="headerlink" href="#equation-hmmeq57" title="公式的永久链接">¶</a></span>\[\begin{split}\delta(\mathbf{O}, \mathbf{a}) &amp;= r_a(0) r(0) + 2 \sum_{i = 1}^P r_a(i) r(i) \\
\mathbf{a}^{\prime} &amp;= [1, a_1, a_2, \ldots, a_p] \\
r_a(i) &amp;= \sum_{n = 0}^{p - i} a_n a_{n + i} \quad (a_0 = 1), 1 \leq i \leq p \\
r(i) &amp;= \sum_{n = 0}^{K-i-1} x_n x_{n + i} \quad 0 \leq i \leq p.\end{split}\]</div>
<p>In the above equations it can be recognized that <span class="math notranslate nohighlight">\(r(i)\)</span> is the
autocorrelation of the observation samples, and <span class="math notranslate nohighlight">\(r_a(i)\)</span> is the
autocorrelation of the autoregressive coefficients.</p>
<p>The total (frame) prediction residual <span class="math notranslate nohighlight">\(\alpha\)</span> can be written as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq58">
<span class="eqno">(58)<a class="headerlink" href="#equation-hmmeq58" title="公式的永久链接">¶</a></span>\[\alpha = E\left[
\sum_{i = 1}^K e_i^2
\right]
= K \sigma^2\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma^2\)</span> is the variance per sample of the error signal. Consider
the normalized observation vector</p>
<div class="math notranslate nohighlight" id="equation-hmmeq59">
<span class="eqno">(59)<a class="headerlink" href="#equation-hmmeq59" title="公式的永久链接">¶</a></span>\[\hat{\mathbf{O}} = \dfrac{\mathbf{O}}{\sqrt{\alpha}} = \dfrac{\mathbf{O}}{\sqrt{K \sigma^2}}\]</div>
<p>where each sample <span class="math notranslate nohighlight">\(x_i\)</span>, is divided by <span class="math notranslate nohighlight">\(\sqrt{K \sigma^2}\)</span>, i.e.,
each sample is normalized by the sample variance. Then
<span class="math notranslate nohighlight">\(f(\hat{\mathbf{O}})\)</span> can be written as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq60">
<span class="eqno">(60)<a class="headerlink" href="#equation-hmmeq60" title="公式的永久链接">¶</a></span>\[f(\hat{\mathbf{O}}) = \left(
\dfrac{2 \pi}{K}
\right)^{-K/2}
\exp(-\dfrac{K}{2} \delta(\hat{\mathbf{O}}, \mathbf{a}))\]</div>
<p>In practice, the factor <span class="math notranslate nohighlight">\(K\)</span> (in front of the exponential of <a class="reference internal" href="#equation-hmmeq60">(60)</a>)
is replaced by an effective frame length <span class="math notranslate nohighlight">\(K\)</span> which represents the
effective length of each data vector. Thus if consecutive data vectors are
overlapped by 3 to 1, then we would use <span class="math notranslate nohighlight">\(\hat{K} = K/3\)</span> in <a class="reference internal" href="#equation-hmmeq60">(60)</a>,
so that the contribution of each sample of signal to the overall density is
counted exactly once.</p>
<p>The way in which we use Gaussian autoregressive density in HMMs is
straightforward. We assume a mixture density of the form</p>
<div class="math notranslate nohighlight" id="equation-hmmeq61">
<span class="eqno">(61)<a class="headerlink" href="#equation-hmmeq61" title="公式的永久链接">¶</a></span>\[b_j(\mathbf{O}) = \sum_{m = 1}^M c_{jm} b_{jm}(\mathbf{O})\]</div>
<p>where each <span class="math notranslate nohighlight">\(b_{jm}(\mathbf{O})\)</span> is the density defined by <a class="reference internal" href="#equation-hmmeq60">(60)</a>
with autoregression vector <span class="math notranslate nohighlight">\(a_{jm}\)</span> (or equivalently by autocorrelation
vector <span class="math notranslate nohighlight">\(r_{a_{jm}}\)</span>), i.e.,</p>
<div class="math notranslate nohighlight" id="equation-hmmeq62">
<span class="eqno">(62)<a class="headerlink" href="#equation-hmmeq62" title="公式的永久链接">¶</a></span>\[b_{jm}(\mathbf{O}) = \left(
\dfrac{2 \pi}{K}
\right)^{-K/2}
\exp(-\dfrac{K}{2} \delta(\mathbf{O}, \mathbf{a}_{jm})).\]</div>
<p>A reestimation formula for the sequence autocorrelation, <span class="math notranslate nohighlight">\(r(i)\)</span> of
<a class="reference internal" href="#equation-hmmeq57">(57)</a>, for the <span class="math notranslate nohighlight">\(j\)</span> -th state, <span class="math notranslate nohighlight">\(k\)</span> th mixture, component has
been derived, and is of the form</p>
<div class="math notranslate nohighlight" id="equation-hmmeq63a">
<span class="eqno">(63)<a class="headerlink" href="#equation-hmmeq63a" title="公式的永久链接">¶</a></span>\[\bar{\mathbf{r}}_{jk} = \dfrac{\sum_{t = 1}^T \gamma_t(j, k) \cdot \mathbf{r}_t}{\sum_{t = 1}^T \gamma_t(j, k)}\]</div>
<p>where <span class="math notranslate nohighlight">\(\gamma_t(j, k)\)</span> is defined as the probability of being in state
<span class="math notranslate nohighlight">\(j\)</span> at time <span class="math notranslate nohighlight">\(t\)</span> and using mixture component <span class="math notranslate nohighlight">\(k\)</span>, i.e.,</p>
<div class="math notranslate nohighlight" id="equation-hmmeq63b">
<span class="eqno">(64)<a class="headerlink" href="#equation-hmmeq63b" title="公式的永久链接">¶</a></span>\[\gamma_t(j, k) =
\left[
\dfrac{\alpha_t(j) \beta_t(j)}
{\sum_{j = 1}^N \alpha_t(j) \beta_t(j)}
\right]
\left[
\dfrac{c_{jk} b_{jk}(\mathbf{O}_t)}
{\sum_{k = 1}^M c_{jk} b_{jk}(\mathbf{O}_t)}
\right].\]</div>
<p>It can be seen that <span class="math notranslate nohighlight">\(\bar{\mathbf{r}}_{jk}\)</span> is a weighted sum (by
probability of occurrence) of the normalized autocorrelations of the frames in
the observation sequence. From <span class="math notranslate nohighlight">\(\bar{\mathbf{r}}_{jk}\)</span>, one can solve a
set of normal equations to obtain the corresponding autoregressive coefficient
vector <span class="math notranslate nohighlight">\(\bar{\mathbf{a}}_{jk}\)</span>, for the <span class="math notranslate nohighlight">\(k\)</span> -th mixture of state
<span class="math notranslate nohighlight">\(j\)</span>. The new autocorrection vectors of the autoregression coefficients can
then be calculated using <a class="reference internal" href="#equation-hmmeq57">(57)</a>, thereby closing the reestimation loop.</p>
</section>
<section id="variants-on-hmm-structures-null-transitions-and-tied-states">
<h3>Variants on HMM Structures - Null Transitions and Tied States<a class="headerlink" href="#variants-on-hmm-structures-null-transitions-and-tied-states" title="永久链接至标题">¶</a></h3>
<p>Throughout this paper we have considered HMMs in which the observations were
associated with states of the model. It is also possible to consider models in
which the observations are associated with the arcs of the model. This type of
HMM has been used extensively in the IBM continuous speech recognizer <a class="reference internal" href="#ref13" id="id57"><span>[Ref13]</span></a>.
It has been found useful, for this type of model, to allow transitions which
produce no output-i.e., jumps from one state to another which produce no
observation <a class="reference internal" href="#ref13" id="id58"><span>[Ref13]</span></a>. Such transitions are called null transitions and are
designated by a dashed line with the symbol <span class="math notranslate nohighlight">\(\phi\)</span> used to denote the null
output.</p>
<figure class="align-center" id="id109">
<span id="hmmfig8"></span><img alt="_images/hmmfig8.png" src="_images/hmmfig8.png" />
<figcaption>
<p><span class="caption-number">图 8 </span><span class="caption-text">Examples of networks incorporating null transitions. (a) Left-right
model. (b) Finite state network. (c) Grammar network.</span><a class="headerlink" href="#id109" title="永久链接至图片">¶</a></p>
</figcaption>
</figure>
<p><a class="reference internal" href="#hmmfig8"><span class="std std-numref">图 8</span></a> illustrates 3 examples (from speech processing tasks) where
null arcs have been successfully utilized. The example of part (a) corresponds
to an HMM (a left-right model) with a large number of states in which it is
possible to omit transitions between any pair of states. Hence it is possible to
generate observation sequences with as few as <span class="math notranslate nohighlight">\(1\)</span> observation and still
account for a path which begins in state <span class="math notranslate nohighlight">\(1\)</span> and ends in state <span class="math notranslate nohighlight">\(N\)</span>.</p>
<p>The example of <a class="reference internal" href="#hmmfig8"><span class="std std-numref">图 8</span></a> (b) is a finite state network (FSN)
representation of aword in terms of linguistic unit models (i.e., the sound on
each arc is itself an HMM). For this model the null transition gives a compact
and efficient way of describing alternate word pronunciations (i.e., symbol
delections).</p>
<p>Finally the FSN of <a class="reference internal" href="#hmmfig8"><span class="std std-numref">图 8</span></a> (c) shows how the ability to insert a null
transition into a grammar network allows a relatively simple network to generate
arbitrarily long word (digit) sequences. In the example shown in
<a class="reference internal" href="#hmmfig8"><span class="std std-numref">图 8</span></a> (c), the null transition allows the network to generate
arbitrary sequences of digits of arbitrary length by returning to the initial
state after each individual digit is produced.</p>
<p>Another interesting variation in the HMM structure is the concept of parameter
tieing <a class="reference internal" href="#ref13" id="id59"><span>[Ref13]</span></a>. Basically the idea is to set up an equivalence relation between
HMM parameters in different states. In this manner the number of independent
parameters in the model is reduced and the parameter estimation becomes somewhat
simpler. Parameter tieing is used in cases where the observation density (for
example) is known to be the same in 2 or more states. Such cases occur often in
characterizing speech sounds. The technique is especially appropriate in the
case where there is insufficient training data to estimate, reliably, a large
number of model parameters. For such cases it is appropriate to tie model
parameters so as to reduce the number of parameters (i.e., size of the model)
thereby making the parameter estimation problem somewhat simpler. We will
discuss this method later in this paper.</p>
</section>
<section id="inclusion-of-explicit-state-duration-density-in-hmms-ref29-ref30">
<h3>Inclusion of Explicit State Duration Density in HMMs <a class="footnote-reference brackets" href="#hmm8" id="id60">8</a>, <a class="reference internal" href="#ref29" id="id61"><span>[Ref29]</span></a>, <a class="reference internal" href="#ref30" id="id62"><span>[Ref30]</span></a><a class="headerlink" href="#inclusion-of-explicit-state-duration-density-in-hmms-ref29-ref30" title="永久链接至标题">¶</a></h3>
<p>Perhaps the major weakness of conventional HMMs is the modeling of state
duration. Earlier we showed <a class="reference internal" href="#equation-hmmeq5">(5)</a> that the inherent duration probability
density <span class="math notranslate nohighlight">\(p_i(d)\)</span> associated with state <span class="math notranslate nohighlight">\(S_i\)</span>, with self transition
coefficient <span class="math notranslate nohighlight">\(a_{ii}\)</span>, was of the form</p>
<div class="math notranslate nohighlight" id="equation-hmmeq64">
<span class="eqno">(65)<a class="headerlink" href="#equation-hmmeq64" title="公式的永久链接">¶</a></span>\[\begin{split}p_i(d) &amp; = (a_{ii})^{d-1} (1 - a_{ii}) \\
&amp; = \text{ probability of } d \text{ consecutive observations in state } S_i.\end{split}\]</div>
<p>For most physical signals, this exponential state duration density is
inappropriate. Instead we would prefer to explicitly model duration density in
some analytic form. <a class="reference internal" href="#hmmfig9"><span class="std std-numref">图 9</span></a> illustrates, for a pair of model states
<span class="math notranslate nohighlight">\(S_i\)</span> and <span class="math notranslate nohighlight">\(S_j\)</span>, the differences between HMMs without and with
explicit duration density. In part (a) the states have exponential duration
densities based on self-transition coefficients <span class="math notranslate nohighlight">\(a_{ii}\)</span> and
<span class="math notranslate nohighlight">\(a_{jj}\)</span>, respectively. In part (b), the self-transition coefficients are
set to zero, and an explicit duration density is specified <a class="footnote-reference brackets" href="#hmm9" id="id63">9</a>. For this
case, a transition is made only after the appropriate number of observations
have occurred in the state (as specified by the duration density).</p>
<figure class="align-center" id="id110">
<span id="hmmfig9"></span><img alt="_images/hmmfig9.png" src="_images/hmmfig9.png" />
<figcaption>
<p><span class="caption-number">图 9 </span><span class="caption-text">Illustration of general interstate connections of (a) a normal HMM with
exponential state duration density, and (b) a variable duration HMM with
specified state densities and no self transitions from a state back to
itself.</span><a class="headerlink" href="#id110" title="永久链接至图片">¶</a></p>
</figcaption>
</figure>
<p>Based on the simple model of <a class="reference internal" href="#hmmfig9"><span class="std std-numref">图 9</span></a> (b), the sequence of events of
the variable duration HMM is as follows:</p>
<ol class="arabic simple">
<li><p>An initial state, <span class="math notranslate nohighlight">\(q_1 = S_i\)</span>, is chosen according to the initial state
distribution <span class="math notranslate nohighlight">\(\pi_i\)</span>.</p></li>
<li><p>A duration <span class="math notranslate nohighlight">\(d_1\)</span> is chosen according to the state duration density
<span class="math notranslate nohighlight">\(p_{q_1}(d_1)\)</span>. (For expedience and ease of implementation the duration
density <span class="math notranslate nohighlight">\(p_q(d)\)</span> is truncated at a maximum duration value <span class="math notranslate nohighlight">\(D\)</span>.)</p></li>
<li><p>Observations <span class="math notranslate nohighlight">\(O_1 O_2 \cdots O_{d_1}\)</span> are chosen according to the joint
observation density, <span class="math notranslate nohighlight">\(b_{q_1}(O_1 O_2 \cdots O_{d_1})\)</span>. Generally we
assume independent of observations so that <span class="math notranslate nohighlight">\(b_{q_1}(O_1 O_2 \cdots
O_{d_1}) = \prod_{t = 1}^{d_1} b_{q_1}(O_t)\)</span>.</p></li>
<li><p>The next state, <span class="math notranslate nohighlight">\(q_2 = S_j\)</span>, is chosen according to the state
transition probabilities, <span class="math notranslate nohighlight">\(a_{q_1 q_2}\)</span>, with the constraint that
<span class="math notranslate nohighlight">\(a_{q_1 q_2} = 0\)</span>, i.e., no transition back to the same state can
occur. (Clearly this is a requirement since we assume that, in state
<span class="math notranslate nohighlight">\(q_1\)</span>, exactly <span class="math notranslate nohighlight">\(d_1\)</span> observations occur.)</p></li>
</ol>
<p>A little thought should convince the reader that the variable duration HMM can
be made equivalent to the standard HMM by setting <span class="math notranslate nohighlight">\(p_i(d)\)</span> to be the
exponential density of <a class="reference internal" href="#equation-hmmeq64">(65)</a>.</p>
<p>Using the above formulation, several changes must be made to the formulas of
Section III to allow calculation of <span class="math notranslate nohighlight">\(P(\mathcal{O} \mid \lambda)\)</span> and for
reestimation of all model parameters. In particular we assume that the first
state begins at <span class="math notranslate nohighlight">\(t = 1\)</span> and the last state ends at <span class="math notranslate nohighlight">\(t = T\)</span>, i.e.,
entire duration intervals are included with the observation sequence. We then
define the forward variable <span class="math notranslate nohighlight">\(\alpha_t(i)\)</span> as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq65">
<span class="eqno">(66)<a class="headerlink" href="#equation-hmmeq65" title="公式的永久链接">¶</a></span>\[\alpha_t(i) = P(O_1 O_2 \cdots O_t, S_i \text{ ends at } t \mid \lambda).\]</div>
<p>We assume that a total of <span class="math notranslate nohighlight">\(r\)</span> states have been visited during the first
<span class="math notranslate nohighlight">\(t\)</span> observations and we denote the states as <span class="math notranslate nohighlight">\(q_1, q_2, \ldots,
q_r\)</span>, with durations associated with each state of <span class="math notranslate nohighlight">\(d_1, d_2, \ldots, d_r\)</span>
Thus the constraints of <a class="reference internal" href="#equation-hmmeq65">(66)</a> are</p>
<div class="math notranslate nohighlight" id="equation-hmmeq66">
<span class="eqno">(67)<a class="headerlink" href="#equation-hmmeq66" title="公式的永久链接">¶</a></span>\[\begin{split}q_r &amp;= S_i \\
\sum_{s = 1}^r d_s &amp; = t.\end{split}\]</div>
<p>Equation <a class="reference internal" href="#equation-hmmeq65">(66)</a> can then be written as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq67">
<span class="eqno">(68)<a class="headerlink" href="#equation-hmmeq67" title="公式的永久链接">¶</a></span>\[\begin{split}\alpha_t(i) &amp;= \sum_q \sum_d \pi_{q_1} \cdot p_{q_1}(d_1) \cdots P(O_1 O_2 \cdots O_{d_1} \mid q_1) \\
&amp; \quad \cdot a_{q_1 q_2} p_{q_2}(d_2) P(O_{d_1 + 1} \cdots O_{d_1 + d_2} \mid q_2) \cdots \\
&amp; \quad \cdot a_{q_{r-1} q_r} p_{q_r}(d_r) P(O_{d_1 + d_2 + \cdots \d_{r-1} + 1} \cdots O_{t} \mid q_t)\end{split}\]</div>
<p>where the sum is over all states <span class="math notranslate nohighlight">\(q\)</span> and all possible state durations
<span class="math notranslate nohighlight">\(d\)</span>. By induction we can write <span class="math notranslate nohighlight">\(\alpha_t(j)\)</span> as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq68">
<span class="eqno">(69)<a class="headerlink" href="#equation-hmmeq68" title="公式的永久链接">¶</a></span>\[\alpha_t(j) = \sum_{i = 1}^N \sum_{d = 1}^D \alpha_{t-d}(i) a_{ij} p_{j}(d) \prod_{s = t-d+1}^t b_j(\mathbf{O}_s)\]</div>
<p>where <span class="math notranslate nohighlight">\(D\)</span> is the maximum duration within any state. To initialize the
computation of <span class="math notranslate nohighlight">\(\alpha_t(j)\)</span> we use</p>
<div class="math notranslate nohighlight" id="equation-hmmeq69">
<span class="eqno">(70)<a class="headerlink" href="#equation-hmmeq69" title="公式的永久链接">¶</a></span>\[\begin{split}\alpha_1(i) &amp;= \pi_i p_i(1) \cdot b_i(\mathbf{O}_1) \\
\alpha_2(i) &amp;= \pi_i p_i(2) \prod_{s = 1}^2 b_i(\mathbf{O}_s) + \sum_{j = 1, j \neq i}^N \alpha_1(j) a_{ji} p_i(1) b_i(\mathbf{O}_2) \\
\alpha_3(i) &amp;= \pi_i p_i(3) \prod_{s = 1}^3 b_i(\mathbf{O}_s) + \sum_{d = 1}^2 \sum_{j = 1, j \neq i}^N \alpha_{3-d}(j) a_{ji} p_i(d) \prod_{s = 4-d}^3 b_i(\mathbf{O}_s) \\\end{split}\]</div>
<p>etc., until <span class="math notranslate nohighlight">\(\alpha_D(i)\)</span> is computed; then <a class="reference internal" href="#equation-hmmeq68">(69)</a> can be used for
all <span class="math notranslate nohighlight">\(t &gt; D\)</span>. It should be clear that the desired probability of
<span class="math notranslate nohighlight">\(\mathcal{O}\)</span> given the model <span class="math notranslate nohighlight">\(\lambda\)</span> can be written in terms of
the <span class="math notranslate nohighlight">\(\alpha\)</span>’s as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq70">
<span class="eqno">(71)<a class="headerlink" href="#equation-hmmeq70" title="公式的永久链接">¶</a></span>\[P(\mathcal{O} \mid \lambda) = \sum_{i = 1}^N \alpha_T(i)\]</div>
<p>as was previously used for ordinary HMMs.</p>
<p>In ordertogive reestimation formulas for all the variables of the variable
duration HMM, we must define three more forward-backward variables, namely</p>
<div class="math notranslate nohighlight" id="equation-hmmeq71">
<span class="eqno">(72)<a class="headerlink" href="#equation-hmmeq71" title="公式的永久链接">¶</a></span>\[\alpha_t^*(i) = P(O_1 O_2 \cdots O_t, S_i \text{ begins at } t+1 \mid \lambda)\]</div>
<div class="math notranslate nohighlight" id="equation-hmmeq72">
<span class="eqno">(73)<a class="headerlink" href="#equation-hmmeq72" title="公式的永久链接">¶</a></span>\[\beta_t(i) = P(O_{t+1} \cdots O_T \mid S_i \text{ ends at } t, \lambda)\]</div>
<div class="math notranslate nohighlight" id="equation-hmmeq73">
<span class="eqno">(74)<a class="headerlink" href="#equation-hmmeq73" title="公式的永久链接">¶</a></span>\[\beta_t^*(i) = P(O_{t+1} \cdots O_T \mid S_i \text{ begins at } t+1, \lambda).\]</div>
<p>The relationships between <span class="math notranslate nohighlight">\(\alpha, \alpha^*, \beta,\)</span> and <span class="math notranslate nohighlight">\(\beta^*\)</span>
are as follows:</p>
<div class="math notranslate nohighlight" id="equation-hmmeq74">
<span class="eqno">(75)<a class="headerlink" href="#equation-hmmeq74" title="公式的永久链接">¶</a></span>\[\alpha_t^*(j) = \sum_{i = 1}^N \alpha_t(i) a_{ij}\]</div>
<div class="math notranslate nohighlight" id="equation-hmmeq75">
<span class="eqno">(76)<a class="headerlink" href="#equation-hmmeq75" title="公式的永久链接">¶</a></span>\[\alpha_t(i) = \sum_{d=1}^D \alpha_{t-d}^*(i) p_i(d) \prod_{s = t-d+1}^t b_i(\mathbf{O}_s)\]</div>
<div class="math notranslate nohighlight" id="equation-hmmeq76">
<span class="eqno">(77)<a class="headerlink" href="#equation-hmmeq76" title="公式的永久链接">¶</a></span>\[\beta_t(i) = \sum_{j = 1}^N a_{ij} \beta_t^*(j)\]</div>
<div class="math notranslate nohighlight" id="equation-hmmeq77">
<span class="eqno">(78)<a class="headerlink" href="#equation-hmmeq77" title="公式的永久链接">¶</a></span>\[\beta_t^*(i) = \sum_{d = 1}^D \beta_{t+d}(i) p_i(d) \prod_{s = t+1}^{t+d} b_i(\mathbf{O}_s).\]</div>
<p>Based on the above relationships and definitions, the reestimation formulas for
the variable duration HMM are</p>
<div class="math notranslate nohighlight" id="equation-hmmeq78">
<span class="eqno">(79)<a class="headerlink" href="#equation-hmmeq78" title="公式的永久链接">¶</a></span>\[\bar{\pi}_i = \dfrac{\pi_i \beta_0^*(i)}{P(\mathcal{O} \mid \lambda)}\]</div>
<div class="math notranslate nohighlight" id="equation-hmmeq79">
<span class="eqno">(80)<a class="headerlink" href="#equation-hmmeq79" title="公式的永久链接">¶</a></span>\[\bar{a}_{ij} = \dfrac{\sum_{t = 1}^T \alpha_t(i) a_{ij} \beta_t^*(j)}
{\sum_{j = 1}^N \sum_{t = 1}^T \alpha_t(i) a_{ij} \beta_t^*(j)}\]</div>
<div class="math notranslate nohighlight" id="equation-hmmeq80">
<span class="eqno">(81)<a class="headerlink" href="#equation-hmmeq80" title="公式的永久链接">¶</a></span>\[\bar{b}_i(k) = \dfrac
{\sum_{t = 1 \text{ s.t. } O_t = k}^T \left[
\sum_{\tau &lt; t} \alpha_{\tau}^*(i) \beta_{\tau}^*(i) - \sum_{\tau &lt; t} \alpha_{\tau}(i) \beta_{\tau}(i)
\right]}
{\sum_{k = 1}^M \sum_{t = 1 \text{ s.t. } O_t = v_k}^T
\left[
\sum_{\tau &lt; t} \alpha_{\tau}^*(i) \beta_{\tau}^*(i) - \sum_{\tau &lt; t} \alpha_{\tau}(i) \beta_{\tau}(i)
\right]}\]</div>
<div class="math notranslate nohighlight" id="equation-hmmeq81">
<span class="eqno">(82)<a class="headerlink" href="#equation-hmmeq81" title="公式的永久链接">¶</a></span>\[\bar{p}_i(d) = \dfrac
{\sum_{t=1}^T \alpha_t^*(i) p_i(d) \beta_{t+d}(i)
\prod_{s=t+1}^{t+d} b_{j}(\mathbf{O}_s)}
{\sum_{d = 1}^D
\sum_{t=1}^T \alpha_t^*(i) p_i(d) \beta_{t+d}(i)
\prod_{s=t+1}^{t+d} b_{j}(\mathbf{O}_s)}\]</div>
<p>The interpretation of the reestimation formulas is the following. The formula
for <span class="math notranslate nohighlight">\(\bar{\pi}_i\)</span> is the probability that state <span class="math notranslate nohighlight">\(i\)</span> was the first
state, given <span class="math notranslate nohighlight">\(\mathcal{O}\)</span>. The formula for <span class="math notranslate nohighlight">\(\bar{a}_{ij}\)</span> is almost
the same as for the usual HMM except it uses the condition that the alpha terms
in which a state ends at <span class="math notranslate nohighlight">\(t\)</span>, join with the beta terms in which a new
state begins at <span class="math notranslate nohighlight">\(t + 1\)</span>. The formula for <span class="math notranslate nohighlight">\(\bar{b}_i(k)\)</span> (assuming a
discrete density) is the expected number of times that observation <span class="math notranslate nohighlight">\(O_t =
v_k\)</span> occurred in state <span class="math notranslate nohighlight">\(i\)</span>, normalized by the expected number of times
that any observation occurred in state <span class="math notranslate nohighlight">\(i\)</span>. Finally, the reestimation
formula for <span class="math notranslate nohighlight">\(\bar{p}_i(d)\)</span> is the ratio of the expected number of times
state <span class="math notranslate nohighlight">\(i\)</span> occurred with duration <span class="math notranslate nohighlight">\(d\)</span>, to the expected number of
times state <span class="math notranslate nohighlight">\(i\)</span> occurred with any duration.</p>
<p>The importance of incorporating state duration densities is reflected in the
observation that, for some problems, the quality of the modeling is
significantly improved when explicit state duration densities are used. However,
there are drawbacks to the use of the variable duration model discussed in this
section. One is the greatly increased computational load associated with using
variable durations. It can be seen from the definition and initialization
conditions on the forward variable <span class="math notranslate nohighlight">\(\alpha_i(i)\)</span>, from <a class="reference internal" href="#equation-hmmeq68">(69)</a>,
<a class="reference internal" href="#equation-hmmeq69">(70)</a>, that about <span class="math notranslate nohighlight">\(D\)</span> times the storage and <span class="math notranslate nohighlight">\(D^2/2\)</span> times
the computation is required. For <span class="math notranslate nohighlight">\(D\)</span> on the order of 25 (as is reasonable
for many speech processing problems), computation is increased by a factor
of 300. Another problem with the variable duration models is the large number of
parameters (<span class="math notranslate nohighlight">\(D\)</span>), associated with each state, that must be estimated, in
addition to the usual HMM parameters. Furthermore, for a fixed number of
observations <span class="math notranslate nohighlight">\(T\)</span>, in the training set, there are, on average, fewer state
transitions and much less data to estimate <span class="math notranslate nohighlight">\(p_i(d)\)</span> than would be used in
a standard HMM. Thus the reestimation problem is more difficult for variable
duration HMMs than for the standard HMM.</p>
<p>One proposal to alleviate some of these problems is to use a parametric state
duration density instead of the non-parametric <span class="math notranslate nohighlight">\(p_i(d)\)</span> used above
<a class="reference internal" href="#ref29" id="id64"><span>[Ref29]</span></a>, <a class="reference internal" href="#ref30" id="id65"><span>[Ref30]</span></a>. In particular, proposals include the Gaussian family with</p>
<div class="math notranslate nohighlight" id="equation-hmmeq82">
<span class="eqno">(83)<a class="headerlink" href="#equation-hmmeq82" title="公式的永久链接">¶</a></span>\[p_i(d) = \mathcal{N}(d, \mu_i, \sigma_i^2)\]</div>
<p>with parameters <span class="math notranslate nohighlight">\(\mu_i\)</span> and <span class="math notranslate nohighlight">\(\sigma_i^2\)</span>, or the Gamma family with</p>
<div class="math notranslate nohighlight" id="equation-hmmeq83">
<span class="eqno">(84)<a class="headerlink" href="#equation-hmmeq83" title="公式的永久链接">¶</a></span>\[p_i(d) = \dfrac{\eta_i^{\nu_i} d^{\nu_i - 1} e^{-\eta_i d}}
{\Gamma(\nu_i)}\]</div>
<p>with parameters <span class="math notranslate nohighlight">\(\nu_i\)</span> and <span class="math notranslate nohighlight">\(\eta_i\)</span> and with mean <span class="math notranslate nohighlight">\(\nu_i
\eta_i^{-1}\)</span> and variance <span class="math notranslate nohighlight">\(\nu_i \eta_i^{-2}\)</span>. Reestimation formulas for
<span class="math notranslate nohighlight">\(\eta_i\)</span> and <span class="math notranslate nohighlight">\(\nu_i\)</span> have been derived and used with good results
<a class="reference internal" href="#ref19" id="id66"><span>[Ref19]</span></a>. Another possibility, which has been used with good success, is to
assume a uniform duration distribution (over an appropriate range of durations)
and use a path-constrained Viterbi decoding procedure <a class="reference internal" href="#ref31" id="id67"><span>[Ref31]</span></a>.</p>
</section>
<section id="optimization-criterion-ml-mmi-and-mdi-ref32-ref33">
<h3>Optimization Criterion - ML, MMI, and MDI <a class="reference internal" href="#ref32" id="id68"><span>[Ref32]</span></a>, <a class="reference internal" href="#ref33" id="id69"><span>[Ref33]</span></a><a class="headerlink" href="#optimization-criterion-ml-mmi-and-mdi-ref32-ref33" title="永久链接至标题">¶</a></h3>
<p>The basic philosophy of HMMs is that a signal (or observation
sequence) can be well modeled if the parameters of
an HMM are carefully and correctly chosen. The problem
with this philosophy is that it is sometimes inaccurate -
either because the signal does not obey the constraints of
the HMM, or because it is too difficult to get reliable estimates
of all HMM parameters. To alleviate this type of problem,
there has been proposed at least two alternatives to
the standard maximum likelihood (ML) optimization procedure
for estimating HMM parameters.</p>
<p>The first alternative <a class="reference internal" href="#ref32" id="id70"><span>[Ref32]</span></a> is based on the idea that several HMMs are to be
designed and we wish to design them all at the same time in such a way so as to
maximize the discrimination power of each model (i.e., each model’s ability to
distinguish between observation sequences generated by the correct model and
those generated by alternative models). We denote the different HMMs as
<span class="math notranslate nohighlight">\(\lambda_{\nu}, \nu = 1, 2, \ldots, V\)</span>. The standard ML design criterion
is to use a separate training sequence of observations <span class="math notranslate nohighlight">\(O^{\nu}\)</span> to derive
model parameters for each model <span class="math notranslate nohighlight">\(\lambda_{\nu}\)</span>. Thus the standard ML
optimization yields</p>
<div class="math notranslate nohighlight" id="equation-hmmeq84">
<span class="eqno">(85)<a class="headerlink" href="#equation-hmmeq84" title="公式的永久链接">¶</a></span>\[P_{\nu}^* = \mathrm{max}_{\lambda_{\nu}} P(O^{\nu} \mid \lambda_{\nu}).\]</div>
<p>The proposed alternative design criterion <a class="reference internal" href="#ref31" id="id71"><span>[Ref31]</span></a> is the maximum mutual
information (MMI) criterion in which the average mutual information <span class="math notranslate nohighlight">\(I\)</span>
between the observation sequence <span class="math notranslate nohighlight">\(O^{\nu}\)</span> and the complete set of models
<span class="math notranslate nohighlight">\(\lambda = (\lambda_1, \lambda_2, \ldots, \lambda_V)\)</span> is maximized. One
possible way of implementing this <a class="footnote-reference brackets" href="#hmm10" id="id72">10</a> is</p>
<div class="math notranslate nohighlight" id="equation-hmmeq85">
<span class="eqno">(86)<a class="headerlink" href="#equation-hmmeq85" title="公式的永久链接">¶</a></span>\[I_{\nu}^* = \mathrm{max}_{\lambda} \left[
\log(P(O^{\nu} \mid \lambda_{\nu})) - \log(\sum_{w = 1}^V P(O^{\nu} \mid \lambda_w))
\right]\]</div>
<p>i.e., choose <span class="math notranslate nohighlight">\(\lambda\)</span> so as to separate the correct model
<span class="math notranslate nohighlight">\(\lambda_{\nu}\)</span>, from all other models on the training sequence
<span class="math notranslate nohighlight">\(O^{\nu}\)</span>. By summing <a class="reference internal" href="#equation-hmmeq85">(86)</a> over all training sequences, one would
hope to attain the most separated set of models possible. Thus a possible
implementation would be</p>
<div class="math notranslate nohighlight" id="equation-hmmeq86">
<span class="eqno">(87)<a class="headerlink" href="#equation-hmmeq86" title="公式的永久链接">¶</a></span>\[I^* = \mathrm{max}_{\lambda} \left\{
\sum_{\nu = 1}^V \left[
\log(P(O^{\nu} \mid \lambda_{\nu})) - \log(\sum_{w = 1}^V P(O^{\nu} \mid \lambda_w))
\right]
\right\}.\]</div>
<p>There are various theoretical reasons why analytical (or reestimation type)
solutions to <a class="reference internal" href="#equation-hmmeq86">(87)</a> cannot be realized. Thus the only known way of
actually solving <a class="reference internal" href="#equation-hmmeq86">(87)</a> is via general optimization procedures like the
steepest descent methods <a class="reference internal" href="#ref32" id="id73"><span>[Ref32]</span></a>.</p>
<p>The second alternative philosophy is to assume that the signal to be modeled was
not necessarily generated by a Markov source, but does obey certain constraints
(e.g., positive definite correlation function) <a class="reference internal" href="#ref33" id="id74"><span>[Ref33]</span></a>. The goal of the design
procedure is therefore to choose HMM parameters which minimize the
discrimination information (DI) or the cross entropy between the set of valid
(i.e., which satisfy the measurements) signal probability densities (call this
set <span class="math notranslate nohighlight">\(Q\)</span>), and the set of HMM probability densities (call this set
<span class="math notranslate nohighlight">\(P_{\lambda}\)</span>), where the DI between <span class="math notranslate nohighlight">\(Q\)</span> and <span class="math notranslate nohighlight">\(P_{\lambda}\)</span> can
generally be written in the form</p>
<div class="math notranslate nohighlight" id="equation-hmmeq87">
<span class="eqno">(88)<a class="headerlink" href="#equation-hmmeq87" title="公式的永久链接">¶</a></span>\[D(Q \| P_{\lambda}) = \int q(y) \ln (q(y)/p(y)) dy\]</div>
<p>where <span class="math notranslate nohighlight">\(q\)</span> and <span class="math notranslate nohighlight">\(p\)</span> are the probability density functions
corresponding to <span class="math notranslate nohighlight">\(Q\)</span> and <span class="math notranslate nohighlight">\(P_{\lambda}\)</span>. Techniques for minimizing
<a class="reference internal" href="#equation-hmmeq87">(88)</a> (thereby giving an MDI solution) for the optimum values of
<span class="math notranslate nohighlight">\(\lambda = (A, B, \pi)\)</span> are highly nontrivial; however, they use a
generalized Baum algorithm as the core of each iteration, and thus are
efficiently tailored to hidden Markov modeling <a class="reference internal" href="#ref33" id="id75"><span>[Ref33]</span></a>.</p>
<p>It has been shown that the ML, MMI, and MDI approaches can all be uniformly
formulated as MDI approaches. <a class="footnote-reference brackets" href="#hmm11" id="id76">11</a> The three approaches differ in either
the probability density attributed to the source being modeled, or in the model
effectively being used. None of the approaches, however, assumes that the source
has the probability distribution of the model.</p>
</section>
<section id="comparison-of-hmms-ref34">
<h3>Comparison of HMMs <a class="reference internal" href="#ref34" id="id77"><span>[Ref34]</span></a><a class="headerlink" href="#comparison-of-hmms-ref34" title="永久链接至标题">¶</a></h3>
<p>An interesting question associated with HMMs is the following: Given two HMMs,
<span class="math notranslate nohighlight">\(\lambda_1\)</span> and <span class="math notranslate nohighlight">\(\lambda_2\)</span>, what is a reasonable measure of the
similarity of the two models? A key point here is the similarity criterion. By
way of example, consider the case of two models</p>
<div class="math notranslate nohighlight">
\[\lambda_1 = (A_1, B_1, \pi_1), \quad
\lambda_2 = (A_2, B_2, \pi_2)\]</div>
<p>with</p>
<div class="math notranslate nohighlight">
\[\begin{split}A_1 &amp;=
\begin{bmatrix}
p &amp; 1-p \\
1-p &amp; p
\end{bmatrix},\\
B_1 &amp;=
\begin{bmatrix}
q &amp; 1-q\\
1-q &amp; q
\end{bmatrix},\\
\pi_1 &amp;= (1/2, 1/2).\end{split}\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\begin{split}A_2 &amp;=
\begin{bmatrix}
r &amp; 1-r \\
1-r &amp; r
\end{bmatrix},\\
B_2 &amp;=
\begin{bmatrix}
s &amp; 1-s\\
1-s &amp; s
\end{bmatrix},\\
\pi_2 &amp;= (1/2, 1/2).\end{split}\]</div>
<p>For <span class="math notranslate nohighlight">\(\lambda_1\)</span> to be equivalent to <span class="math notranslate nohighlight">\(\lambda_2\)</span>, in the sense of
having the same statistical properties for the observation symbols, i.e.,
<span class="math notranslate nohighlight">\(E[O_t = v_k \mid \lambda_1] = E[O_t = v_k \mid \lambda_2]\)</span> for all
<span class="math notranslate nohighlight">\(v_k\)</span>, we require</p>
<div class="math notranslate nohighlight">
\[pq + (1-p)(1-q) = rs + (1-r)(1-s)\]</div>
<p>or, by solving for <span class="math notranslate nohighlight">\(s\)</span>, we get</p>
<div class="math notranslate nohighlight">
\[s = \dfrac{p + q - 2pq}{1 - 2r}.\]</div>
<p>By choosing (arbitrarily) <span class="math notranslate nohighlight">\(p = 0.6, q = 0.7, r = 0.2\)</span>, we get <span class="math notranslate nohighlight">\(s=
13/30 \approx 0.433\)</span>. Thus, even when the two models, <span class="math notranslate nohighlight">\(\lambda_1\)</span>, and
<span class="math notranslate nohighlight">\(\lambda_2\)</span>, look ostensibly very different (i.e., <span class="math notranslate nohighlight">\(A_1\)</span> is very
different from <span class="math notranslate nohighlight">\(A_2\)</span>, and <span class="math notranslate nohighlight">\(B_1\)</span> is very different from <span class="math notranslate nohighlight">\(B_2\)</span>),
statistical equivalence of the models can occur.</p>
<p>We can generalize the concept of model distance (dissimilarity) by defining a
distance measure <span class="math notranslate nohighlight">\(D(\lambda_1, \lambda_2)\)</span>, between two Markov models,
<span class="math notranslate nohighlight">\(\lambda_1\)</span>, and <span class="math notranslate nohighlight">\(\lambda_2\)</span>, as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq88">
<span class="eqno">(89)<a class="headerlink" href="#equation-hmmeq88" title="公式的永久链接">¶</a></span>\[D(\lambda_1, \lambda_2) = \dfrac{1}{T} \left[
\log(P(O^{(2)} \mid \lambda_1)) - \log(P(O^{(2)} \mid \lambda_2))
\right]\]</div>
<p>where <span class="math notranslate nohighlight">\(O^{(2)} = O_1 O_2 O_3 \cdots O_T\)</span> is a sequence of observations
generated by model <span class="math notranslate nohighlight">\(\lambda_2\)</span> <a class="reference internal" href="#ref34" id="id78"><span>[Ref34]</span></a>. Basically <a class="reference internal" href="#equation-hmmeq88">(89)</a> is a
measure of how well model <span class="math notranslate nohighlight">\(\lambda_1\)</span> matches observations generated by
model <span class="math notranslate nohighlight">\(\lambda_2\)</span>, relative to how well model <span class="math notranslate nohighlight">\(\lambda_2\)</span> matches
observations generated by itself. Several interpretations of <a class="reference internal" href="#equation-hmmeq88">(89)</a> exist
in terms of cross entropy, or divergence, or discrimination information
<a class="reference internal" href="#ref34" id="id79"><span>[Ref34]</span></a>.</p>
<p>One of the problems with the distance measure of <a class="reference internal" href="#equation-hmmeq88">(89)</a> is that it is
nonsymmetric. Hence a natural expression of this measure is the symmetrized
version, namely</p>
<div class="math notranslate nohighlight" id="equation-hmmeq89">
<span class="eqno">(90)<a class="headerlink" href="#equation-hmmeq89" title="公式的永久链接">¶</a></span>\[D_s(\lambda_1, \lambda_2) = \dfrac{D(\lambda_1 \lambda_2) + D(\lambda_2, \lambda_1)}{2}.\]</div>
</section>
</section>
<section id="implementation-issues-for-hmms">
<h2>IMPLEMENTATION ISSUES FOR HMMs<a class="headerlink" href="#implementation-issues-for-hmms" title="永久链接至标题">¶</a></h2>
<p>The discussion in the previous two sections has primarily dealt with the theory
of HMMs and several variations on the form of the model. In this section we deal
with several practical implementation issues including scaling, multiple
observation sequences, initial parameter estimates, missing data, and choice of
model size and type. For some of these implementation issues we can prescribe
exact analytical solutions; for other issues we can only provide some
seat-of-the-pants experience gained from working with HMMs over the last several
years.</p>
<section id="scaling-ref14">
<h3>Scaling <a class="reference internal" href="#ref14" id="id80"><span>[Ref14]</span></a><a class="headerlink" href="#scaling-ref14" title="永久链接至标题">¶</a></h3>
<p>In order to understand why scaling is required for implementing the reestimation
procedure of HMMs, consider the definition of <span class="math notranslate nohighlight">\(\alpha_t(i)\)</span> of
<a class="reference internal" href="#equation-hmmeq18">(18)</a>. It can be seen that <span class="math notranslate nohighlight">\(\alpha_t(i)\)</span> consists of the sum of a
large number of terms, each of the form</p>
<div class="math notranslate nohighlight">
\[\left(
\prod_{s = 1}^{t - 1} a_{q_s q_{s+1}} \prod_{s = 1}^t b_{q_s}(O_s)
\right)\]</div>
<p>with <span class="math notranslate nohighlight">\(q_t = S_i\)</span>. Since each <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> term is less than 1
(generally significantly less than 1), it can be seen that as <span class="math notranslate nohighlight">\(t\)</span> starts
to get big (e.g., 10 or more), each term of <span class="math notranslate nohighlight">\(\alpha_t(i)\)</span> starts to head
exponentially to zero. For sufficiently large <span class="math notranslate nohighlight">\(t\)</span> (e.g., 100 or more) the
dynamic range of the <span class="math notranslate nohighlight">\(\alpha_t(i)\)</span> computation will exceed the precision
range of essentially any machine (even in double precision). Hence the only
reasonable way of performing the computation is by incorporating a scaling
procedure.</p>
<p>The basic scaling procedure which is used is to multiply <span class="math notranslate nohighlight">\(\alpha_t(i)\)</span> by
a scaling coefficient that is independent of <span class="math notranslate nohighlight">\(i\)</span> (i.e., it depends only on
<span class="math notranslate nohighlight">\(t\)</span>), with the goal of keeping the scaled <span class="math notranslate nohighlight">\(\alpha_t(i)\)</span> within the
dynamic range of the computer for <span class="math notranslate nohighlight">\(1 \leq t \leq T\)</span>. A similar scaling is
done to the <span class="math notranslate nohighlight">\(\beta_t(i)\)</span> coefficients (since these also tend to zero
exponentially fast) and then, at the end of the computation, the scaling
coefficients are canceled out exactly.</p>
<p>To understand this scaling procedure better, consider the reestimation formula
for the state transition coefficients <span class="math notranslate nohighlight">\(a_{ij}\)</span>. If we write the
reestimation formula <a class="reference internal" href="#equation-hmmeq41">(41)</a> directly in terms of the forward and backward
variables we get</p>
<div class="math notranslate nohighlight" id="equation-hmmeq90">
<span class="eqno">(91)<a class="headerlink" href="#equation-hmmeq90" title="公式的永久链接">¶</a></span>\[\bar{a}_{ij} = \dfrac
{\sum_{t = 1}^{T-1} \alpha_t(i) a_{ij} b_j(O_{t+1}) \beta_{t+1}(j)}
{\sum_{t = 1}^{T-1} \sum_{j = 1}^N \alpha_t(i) a_{ij} b_j(O_{t+1}) \beta_{t+1}(j)}.\]</div>
<p>Consider the computation of <span class="math notranslate nohighlight">\(\alpha_t(i)\)</span>. For each <span class="math notranslate nohighlight">\(t\)</span>, we first
compute <span class="math notranslate nohighlight">\(\alpha_t(i)\)</span> according to the induction formula <a class="reference internal" href="#equation-hmmeq20">(20)</a>,
and then we multiply it by a scaling coefficient <span class="math notranslate nohighlight">\(c_t\)</span>, where</p>
<div class="math notranslate nohighlight" id="equation-hmmeq91">
<span class="eqno">(92)<a class="headerlink" href="#equation-hmmeq91" title="公式的永久链接">¶</a></span>\[c_t = \dfrac{1}
{\sum_{i = 1}^N \alpha_t(i)}.\]</div>
<p>Thus, for a fixed <span class="math notranslate nohighlight">\(t\)</span>, we first compute</p>
<div class="math notranslate nohighlight" id="equation-hmmeq92a">
<span class="eqno">(93)<a class="headerlink" href="#equation-hmmeq92a" title="公式的永久链接">¶</a></span>\[\alpha_t(i) = \sum_{j=1}^N \hat{\alpha}_{t-1}(j) a_{ij} b_j(O_t).\]</div>
<p>Then the scaled coefficient set <span class="math notranslate nohighlight">\(\hat{\alpha}_t(i)\)</span> is computed as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq92b">
<span class="eqno">(94)<a class="headerlink" href="#equation-hmmeq92b" title="公式的永久链接">¶</a></span>\[\hat{\alpha}_t(i) = \dfrac
{\sum_{j=1}^N \hat{\alpha}_{t-1}(j) a_{ij} b_j(O_t)}
{\sum_{i=1}^N \sum_{j=1}^N \hat{\alpha}_{t-1}(j) a_{ij} b_j(O_t)}.\]</div>
<p>By induction we can write <span class="math notranslate nohighlight">\(\hat{\alpha}_{t-1}(j)\)</span> as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq93a">
<span class="eqno">(95)<a class="headerlink" href="#equation-hmmeq93a" title="公式的永久链接">¶</a></span>\[\hat{\alpha}_{t-1}(j) = \left(
\prod_{\tau = 1}^{t - 1} c_{\tau}
\right)
\alpha_{t-1}(j).\]</div>
<p>Thus we can write <span class="math notranslate nohighlight">\(\hat{\alpha}_{t}(i)\)</span> as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq93b">
<span class="eqno">(96)<a class="headerlink" href="#equation-hmmeq93b" title="公式的永久链接">¶</a></span>\[\hat{\alpha}_{t}(i) = \dfrac
{\sum_{j=1}^N \alpha_{t-1}(j) \left(
\prod_{\tau = 1}^{t - 1} c_{\tau}
\right) a_{ij} b_j(O_t)}
{\sum_{i=1}^N \sum_{j=1}^N \alpha_{t-1}(j) \left(
\prod_{\tau = 1}^{t - 1} c_{\tau}
\right) a_{ij} b_j(O_t)}
= \dfrac
{\alpha_t(i)}
{\sum_{i=1}^N \alpha_t(i)}\]</div>
<p>i.e., each <span class="math notranslate nohighlight">\(\alpha_t(i)\)</span> is effectively scaled by the sum over all states
of <span class="math notranslate nohighlight">\(\alpha_t(i)\)</span>.</p>
<p>Next we compute the <span class="math notranslate nohighlight">\(\beta_t(i)\)</span> terms from the backward recursion. The
only difference here is that we use the same scale factors for each time
<span class="math notranslate nohighlight">\(t\)</span> for the betas as was used for the alphas. Hence the scaled
<span class="math notranslate nohighlight">\(\beta\)</span>’s are of the form</p>
<div class="math notranslate nohighlight" id="equation-hmmeq94">
<span class="eqno">(97)<a class="headerlink" href="#equation-hmmeq94" title="公式的永久链接">¶</a></span>\[\hat{\beta}_t(i) = c_t \beta_t(i).\]</div>
<p>Since each scale factor effectively restores the magnitude of the <span class="math notranslate nohighlight">\(\alpha\)</span>
terms to 1, and since the magnitudes of the <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span>
terms are comparable, using the same scaling factors on the <span class="math notranslate nohighlight">\(\beta\)</span>’s as
was used on the <span class="math notranslate nohighlight">\(\alpha\)</span>’s is an effective way of keeping the computation
within reasonable bounds. Furthermore, in terms of the scaled variables we see
that the reestimation equation <a class="reference internal" href="#equation-hmmeq90">(91)</a> becomes</p>
<div class="math notranslate nohighlight" id="equation-hmmeq95">
<span class="eqno">(98)<a class="headerlink" href="#equation-hmmeq95" title="公式的永久链接">¶</a></span>\[\bar{a}_{ij} = \dfrac
{\sum_{t=1}^{T-1} \hat{\alpha}_t(i) a_{ij} b_j(O_{t+1}) \hat{\beta}_{t+1}(j)}
{\sum_{t=1}^{T-1} \sum_{j=1}^N \hat{\alpha}_t(i) a_{ij} b_j(O_{t+1}) \hat{\beta}_{t+1}(j)}\]</div>
<p>but each <span class="math notranslate nohighlight">\(\hat{\alpha}_t(i)\)</span> can be written as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq96">
<span class="eqno">(99)<a class="headerlink" href="#equation-hmmeq96" title="公式的永久链接">¶</a></span>\[\hat{\alpha}_t(i) = \left[
\prod_{s=1}^t c_s
\right]
\alpha_t(i) = C_t \alpha_t(i)\]</div>
<p>and each <span class="math notranslate nohighlight">\(\hat{\beta}_{t+1}(j)\)</span> can be written as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq97">
<span class="eqno">(100)<a class="headerlink" href="#equation-hmmeq97" title="公式的永久链接">¶</a></span>\[\hat{\beta}_{t+1}(j) = \left[
\prod_{s=t+1}^T c_s
\right]
\beta_{t+1}(j) = D_{t+1} \beta_{t+1}(j).\]</div>
<p>Thus <a class="reference internal" href="#equation-hmmeq95">(98)</a> can be written as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq98">
<span class="eqno">(101)<a class="headerlink" href="#equation-hmmeq98" title="公式的永久链接">¶</a></span>\[\bar{\alpha}_{ij} = \dfrac
{\sum_{t=1}^{T-1} C_t \alpha_t(i) a_{ij} b_j(O_{t+1}) D_{t+1} \beta_{t+1}(j)}
{\sum_{t=1}^{T-1} \sum_{j=1}^N C_t \alpha_t(i) a_{ij} b_j(O_{t+1}) D_{t+1} \beta_{t+1}(j)}.\]</div>
<p>Finally the term <span class="math notranslate nohighlight">\(C_t D_{t+1}\)</span> can be seen to be of the form</p>
<div class="math notranslate nohighlight" id="equation-hmmeq99">
<span class="eqno">(102)<a class="headerlink" href="#equation-hmmeq99" title="公式的永久链接">¶</a></span>\[C_t D_{t+1} = \prod_{s=1}^t c_s \prod_{s=t+1}^T c_s = \prod_{s=1}^T c_s = C_T\]</div>
<p>independent of <span class="math notranslate nohighlight">\(t\)</span>. Hence the terms <span class="math notranslate nohighlight">\(C_t D_{t+1}\)</span> cancel out of both
the numerator and denominator of <a class="reference internal" href="#equation-hmmeq98">(101)</a> and the exact reestimation
equation is therefore realized.</p>
<p>It should be obvious that the above scaling procedure applies equally well to
reestimation of the <span class="math notranslate nohighlight">\(\pi\)</span> or <span class="math notranslate nohighlight">\(B\)</span> coefficients. It should also be
obvious that the scaling procedure of <a class="reference internal" href="#equation-hmmeq92a">(93)</a> and <a class="reference internal" href="#equation-hmmeq92b">(94)</a> need not
be applied at every time instant <span class="math notranslate nohighlight">\(t\)</span>, but can be performed whenever
desired, or necessary (e.g., to prevent underflow). If scaling is not performed
at some instant <span class="math notranslate nohighlight">\(t\)</span>, the scaling coefficients <span class="math notranslate nohighlight">\(c_t\)</span>, are set to
<span class="math notranslate nohighlight">\(1\)</span> at that time and all the conditions discussed above are then met.</p>
<p>The only real change to the HMM procedure because of scaling is the procedure
for computing <span class="math notranslate nohighlight">\(P(O \mid \lambda)\)</span>. We cannot merely sum up the
<span class="math notranslate nohighlight">\(\hat{\alpha_T(i)}\)</span> terms since these are scaled already. However, we can
use the property that</p>
<div class="math notranslate nohighlight" id="equation-hmmeq100">
<span class="eqno">(103)<a class="headerlink" href="#equation-hmmeq100" title="公式的永久链接">¶</a></span>\[\prod_{t=1}^T c_t \sum_{i=1}^N \alpha_T(i) = C_T \sum_{i=1}^N \alpha_T(i) = 1.\]</div>
<p>Thus we have</p>
<div class="math notranslate nohighlight" id="equation-hmmeq101">
<span class="eqno">(104)<a class="headerlink" href="#equation-hmmeq101" title="公式的永久链接">¶</a></span>\[\prod_{t=1}^T c_t \cdot P(O \mid \lambda) = 1\]</div>
<p>or</p>
<div class="math notranslate nohighlight" id="equation-hmmeq102">
<span class="eqno">(105)<a class="headerlink" href="#equation-hmmeq102" title="公式的永久链接">¶</a></span>\[P(O \mid \lambda) = \dfrac{1}{\prod_{t=1}^T c_t}\]</div>
<p>or</p>
<div class="math notranslate nohighlight" id="equation-hmmeq103">
<span class="eqno">(106)<a class="headerlink" href="#equation-hmmeq103" title="公式的永久链接">¶</a></span>\[\log P(O \mid \lambda) = - \sum_{t=1}^T \log c_t.\]</div>
<p>Thus the log of <span class="math notranslate nohighlight">\(P\)</span> can be computed, but not <span class="math notranslate nohighlight">\(P\)</span> since it would
be out of the dynamic range of the machine anyway.</p>
<p>Finally we note that when using the Viterbi algorithm to give the maximum
likelihood state sequence, no scaling is required if we use logarithms in the
following way. (Refer back to <a class="reference internal" href="#equation-hmmeq32">(32)</a>, <a class="reference internal" href="#equation-hmmeq33">(33)</a>, <a class="reference internal" href="#equation-hmmeq34">(34)</a>.) We
define</p>
<div class="math notranslate nohighlight" id="equation-hmmeq104">
<span class="eqno">(107)<a class="headerlink" href="#equation-hmmeq104" title="公式的永久链接">¶</a></span>\[\phi_t(i) = \mathrm{max}_{q_1, q_2, \ldots, q_t} \left\{
\log P[q_1 q_2 \cdots q_t, O_1 O_2 \cdots O_t \mid \lambda]
\right\}\]</div>
<p>and initially set</p>
<div class="math notranslate nohighlight" id="equation-hmmeq105a">
<span class="eqno">(108)<a class="headerlink" href="#equation-hmmeq105a" title="公式的永久链接">¶</a></span>\[\phi_1(i) = \log(\pi_i) + \log b_i(O_1)\]</div>
<p>with the recursion step</p>
<div class="math notranslate nohighlight" id="equation-hmmeq105b">
<span class="eqno">(109)<a class="headerlink" href="#equation-hmmeq105b" title="公式的永久链接">¶</a></span>\[\phi_t(j) = \mathrm{max}_{1 \leq i \leq N} \left[
\phi_{t-1}(i) + \log(a_{ij}) + \log b_j(O_t)
\right]\]</div>
<p>and termination step</p>
<div class="math notranslate nohighlight" id="equation-hmmeq105c">
<span class="eqno">(110)<a class="headerlink" href="#equation-hmmeq105c" title="公式的永久链接">¶</a></span>\[\log(P^*) = \mathrm{max}_{1 \leq i \leq N} \phi_T(i).\]</div>
<p>Again we arrive at <span class="math notranslate nohighlight">\(\log P^*\)</span> rather than <span class="math notranslate nohighlight">\(P^*\)</span>, but with
significantly less computation and with no numerical problems. (The reader
should note that the terms <span class="math notranslate nohighlight">\(\log a_{ij}\)</span>, of <a class="reference internal" href="#equation-hmmeq105b">(109)</a> can be
precomputed and therefore do not cost anything in the computation. Furthermore,
the terms <span class="math notranslate nohighlight">\(\log b_j(O_t)\)</span> can be precomputed when a finite observation
symbol analysis (e.g., a codebook of observation sequences) is used.</p>
</section>
<section id="multiple-observation-sequences-ref14">
<h3>Multiple Observation Sequences <a class="reference internal" href="#ref14" id="id81"><span>[Ref14]</span></a><a class="headerlink" href="#multiple-observation-sequences-ref14" title="永久链接至标题">¶</a></h3>
<p>In Section IV we discussed a form of HMM called the left-right or Bakis model in
which the state proceeds from state 1 at <span class="math notranslate nohighlight">\(t = 1\)</span> to state <span class="math notranslate nohighlight">\(N\)</span> at
<span class="math notranslate nohighlight">\(t = T\)</span> in a sequential manner (recall the model of <a class="reference internal" href="#hmmfig7"><span class="std std-numref">图 7</span></a>
(b)). We have already discussed how a left-right model imposes constraints on
the state transition matrix, and the initial state probabilities <a class="reference internal" href="#equation-hmmeq45">(45)</a> -
<a class="reference internal" href="#equation-hmmeq48">(48)</a>. However, the major problem with left-right models is that one
cannot use a single observation sequence to train the model (i.e., for
reestimation of model parameters). This is because the transient nature of the
states within the model only allow a small number of observations for any state
(until a tran- sition is made to a successor state). Hence, in order to have
sufficient data to make reliable estimates of all model parameters, one has to
use multiple observation sequences.</p>
<p>The modification of the reestimation procedure is straightforward and goes as
follows. We denote the set of <span class="math notranslate nohighlight">\(K\)</span> observation sequences as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq106">
<span class="eqno">(111)<a class="headerlink" href="#equation-hmmeq106" title="公式的永久链接">¶</a></span>\[\mathbf{O} = [\mathbf{O}^{(1)}, \mathbf{O}^{(2)}, \ldots, \mathbf{O}^{(k)}]\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{O}^{(k)} = [O_1^{(k)} O_2^{(2)} \cdots O_{T_k}^{(k)}]\)</span> is
the <span class="math notranslate nohighlight">\(k\)</span>-th observation sequence. We assume each observation sequence is
independent of every other observation sequence, and our goal is to adjust the
parameters of the model <span class="math notranslate nohighlight">\(\lambda\)</span> to maximize</p>
<div class="math notranslate nohighlight" id="equation-hmmeq107">
<span class="eqno">(112)<a class="headerlink" href="#equation-hmmeq107" title="公式的永久链接">¶</a></span>\[\begin{split}P(O \mid \lambda) &amp;= \prod_{k = 1}^K P(\mathbf{O}^{(k)} \mid \lambda) \\
&amp;= \prod_{k=1}^K P_k.\end{split}\]</div>
<p>Since the reestimation formulas are based on frequencies of occurrence of
various events, the reestimation formulas for multiple observation sequences are
modified by adding together the individual frequencies of occurrence for each
sequence. Thus the modified reestimation formulas for <span class="math notranslate nohighlight">\(\bar{a}_{ij}\)</span> and
<span class="math notranslate nohighlight">\(\bar{b}_j(\ell)\)</span> are</p>
<div class="math notranslate nohighlight" id="equation-hmmeq109">
<span class="eqno">(113)<a class="headerlink" href="#equation-hmmeq109" title="公式的永久链接">¶</a></span>\[\bar{a}_{ij} = \dfrac
{\sum_{k=1}^K \dfrac{1}{P_k} \sum_{t=1}^{T_k-1} \alpha_t^k(i) a_{ij} b_j(O_{t+1}^{(k)}) \beta_{t+1}^k(j)}
{\sum_{k=1}^K \dfrac{1}{P_k} \sum_{t=1}^{T_k-1} \alpha_t^k(i) \beta_{t+1}^k(j)}\]</div>
<p>and</p>
<div class="math notranslate nohighlight" id="equation-hmmeq110">
<span class="eqno">(114)<a class="headerlink" href="#equation-hmmeq110" title="公式的永久链接">¶</a></span>\[\bar{b}_j{\ell} = \dfrac
{\sum_{k=1}^K \dfrac{1}{P_k} \sum_{t=1, \text{ s.t. } O_t = v_t}^{T_k-1} \alpha_t^k(i) \beta_t^k(i)}
{\sum_{k=1}^K \dfrac{1}{P_k} \sum_{t=1}^{T_k-1} \alpha_t^k(i) \beta_t^k(i)}\]</div>
<p>and <span class="math notranslate nohighlight">\(\pi\)</span> is not reestimated since <span class="math notranslate nohighlight">\(\pi_1 = 1, \pi_i = 0, i \neq 1\)</span>.</p>
<p>The proper scaling of <a class="reference internal" href="#equation-hmmeq109">(113)</a> - <a class="reference internal" href="#equation-hmmeq110">(114)</a> is now straightforward
since each observation sequence has its own scaling factor. The key idea is to
remove the scaling factor from each term before summing. This can be
accomplished by writing the reestimation equations in terms of the scaled
variables, i.e.,</p>
<div class="math notranslate nohighlight" id="equation-hmmeq111">
<span class="eqno">(115)<a class="headerlink" href="#equation-hmmeq111" title="公式的永久链接">¶</a></span>\[\bar{a}_{ij} = \dfrac
{\sum_{k=1}^K \dfrac{1}{P_k} \sum_{t=1}^{T_k-1} \hat{\alpha}_t^k(i) a_{ij} b_j(O_{t+1}^{(k)}) \hat{\beta}_t^k(i)}
{\sum_{k=1}^K \dfrac{1}{P_k} \sum_{t=1}^{T_k-1} \hat{\alpha}_t^k(i) \hat{\beta}_t^k(i)}.\]</div>
<p>In this manner, for each sequence <span class="math notranslate nohighlight">\(O^{(k)}\)</span>, the same scale factors will
appear in each term of the sum over <span class="math notranslate nohighlight">\(t\)</span> as appears in the <span class="math notranslate nohighlight">\(P_k\)</span>
term, and hence will cancel exactly. Thus using the scaled values of the alphas
and betas results in an unscaled <span class="math notranslate nohighlight">\(\bar{a}_{ij}\)</span>. A similar result is
obtained for the <span class="math notranslate nohighlight">\(\bar{b}_j(\ell)\)</span> term.</p>
</section>
<section id="initial-estimates-of-hmm-parameters">
<h3>Initial Estimates of HMM Parameters<a class="headerlink" href="#initial-estimates-of-hmm-parameters" title="永久链接至标题">¶</a></h3>
<p>In theory, the reestimation equations should give values of the HMM parameters
which correspond to a local maximum of the likelihood function. A key question
is therefore how do we choose initial estimates of the HMM parameters so that
the local maximum is the global maximum of the likelihood function.</p>
<p>Basically there is no simple or straightforward answer to the above question.
Instead, experience has shown that either random (subject to the stochastic and
the nonzero value constraints) or uniform initial estimates of the <span class="math notranslate nohighlight">\(\pi\)</span>
and <span class="math notranslate nohighlight">\(A\)</span> parameters is adequate for giving useful reestimates of these
parameters in almost all cases. However, for the <span class="math notranslate nohighlight">\(B\)</span> parameters,
experience has shown that good initial estimates are helpful in the discrete
symbol case, and are essential (when dealing with multiple mixtures) in the
continuous distribution case <a class="reference internal" href="#ref35" id="id82"><span>[Ref35]</span></a>. Such initial estimates can be obtained in
a number of ways, including manual segmentation of the observation sequence(s)
into states with averaging of observations within states, maximum likelihood
segmentation of observations with averaging, and segmental <span class="math notranslate nohighlight">\(k\)</span>-means
segmentation with clustering, etc. We discuss such segmentation techniques later
in this paper.</p>
</section>
<section id="effects-of-insufficient-training-data-ref36">
<h3>Effects of Insufficient Training Data <a class="reference internal" href="#ref36" id="id83"><span>[Ref36]</span></a><a class="headerlink" href="#effects-of-insufficient-training-data-ref36" title="永久链接至标题">¶</a></h3>
<p>Another problem associated with training HMM parameters via reestimation methods
is that the observation sequence used for training is, of necessity, finite.
Thus there is often an insufficient number of occurrences of different model
events (e.g., symbol occurrences within states) to give good estimates of the
model parameters. One solution to this problem is to increase the size of the
training observation set. Often this is impractical. A second possible solution
is to reduce the size of the model (e.g., number of states, number of symbols
per state, etc). Although this is always possible, often there are physical
reasons why a given model is used and therefore the model size cannot be
changed. A third possible solution is to interpolate one set of parameter
estimates with another set of parameter estimates from a model for which an
adequate amount of training data exists <a class="reference internal" href="#ref36" id="id84"><span>[Ref36]</span></a>. The idea is to simultaneously
design both the desired model as well as a smaller model for which the amount of
training data is adequate to give good parameter estimates, and then to
interpolate the parameter estimates from the two models. The way in which the
smaller model is chosen is by tieing one or more sets of parameters of the
initial model to create the smaller model. Thus if we have estimates for the
parameters for the model <span class="math notranslate nohighlight">\(\lambda = (A, B, \pi)\)</span>, as well as for the
reduced size model <span class="math notranslate nohighlight">\(\lambda^{\prime} = (A^{\prime}, B^{\prime}, K^{\prime})\)</span>,
then the interpolated model, <span class="math notranslate nohighlight">\(\tilde{\lambda} = (\tilde{A}, \tilde{B}, \tilde{\pi})\)</span>,
is obtained as</p>
<div class="math notranslate nohighlight" id="equation-hmmeq112">
<span class="eqno">(116)<a class="headerlink" href="#equation-hmmeq112" title="公式的永久链接">¶</a></span>\[\tilde{\lambda} = \epsilon \lambda + (1 - \epsilon) \lambda^{\prime}\]</div>
<p>where <span class="math notranslate nohighlight">\(\epsilon\)</span> represents the weighting of the parameters of the full
model, and <span class="math notranslate nohighlight">\((1 - \epsilon)\)</span> represents the weighting of the parameters of
the reduced model. A key issue is the determination of the optimal value of
<span class="math notranslate nohighlight">\(\epsilon\)</span>, which is clearly a function of the amount of training data.
(As the amount of training data gets large, we expect <span class="math notranslate nohighlight">\(\epsilon\)</span> to tend
to <span class="math notranslate nohighlight">\(1.0\)</span>; similarly for small amounts of training data we expect
<span class="math notranslate nohighlight">\(\epsilon\)</span> to tend to <span class="math notranslate nohighlight">\(0.0\)</span>.) The solution to the determination of
an optimal value for <span class="math notranslate nohighlight">\(\epsilon\)</span> was provided by Jelinek and Mercer
<a class="reference internal" href="#ref36" id="id85"><span>[Ref36]</span></a> who showed how the optimal value for <span class="math notranslate nohighlight">\(\epsilon\)</span> could be
estimated using the forward-backward algorithm by interpreting <a class="reference internal" href="#equation-hmmeq112">(116)</a> as
an expanded HMM of the type shown in <a class="reference internal" href="#hmmfig10"><span class="std std-numref">图 10</span></a>. For this expanded model
the parameter <span class="math notranslate nohighlight">\(\epsilon\)</span> is the probability of a state transition from the
(neutral) state <span class="math notranslate nohighlight">\(\tilde{s}\)</span> to the model <span class="math notranslate nohighlight">\(\lambda\)</span>; similarly
<span class="math notranslate nohighlight">\((1 - \epsilon)\)</span> is the probability of a state transition from
<span class="math notranslate nohighlight">\(\tilde{s}\)</span> to the model <span class="math notranslate nohighlight">\(\lambda^{\prime}\)</span>. Between each of the
models, <span class="math notranslate nohighlight">\(\lambda\)</span> and <span class="math notranslate nohighlight">\(\lambda^{\prime}\)</span>, and <span class="math notranslate nohighlight">\(\tilde{s}\)</span>,
there is a null transition. Using the model of <a class="reference internal" href="#hmmfig9"><span class="std std-numref">图 9</span></a>, the value of
<span class="math notranslate nohighlight">\(\epsilon\)</span> can be estimated from the training data in the standard manner.
A key point is to segment the training data <span class="math notranslate nohighlight">\(T\)</span> into two disjoint sets,
i.e., <span class="math notranslate nohighlight">\(T = T_1 \cup T_2\)</span>. Training set <span class="math notranslate nohighlight">\(T_1\)</span> is first used to train
models <span class="math notranslate nohighlight">\(\lambda\)</span> and <span class="math notranslate nohighlight">\(\lambda^{\prime}\)</span> (i.e., to give estimates of
<span class="math notranslate nohighlight">\((A, B, \pi)\)</span> and <span class="math notranslate nohighlight">\((A^{\prime}, B^{\prime}, \pi^{\prime})\)</span>. Training
set <span class="math notranslate nohighlight">\(T_2\)</span> is then used to give an estimate of <span class="math notranslate nohighlight">\(\epsilon\)</span>, assuming
the models <span class="math notranslate nohighlight">\(\lambda\)</span> and <span class="math notranslate nohighlight">\(\lambda^{\prime}\)</span> are fixed. A modified
version of this training procedure, called the method of deleted interpolation
<a class="reference internal" href="#ref36" id="id86"><span>[Ref36]</span></a>, iterates the above procedure through multiple partitions of the
training set. For example one might consider a partition of the training set
such that <span class="math notranslate nohighlight">\(T_1\)</span> is 90 percent of <span class="math notranslate nohighlight">\(T\)</span> and <span class="math notranslate nohighlight">\(T_2\)</span> is the
remaining 10 percent of <span class="math notranslate nohighlight">\(T\)</span>. There are a large number of ways in which
such a partitioning can be accomplished but one particularly simple one is to
cycle <span class="math notranslate nohighlight">\(T_2\)</span> through the data, i.e., the first partition uses the last 10
percent of the data as <span class="math notranslate nohighlight">\(T_2\)</span>, the second partition uses the next-to-last
10 percent of the data as <span class="math notranslate nohighlight">\(T_2\)</span>, etc.</p>
<figure class="align-center" id="id111">
<span id="hmmfig10"></span><img alt="_images/hmmfig10.png" src="_images/hmmfig10.png" />
<figcaption>
<p><span class="caption-number">图 10 </span><span class="caption-text">Example of how the process of deleted interpolation can be represented using
a state diagram.</span><a class="headerlink" href="#id111" title="永久链接至图片">¶</a></p>
</figcaption>
</figure>
<p>The technique of deleted interpolation has been successfully applied to a number
of problems in speech recognition including the estimation of trigram word
probabilities for language models <a class="reference internal" href="#ref13" id="id87"><span>[Ref13]</span></a>, and the estimation of HMM output
probabilities for trigram phone models <a class="reference internal" href="#ref37" id="id88"><span>[Ref37]</span></a>, <a class="reference internal" href="#ref38" id="id89"><span>[Ref38]</span></a>.</p>
<p>Another way of handling the effects of insufficient training data is to add
extra constraints to the model parameters to insure that no model parameter
estimate falls below a specified level. Thus, for example, we might specify the
constraint, for a discrete symbol model, that</p>
<div class="math notranslate nohighlight" id="equation-hmmeq113a">
<span class="eqno">(117)<a class="headerlink" href="#equation-hmmeq113a" title="公式的永久链接">¶</a></span>\[b_j(k) \geq \delta\]</div>
<p>or, for a continuous distribution model, that</p>
<div class="math notranslate nohighlight" id="equation-hmmeq113b">
<span class="eqno">(118)<a class="headerlink" href="#equation-hmmeq113b" title="公式的永久链接">¶</a></span>\[U_{jk}(r, r) \geq \delta.\]</div>
<p>The constraints can be applied as a postprocessor to the reestimation equations
such that if a constraint is violated, the relevant parameter is manually
corrected, and all remaining parameters are rescaled so that the densities obey
the required stochastic constraints. Such post-processor techniques have been
applied to several problems in speech processing with good success <a class="reference internal" href="#ref39" id="id90"><span>[Ref39]</span></a>. It
can be seen from <a class="reference internal" href="#equation-hmmeq112">(116)</a> that this procedure is essentially equivalent to
a simple form of deleted interpolation in which the model
<span class="math notranslate nohighlight">\(\lambda^{\prime}\)</span> is a uniform distribution model, and the interpolation
value <span class="math notranslate nohighlight">\(\epsilon\)</span> is chosen as the fixed constant <span class="math notranslate nohighlight">\((1 - \delta)\)</span>.</p>
</section>
<section id="choice-of-model">
<h3>Choice of Model<a class="headerlink" href="#choice-of-model" title="永久链接至标题">¶</a></h3>
<p>The remaining issue in implementing HMMs is the choice of type of model (ergodic
or left-right or some other form), choice of model size (number of states), and
choice of observation symbols (discrete or continuous, single or multi-mixture,
choice of observation parameters). Unfortunately, there is no simple,
theoretically correct, way of making such choices. These choices must be made
depending on the signal being modeled. With these comments we end our discussion
of the theoretical aspects of hidden Markov models, and proceed to a discussion
of how such models have been applied to selected problems in speech recognition.</p>
</section>
</section>
<section id="implementation-of-speech-recognizers-using-hmms">
<h2>IMPLEMENTATION OF SPEECH RECOGNIZERS USING HMMs<a class="headerlink" href="#implementation-of-speech-recognizers-using-hmms" title="永久链接至标题">¶</a></h2>
<p>TBA.</p>
</section>
<section id="connected-word-recognition-using-hmms-ref59-ref63">
<h2>CONNECTED WORD RECOGNITION USING HMMs <a class="reference internal" href="#ref59" id="id91"><span>[Ref59]</span></a> - <a class="reference internal" href="#ref63" id="id92"><span>[Ref63]</span></a><a class="headerlink" href="#connected-word-recognition-using-hmms-ref59-ref63" title="永久链接至标题">¶</a></h2>
<p>TBA.</p>
</section>
<section id="hmms-for-large-vocabulary-speech-recognition-ref6-ref13-ref31-ref37-ref38-ref51-ref64-ref66">
<h2>HMMs FOR LARGE VOCABULARY SPEECH RECOGNITION <a class="reference internal" href="#ref6" id="id93"><span>[Ref6]</span></a> - <a class="reference internal" href="#ref13" id="id94"><span>[Ref13]</span></a>, <a class="reference internal" href="#ref31" id="id95"><span>[Ref31]</span></a>, <a class="reference internal" href="#ref37" id="id96"><span>[Ref37]</span></a>, <a class="reference internal" href="#ref38" id="id97"><span>[Ref38]</span></a>, <a class="reference internal" href="#ref51" id="id98"><span>[Ref51]</span></a>, <a class="reference internal" href="#ref64" id="id99"><span>[Ref64]</span></a> - <a class="reference internal" href="#ref66" id="id100"><span>[Ref66]</span></a><a class="headerlink" href="#hmms-for-large-vocabulary-speech-recognition-ref6-ref13-ref31-ref37-ref38-ref51-ref64-ref66" title="永久链接至标题">¶</a></h2>
<p>TBA.</p>
<p class="rubric">Footnotes</p>
<dl class="footnote brackets">
<dt class="label" id="hmm1"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>The idea of characterizing the theoretical aspects of hidden Markov
modeling in terms of solving three fundamental problems is due to
Jack Ferguson of IDA (Institute for Defense Analysis) who introduced
it in lectures and writing.</p>
</dd>
<dt class="label" id="hmm2"><span class="brackets"><a class="fn-backref" href="#id21">2</a></span></dt>
<dd><p>A good overview of discrete Markov processes is in <a class="reference internal" href="#ref20" id="id101"><span>[Ref20]</span></a> ch. 5.</p>
</dd>
<dt class="label" id="hmm3"><span class="brackets"><a class="fn-backref" href="#id22">3</a></span></dt>
<dd><p>The model of <a class="reference internal" href="#hmmfig2"><span class="std std-numref">图 2</span></a> (a) is a memoryless process and thus
is a degenerate case of a Markov model.</p>
</dd>
<dt class="label" id="hmm4"><span class="brackets"><a class="fn-backref" href="#id23">4</a></span></dt>
<dd><p>The urn and ball model was introduced by Jack Ferguson, and his
colleagues, in lectures on HMM theory.</p>
</dd>
<dt class="label" id="hmm5"><span class="brackets"><a class="fn-backref" href="#id24">5</a></span></dt>
<dd><p>The material in this section and in Section III is based on the ideas
presented by Jack Ferguson of IDA in lectures at Bell Laboratories.</p>
</dd>
<dt class="label" id="hmm6"><span class="brackets"><a class="fn-backref" href="#id25">6</a></span></dt>
<dd><p>Strictly speaking, we only need the forward part of the
forward-backward procedure to solve Problem 1. We will introduce the
backward part of the procedure in this section since it will be used
to help solve Problem 3.</p>
</dd>
<dt class="label" id="hmm7"><span class="brackets"><a class="fn-backref" href="#id28">7</a></span></dt>
<dd><p>Again we remind the reader that the backward procedure will be used
in the solution to Problem 3, and is not required for the solution of
Problem 1.</p>
</dd>
<dt class="label" id="hmm8"><span class="brackets"><a class="fn-backref" href="#id60">8</a></span></dt>
<dd><p>In cases wherea Bakis type model is used, i.e., left-right models
where the number of states is proportional to the average duration,
explicit inclusion of state duration density is neither necessary nor
is it useful.</p>
</dd>
<dt class="label" id="hmm9"><span class="brackets"><a class="fn-backref" href="#id63">9</a></span></dt>
<dd><p>Again the ideas behind using explicit state duration densities are
due to Jack Ferguson of IDA. Most of the material in this section is
based on Ferguson’s original work.</p>
</dd>
<dt class="label" id="hmm10"><span class="brackets"><a class="fn-backref" href="#id72">10</a></span></dt>
<dd><p>In <a class="reference internal" href="#equation-hmmeq85">(86)</a> and <a class="reference internal" href="#equation-hmmeq86">(87)</a> we assume that all words are
equiprobable, i.e., <span class="math notranslate nohighlight">\(p(w) = 1/V\)</span>.</p>
</dd>
<dt class="label" id="hmm11"><span class="brackets"><a class="fn-backref" href="#id76">11</a></span></dt>
<dd><p>Y. Ephraim and L. Rabiner, “On the Relations Between Modeling
Approaches for Speech Recognition,” to appear in IEEE TRANSACTIONS
ON INFORMATION THEORY.</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="ref1"><span class="brackets">Ref1</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id31">2</a>)</span></dt>
<dd><p>L. E. Baum and T. Petrie, “Statistical inference for probabilistic
functions of finite state Markov chains”, Ann. Math. Stat., vol. 37,
pp. 1554-1563, 1966.</p>
</dd>
<dt class="label" id="ref2"><span class="brackets">Ref2</span><span class="fn-backref">(<a href="#id3">1</a>,<a href="#id26">2</a>)</span></dt>
<dd><p>L. E. Baum and J. A. Egon, “An inequality with applications to
statistical estimation for probabilistic functions of a Markov process
and to a model for ecology”, Bull. Amer. Meteorol. Soc., vol. 73, pp.
360-363, 1967.</p>
</dd>
<dt class="label" id="ref3"><span class="brackets">Ref3</span><span class="fn-backref">(<a href="#id4">1</a>,<a href="#id27">2</a>,<a href="#id36">3</a>,<a href="#id38">4</a>)</span></dt>
<dd><p>L. E. Baum and G. R. Sell, “Growth functions for transformations on
manifolds”, Pac. J. Math., vol. 27, no. 2, pp. 211-227, 1968.</p>
</dd>
<dt class="label" id="ref4"><span class="brackets"><a class="fn-backref" href="#id5">Ref4</a></span></dt>
<dd><p>L. E. Baum, T. Petrie, G. Soules and N. Weiss, “A maximization
technique occurring in the statistical analysis of probabilistic
functions of Markov chains”, Ann. Math. Stat., vol. 41, no. 1, pp.
164-171, 1970.</p>
</dd>
<dt class="label" id="ref5"><span class="brackets">Ref5</span><span class="fn-backref">(<a href="#id6">1</a>,<a href="#id32">2</a>)</span></dt>
<dd><p>L. E. Baum, “An inequality and associated maximization technique in
statistical estimation for probabilistic functions of Markov
processes”, Inequalities, vol. 3, pp. 1-8, 1972.</p>
</dd>
<dt class="label" id="ref6"><span class="brackets">Ref6</span><span class="fn-backref">(<a href="#id7">1</a>,<a href="#id35">2</a>,<a href="#id37">3</a>,<a href="#id93">4</a>)</span></dt>
<dd><p>J. K. Baker, “The dragon system—An overview”, IEEE Trans. Acoust.
Speech Signal Processing, vol. ASSP-23, no. 1, pp. 24-29, Feb. 1975.</p>
</dd>
<dt class="label" id="ref7"><span class="brackets"><a class="fn-backref" href="#id8">Ref7</a></span></dt>
<dd><p>F. Jelinek, “A fast sequential decoding algorithm using a stack”,
IBM J. Res. Develop., vol. 13, pp. 675-685, 1969.</p>
</dd>
<dt class="label" id="ref8"><span class="brackets"><a class="fn-backref" href="#id9">Ref8</a></span></dt>
<dd><p>L. R. Bahl and F. Jelinek, “Decoding for channels with insertions
deletions and substitutions with applications to speech recognition”,
IEEE Trans. In format. Theory, vol. IT-21, pp. 404-411, 1975.</p>
</dd>
<dt class="label" id="ref9"><span class="brackets"><a class="fn-backref" href="#id10">Ref9</a></span></dt>
<dd><p>F. Jelinek, L. R. Bahl and R. L. Mercer, “Design of a linguistic
statistical decoder for the recognition of continuous speech”, IEEE
Trans. Informat. Theory, vol. IT-21, pp. 250-256, 1975.</p>
</dd>
<dt class="label" id="ref10"><span class="brackets">Ref10</span><span class="fn-backref">(<a href="#id11">1</a>,<a href="#id42">2</a>)</span></dt>
<dd><p>F. Jelinek, “Continuous speech recognition by statistical methods”,
Proc. IEEE, vol. 64, pp. 532-536, Apr. 1976.</p>
</dd>
<dt class="label" id="ref11"><span class="brackets">Ref11</span><span class="fn-backref">(<a href="#id12">1</a>,<a href="#id41">2</a>)</span></dt>
<dd><p>R. Bakis, “Continuous speech word recognition via centisecond
acoustic states”, Proc. ASA Meeting, 1976-Apr.</p>
</dd>
<dt class="label" id="ref12"><span class="brackets"><a class="fn-backref" href="#id13">Ref12</a></span></dt>
<dd><p>F. Jelinek, L. R. Bahl and R. L. Mercer, “Continuous speech
recognition: Statistical methods” in Handbook of Statistics II, The
Netherlands, Amsterdam:North-Holland, 1982.</p>
</dd>
<dt class="label" id="ref13"><span class="brackets">Ref13</span><span class="fn-backref">(<a href="#id14">1</a>,<a href="#id57">2</a>,<a href="#id58">3</a>,<a href="#id59">4</a>,<a href="#id87">5</a>,<a href="#id94">6</a>)</span></dt>
<dd><p>L. R. Bahl, F. Jelinek and R. L. Mercer, “A maximum likelihood
approach to continuous speech recognition”, IEEE Trans. Pattern Anal.
Machine Intell., vol. PAMI-5, pp. 179-190, 1983.</p>
</dd>
<dt class="label" id="ref14"><span class="brackets">Ref14</span><span class="fn-backref">(<a href="#id15">1</a>,<a href="#id34">2</a>,<a href="#id40">3</a>,<a href="#id80">4</a>,<a href="#id81">5</a>)</span></dt>
<dd><p>S. E. Levinson, L. R. Rabiner and M. M. Sondhi, “An introduction to
the application of the theory of probabilistic functions of a Markov
process to automatic speech recognition”, Bell Syst. Tech. J., vol.
62, no. 4, pp. 1035-1074, Apr. 1983.</p>
</dd>
<dt class="label" id="ref15"><span class="brackets"><a class="fn-backref" href="#id16">Ref15</a></span></dt>
<dd><p>B. H. Juang, “On the hidden Markov model and dynamic time warping for
speech recognition—A unified view”, AT&amp;T Tech., vol. 63, no. 7, pp.
1213-1243, Sept. 1984.</p>
</dd>
<dt class="label" id="ref16"><span class="brackets"><a class="fn-backref" href="#id17">Ref16</a></span></dt>
<dd><p>L. R. Rabiner and B. H. Juang, “An introduction to hidden Markov
models”, IEEE ASSP Mag., vol. 3, no. 1, pp. 4-16, 1986.</p>
</dd>
<dt class="label" id="ref17"><span class="brackets"><a class="fn-backref" href="#id18">Ref17</a></span></dt>
<dd><p>J. S. Bridle, “Stochastic models and template matching: Some
important relationships between two apparently different techniques
for automatic speech recognition”, Proc. Inst. of Acoustics Autum
Conf., pp. 1-8, 1984-Nov.</p>
</dd>
<dt class="label" id="ref18"><span class="brackets"><a class="fn-backref" href="#id19">Ref18</a></span></dt>
<dd><p>J. Makhoul, S. Roucos and H. Gish, “Vector quantization in speech
coding”, Proc. IEEE, vol. 73, no. 11, pp. 1551-1588, Nov. 1985.</p>
</dd>
<dt class="label" id="ref19"><span class="brackets">Ref19</span><span class="fn-backref">(<a href="#id20">1</a>,<a href="#id66">2</a>)</span></dt>
<dd><p>S. E. Levinson, “Structural methods in automatic speech recognition”,
Proc. IEEE, vol. 73, no. 11, pp. 1625-1650, Nov. 1985.</p>
</dd>
<dt class="label" id="ref20"><span class="brackets"><a class="fn-backref" href="#id101">Ref20</a></span></dt>
<dd><p>A. W. Drake, “Discrete—state Markov processes” in Fundamentals of
Applied Probability Theory, NY, New York:McGraw-Hill, 1967.</p>
</dd>
<dt class="label" id="ref21"><span class="brackets"><a class="fn-backref" href="#id29">Ref21</a></span></dt>
<dd><p>A. J. Viterbi, “Error bounds for convolutional codes and an
asymptotically optimal decoding algorithm”, IEEE Trans. Informat.
Theory, vol. IT-13, pp. 260-269, Apr. 1967.</p>
</dd>
<dt class="label" id="ref22"><span class="brackets"><a class="fn-backref" href="#id30">Ref22</a></span></dt>
<dd><p>G. D. Forney, “The Viterbi algorithm”, Proc. IEEE, vol. 61, pp.
268-278, Mar. 1973.</p>
</dd>
<dt class="label" id="ref23"><span class="brackets">Ref23</span><span class="fn-backref">(<a href="#id33">1</a>,<a href="#id39">2</a>)</span></dt>
<dd><p>A. P. Dempster, N. M. Laird and D. B. Rubin, “Maximum likelihood from
incomplete data via the EM algorithm”, J. Roy. Stat. Soc., vol. 39,
no. 1, pp. 1-38, 1977.</p>
</dd>
<dt class="label" id="ref24"><span class="brackets">Ref24</span><span class="fn-backref">(<a href="#id43">1</a>,<a href="#id46">2</a>,<a href="#id49">3</a>,<a href="#id50">4</a>)</span></dt>
<dd><p>L. A. Liporace, “Maximum likelihood estimation for multivariate
observations of Markov sources”, IEEE Trans. Informat. Theory, vol.
IT-28, no. 5, pp. 729-734, 1982.</p>
</dd>
<dt class="label" id="ref25"><span class="brackets">Ref25</span><span class="fn-backref">(<a href="#id44">1</a>,<a href="#id47">2</a>,<a href="#id51">3</a>)</span></dt>
<dd><p>B. H. Juang, “Maximum likelihood estimation for mixture multivariate
stochastic observations of Markov chains”, AT&amp;T Tech. J., vol. 64,
no. 6, pp. 1235-1249, July-Aug. 1985.</p>
</dd>
<dt class="label" id="ref26"><span class="brackets">Ref26</span><span class="fn-backref">(<a href="#id45">1</a>,<a href="#id48">2</a>,<a href="#id52">3</a>)</span></dt>
<dd><p>B. H. Juang, S. E. Levinson and M. M. Sondhi, “Maximum likelihood
estimation for multivariate mixture observations of Markov chains”,
IEEE Trans. Informat. Theory, vol. IT-32, no. 2, pp. 307-309,
Mar. 1986.</p>
</dd>
<dt class="label" id="ref27"><span class="brackets">Ref27</span><span class="fn-backref">(<a href="#id53">1</a>,<a href="#id55">2</a>)</span></dt>
<dd><p>A. B. Poritz, “Linear predictive hidden Markov models and the speech
signal”, Proc. ICASSP ‘82, pp. 1291-1294, 1982-May.</p>
</dd>
<dt class="label" id="ref28"><span class="brackets">Ref28</span><span class="fn-backref">(<a href="#id54">1</a>,<a href="#id56">2</a>)</span></dt>
<dd><p>B. H. Juang and L. R. Rabiner, “Mixture autoregressive hidden Markov
models for speech signals”, IEEE Trans. Acoust. Speech Signal
Processing, vol. ASSP-33, no. 6, pp. 1404-1413, Dec. 1985.</p>
</dd>
<dt class="label" id="ref29"><span class="brackets">Ref29</span><span class="fn-backref">(<a href="#id61">1</a>,<a href="#id64">2</a>)</span></dt>
<dd><p>M. J. Russell and R. K. Moore, “Explicit modeling of state occupancy
in hidden Markov models for automatic speech recognition”, Proc.
ICASSP’85, pp. 5-8, 1985-Mar.</p>
</dd>
<dt class="label" id="ref30"><span class="brackets">Ref30</span><span class="fn-backref">(<a href="#id62">1</a>,<a href="#id65">2</a>)</span></dt>
<dd><p>S. E. Levinson, “Continuously variable duration hidden Markov models
for automatic speech recognition”, Computer Speech and Language, vol.
1, no. 1, pp. 29-45, Mar. 1986.</p>
</dd>
<dt class="label" id="ref31"><span class="brackets">Ref31</span><span class="fn-backref">(<a href="#id67">1</a>,<a href="#id71">2</a>,<a href="#id95">3</a>)</span></dt>
<dd><p>B. Lowerre and R. Reddy, “The HARPY speech understanding system” in
Trends in Speech Recognition, NJ, Englewood Cliffs:Prentice-Hall, pp.
340-346, 1980.</p>
</dd>
<dt class="label" id="ref32"><span class="brackets">Ref32</span><span class="fn-backref">(<a href="#id68">1</a>,<a href="#id70">2</a>,<a href="#id73">3</a>)</span></dt>
<dd><p>L. R. Bahl, P. F. Brown, P. V. de Souza and R. L. Mercer, “Maximum
mutual information estimation of hidden Markov model parameters for
speech recognition”, Proc. ICASSP ‘86, pp. 49-52, 1986-Apr.</p>
</dd>
<dt class="label" id="ref33"><span class="brackets">Ref33</span><span class="fn-backref">(<a href="#id69">1</a>,<a href="#id74">2</a>,<a href="#id75">3</a>)</span></dt>
<dd><p>Y. Ephraim, A. Dembo and L. R. Rabiner, “A minimum discrimination
information approach for hidden Markov modeling”, Proc. ICASSP ‘87,
1987-Apr.</p>
</dd>
<dt class="label" id="ref34"><span class="brackets">Ref34</span><span class="fn-backref">(<a href="#id77">1</a>,<a href="#id78">2</a>,<a href="#id79">3</a>)</span></dt>
<dd><p>B. H. Juang and L. R. Rabiner, “A probabilistic distance measure for
hidden Markov models”, AT&amp;T Tech. J., vol. 64, no. 2, pp. 391-408,
Feb. 1985.</p>
</dd>
<dt class="label" id="ref35"><span class="brackets"><a class="fn-backref" href="#id82">Ref35</a></span></dt>
<dd><p>L. R. Rabiner, B. H. Juang, S. E. Levinson and M. M. Sondhi, “Some
properties of continuous hidden Markov model representations”, AT&amp;T
Tech. J., vol. 64, no. 6, pp. 1251-1270, July-Aug. 1985.</p>
</dd>
<dt class="label" id="ref36"><span class="brackets">Ref36</span><span class="fn-backref">(<a href="#id83">1</a>,<a href="#id84">2</a>,<a href="#id85">3</a>,<a href="#id86">4</a>)</span></dt>
<dd><p>F. Jelinek and R. L. Mercer, “Interpolated estimation of Markov
source parameters from sparse data” in Pattern Recognition in
Practice, The Netherlands, Amsterdam:North-Holland, pp.
381-397, 1980.</p>
</dd>
<dt class="label" id="ref37"><span class="brackets">Ref37</span><span class="fn-backref">(<a href="#id88">1</a>,<a href="#id96">2</a>)</span></dt>
<dd><p>R. Schwartz, “Context-dependent modeling for acoustic-phonetic
recognition of continuous speech”, Conf. Proc. IEEE Int. Conf. on
Acoustics Speech and Signal Processing, pp. 1205-1208, 1985-Apr.</p>
</dd>
<dt class="label" id="ref38"><span class="brackets">Ref38</span><span class="fn-backref">(<a href="#id89">1</a>,<a href="#id97">2</a>)</span></dt>
<dd><p>K. F. Lee and H. W. Hon, “Large-vocabulary speaker-independent
continuous speech recognition”, Conf. Proc. IEEE Int. Conf. on
Acoustics Speech and Signal Processing, pp. 123-126, 1988-Apr.</p>
</dd>
<dt class="label" id="ref39"><span class="brackets"><a class="fn-backref" href="#id90">Ref39</a></span></dt>
<dd><p>L. R. Rabiner, S. E. Levinson and M. M. Sondhi, “On the application
of vector quantization and hidden Markov models to
speaker-independent isolated word recognition”, Bell Syst. Tech. J.,
vol. 62, no. 4, pp. 1075-1105, Apr. 1983.</p>
</dd>
<dt class="label" id="ref40"><span class="brackets">Ref40</span></dt>
<dd><p>L. R. Rabiner, S. E. Levinson and M. M. Sondhi, “On the use of hidden
Markov models for speaker-independent recognition of isolated words
from a medium-size vocabulary”, AT&amp;T Tech. J., vol. 63, no. 4, pp.
627-642, Apr. 1984.</p>
</dd>
<dt class="label" id="ref41"><span class="brackets">Ref41</span></dt>
<dd><p>R. Billi, “Vector quantization and Markov source models applied to
speech recognition”, Proc. ICASSP ‘82, pp. 574-577, 1982-May.</p>
</dd>
<dt class="label" id="ref42"><span class="brackets">Ref42</span></dt>
<dd><p>L. R. Rabiner, B. H. Juang, S. E. Levinson and M. M. Sondhi,
“Recognition of isolated digits using hidden Markov models with
continuous mixture densities”, AT&amp;T Tech. J., vol. 64, no. 6, pp.
1211-1222, July-Aug. 1986.</p>
</dd>
<dt class="label" id="ref43"><span class="brackets">Ref43</span></dt>
<dd><p>A. B. Poritz and A. G. Richter, “Isolated word recognition”, Proc.
ICASSP ‘86, pp. 705-708, 1986-Apr.</p>
</dd>
<dt class="label" id="ref44"><span class="brackets">Ref44</span></dt>
<dd><p>R. P. Lippmann, E. A. Martin and D. B. Paul, “Multistyle training for
robust isolated word speech recognition”, Proc. ICASSP ‘87, pp.
705-708, 1987-Apr.</p>
</dd>
<dt class="label" id="ref45"><span class="brackets">Ref45</span></dt>
<dd><p>D. B. Paul, “A speaker stress resistant HMM isolated word
recognizer”, Proc. ICASSP’87, pp. 713-716, 1987-Apr.</p>
</dd>
<dt class="label" id="ref46"><span class="brackets">Ref46</span></dt>
<dd><p>V. N. Gupta, M. Lennig and P. Mermelstein, “Integration of acoustic
information in a large vocabulary word recognizer”, Conf. Proc. IEEE
Int. Conf. on Acoustics Speech and Signal Processing, pp. 697-700,
1987-Apr.</p>
</dd>
<dt class="label" id="ref47"><span class="brackets">Ref47</span></dt>
<dd><p>S. E. Levinson, “Continuous speech recognition by means of
acoustic-phonetic classification obtained from a hidden Markov
model”, Proc. ICASSP ‘87, 1987-Apr.</p>
</dd>
<dt class="label" id="ref48"><span class="brackets">Ref48</span></dt>
<dd><p>J. C. Wilpon, L. R. Rabiner and T. Martin, “An improved word
detection algorithm for telephone quality speech incorporating both
syntactic and semantic constraints”, AT&amp;T Bell Labs Tech. J., vol.
63, no. 3, pp. 479-498, Mar. 1984.</p>
</dd>
<dt class="label" id="ref49"><span class="brackets">Ref49</span></dt>
<dd><p>J. G. Wilpon and L. R. Rabiner, “Application of hidden Markov models
to automatic speech endpoint detection”, Computer Speech and
Language, vol. 2, no. 3/4, pp. 321-341, Sept./Dec. 1987.</p>
</dd>
<dt class="label" id="ref50"><span class="brackets">Ref50</span></dt>
<dd><p>A. Averbuch, “Experiments with the TANGORA 20000 word speech
recognizer”, Conf. Proc. IEEE Int. Conf. on Acoustics Speech and
Signal Processing, pp. 701-704, 1987-Apr.</p>
</dd>
<dt class="label" id="ref51"><span class="brackets"><a class="fn-backref" href="#id98">Ref51</a></span></dt>
<dd><p>B. S. Atal and S. L. Hanauer, “Speech analysis and synthesis by
linear prediction of the speech wave”, J. Acoust. Soc. Am., vol. 50,
pp. 637-655, 1971.</p>
</dd>
<dt class="label" id="ref52"><span class="brackets">Ref52</span></dt>
<dd><p>F. I. Itakura and S. Saito, “Analysis-synthesis telephony based upon
the maximum likelihood method”, Proc. 6th Int. Congress on Acoustics,
pp. C17-20, 1968.</p>
</dd>
<dt class="label" id="ref53"><span class="brackets">Ref53</span></dt>
<dd><p>J. Makhoul, “Linear prediction: A tutorial review”, Proc. IEEE, vol.
63, pp. 561-580, 1975.</p>
</dd>
<dt class="label" id="ref54"><span class="brackets">Ref54</span></dt>
<dd><p>J. D. Markel and A. H. Gray, Linear Prediction of Speech, NY, New
York:Springer-Verlag, 1976.</p>
</dd>
<dt class="label" id="ref55"><span class="brackets">Ref55</span></dt>
<dd><p>Y. Tokhura, “A weighted cepstral distance measure for speech
recognition”, IEEE Trans. Acoust. Speech Signal Processing, vol.
ASSP-35, no. 10, pp. 1414-1422, Oct. 1987.</p>
</dd>
<dt class="label" id="ref56"><span class="brackets">Ref56</span></dt>
<dd><p>B. H. Juang, L. R. Rabiner and J. G. Wilpon, “On the use of bandpass
liftering in speech recognition”, IEEE Trans. Acoust. Speech Signal
Processing, vol. ASSP-35, no. 7, pp. 947-954, July 1987.</p>
</dd>
<dt class="label" id="ref57"><span class="brackets">Ref57</span></dt>
<dd><p>S. Furui, “Speaker independent isolated word recognition based on
dynamics emphasized cepstrum”, Trans. IECE of Japan, vol. 69, no. 12,
pp. 1310-1317, Dec. 1986.</p>
</dd>
<dt class="label" id="ref58"><span class="brackets">Ref58</span></dt>
<dd><p>F. K. Soong and A. E. Rosenberg, “On the use of instantaneous and
transitional spectral information in speaker recognition”, Proc.
ICASSP ‘86, pp. 877-880, 1986-Apr.</p>
</dd>
<dt class="label" id="ref59"><span class="brackets"><a class="fn-backref" href="#id91">Ref59</a></span></dt>
<dd><p>L. R. Rabiner, J. G. Wilpon and B. H. Juang, “A segmental k-means
training procedure for connected word recognition”, AT&amp;T Tech. J.,
vol. 65, no. 3, pp. 21-31, May-June 1986.</p>
</dd>
<dt class="label" id="ref60"><span class="brackets">Ref60</span></dt>
<dd><p>L. R. Rabiner and S. E. Levinson, “A speaker-independent
syntax-directed connected word recognition system based on hidden
Markov models and level building”, IEEE Trans. Acoust. Speech Signal
Processing, vol. ASSP-33, no. 3, pp. 561-573, June 1985.</p>
</dd>
<dt class="label" id="ref61"><span class="brackets">Ref61</span></dt>
<dd><p>L. R. Rabiner, J. G. Wilpon and B. H. Juang, “A modei-based connected
digit recognition system using either hidden Markov models or
templates”, Computer Speech and Language, vol. 1, no. 2, pp. 167-197,
Dec. 1986.</p>
</dd>
<dt class="label" id="ref62"><span class="brackets">Ref62</span></dt>
<dd><p>H. Bourlard, Y. Kamp, H. Ney and C. J. Wellekens, “Speaker-dependent
connected speech recognition via dynamic programming and statistical
methods” in Speech and Speaker Recognition, Switzerland,
Basel:Karger, pp. 115-148, 1985.</p>
</dd>
<dt class="label" id="ref63"><span class="brackets"><a class="fn-backref" href="#id92">Ref63</a></span></dt>
<dd><p>C. J. Wellekens, “Global connected digit recognition using Baum-Welch
algorithm”, Proc. ICASSP ‘86, pp. 1081-1084, 1986-Apr.</p>
</dd>
<dt class="label" id="ref64"><span class="brackets"><a class="fn-backref" href="#id99">Ref64</a></span></dt>
<dd><p>A. M. Derouault, “Context dependent phonetic Markov models for large
vocabulary speech recognition”, Proc. ICASSP ‘87, 1987-Apr.</p>
</dd>
<dt class="label" id="ref65"><span class="brackets">Ref65</span></dt>
<dd><p>B. Merialdo, “Speech recognition with very large size dictionary”,
Proc. ICASSP ‘87, 1987-Apr.</p>
</dd>
<dt class="label" id="ref66"><span class="brackets"><a class="fn-backref" href="#id100">Ref66</a></span></dt>
<dd><p>Y. L. Chow, “BYBLOS: The BBN continuous speech recognition system”,
Proc. ICASSP’87, 1987-Apr.</p>
</dd>
</dl>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Christie_清洁女工之死_2009.html" class="btn btn-neutral float-left" title="Notes on: Christie, A. (2009): 清洁女工之死" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="张书岩_简化字溯源_1997.html" class="btn btn-neutral float-right" title="Notes on: 张书岩, et al. (1997): 简化字溯源" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2020, 侠之大者.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>